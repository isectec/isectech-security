package reporting

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"math"
	"time"

	"go.uber.org/zap"
)

// MetricType defines different types of metrics
type MetricType string

const (
	MetricCounter   MetricType = "counter"
	MetricGauge     MetricType = "gauge"
	MetricHistogram MetricType = "histogram"
	MetricSummary   MetricType = "summary"
	MetricRate      MetricType = "rate"
	MetricRatio     MetricType = "ratio"
)

// MetricCategory defines metric categories
type MetricCategory string

const (
	CategorySecurity    MetricCategory = "security"
	CategoryPerformance MetricCategory = "performance"
	CategoryCompliance  MetricCategory = "compliance"
	CategoryBusiness    MetricCategory = "business"
	CategoryOperational MetricCategory = "operational"
	CategoryTechnical   MetricCategory = "technical"
)

// MetricDefinition defines a metric configuration
type MetricDefinition struct {
	ID          string                 `json:"id" db:"id"`
	Name        string                 `json:"name" db:"name"`
	Type        MetricType             `json:"type" db:"type"`
	Category    MetricCategory         `json:"category" db:"category"`
	Description string                 `json:"description" db:"description"`
	Unit        string                 `json:"unit" db:"unit"`
	Query       string                 `json:"query" db:"query"`
	Calculation *CalculationConfig     `json:"calculation,omitempty" db:"calculation"`
	Thresholds  map[string]interface{} `json:"thresholds,omitempty" db:"thresholds"`
	Labels      map[string]string      `json:"labels,omitempty" db:"labels"`
	IsActive    bool                   `json:"is_active" db:"is_active"`
	CreatedAt   time.Time              `json:"created_at" db:"created_at"`
	UpdatedAt   time.Time              `json:"updated_at" db:"updated_at"`
}

// CalculationConfig defines metric calculation parameters
type CalculationConfig struct {
	Formula      string                 `json:"formula,omitempty"`
	Window       string                 `json:"window,omitempty"`       // time window for calculation
	Granularity  string                 `json:"granularity,omitempty"`  // calculation granularity
	Aggregation  string                 `json:"aggregation,omitempty"`  // sum, avg, max, min, count
	Dependencies []string               `json:"dependencies,omitempty"` // dependent metrics
	Parameters   map[string]interface{} `json:"parameters,omitempty"`
}

// MetricValue represents a collected metric value
type MetricValue struct {
	ID          string                 `json:"id" db:"id"`
	TenantID    string                 `json:"tenant_id" db:"tenant_id"`
	MetricID    string                 `json:"metric_id" db:"metric_id"`
	Timestamp   time.Time              `json:"timestamp" db:"timestamp"`
	Value       float64                `json:"value" db:"value"`
	StringValue string                 `json:"string_value,omitempty" db:"string_value"`
	Labels      map[string]string      `json:"labels,omitempty" db:"labels"`
	Metadata    map[string]interface{} `json:"metadata,omitempty" db:"metadata"`
	Quality     *DataQuality           `json:"quality,omitempty" db:"quality"`
}

// DataQuality represents data quality metrics
type DataQuality struct {
	Score        float64   `json:"score"`        // 0-1 quality score
	Completeness float64   `json:"completeness"` // percentage of complete data
	Accuracy     float64   `json:"accuracy"`     // accuracy assessment
	Timeliness   float64   `json:"timeliness"`   // timeliness score
	Source       string    `json:"source"`       // data source
	Validated    bool      `json:"validated"`    // validation status
	ValidatedAt  time.Time `json:"validated_at,omitempty"`
}

// MetricAlert defines alerting configuration
type MetricAlert struct {
	ID         string                 `json:"id" db:"id"`
	TenantID   string                 `json:"tenant_id" db:"tenant_id"`
	MetricID   string                 `json:"metric_id" db:"metric_id"`
	Name       string                 `json:"name" db:"name"`
	Condition  string                 `json:"condition" db:"condition"` // >, <, ==, !=, etc.
	Threshold  float64                `json:"threshold" db:"threshold"`
	Severity   string                 `json:"severity" db:"severity"` // low, medium, high, critical
	Window     time.Duration          `json:"window" db:"window"`
	Recipients []string               `json:"recipients" db:"recipients"`
	IsActive   bool                   `json:"is_active" db:"is_active"`
	LastFired  *time.Time             `json:"last_fired,omitempty" db:"last_fired"`
	FireCount  int                    `json:"fire_count" db:"fire_count"`
	CreatedAt  time.Time              `json:"created_at" db:"created_at"`
	UpdatedAt  time.Time              `json:"updated_at" db:"updated_at"`
	Metadata   map[string]interface{} `json:"metadata,omitempty" db:"metadata"`
}

// MetricDashboard defines dashboard configuration
type MetricDashboard struct {
	ID          string                 `json:"id" db:"id"`
	TenantID    string                 `json:"tenant_id" db:"tenant_id"`
	Name        string                 `json:"name" db:"name"`
	Description string                 `json:"description" db:"description"`
	Layout      *DashboardLayout       `json:"layout" db:"layout"`
	Widgets     []DashboardWidget      `json:"widgets" db:"widgets"`
	Filters     map[string]interface{} `json:"filters,omitempty" db:"filters"`
	RefreshRate time.Duration          `json:"refresh_rate" db:"refresh_rate"`
	IsPublic    bool                   `json:"is_public" db:"is_public"`
	Tags        []string               `json:"tags,omitempty" db:"tags"`
	CreatedAt   time.Time              `json:"created_at" db:"created_at"`
	UpdatedAt   time.Time              `json:"updated_at" db:"updated_at"`
	CreatedBy   string                 `json:"created_by" db:"created_by"`
}

// DashboardLayout defines dashboard visual layout
type DashboardLayout struct {
	Type    string                 `json:"type"`    // grid, flow, tabs
	Columns int                    `json:"columns"` // number of columns
	Options map[string]interface{} `json:"options,omitempty"`
}

// DashboardWidget defines dashboard widgets
type DashboardWidget struct {
	ID       string                 `json:"id"`
	Type     string                 `json:"type"` // chart, table, kpi, text
	Title    string                 `json:"title"`
	MetricID string                 `json:"metric_id,omitempty"`
	Position *WidgetPosition        `json:"position"`
	Config   map[string]interface{} `json:"config,omitempty"`
	Query    string                 `json:"query,omitempty"`
}

// WidgetPosition defines widget placement
type WidgetPosition struct {
	Row    int `json:"row"`
	Column int `json:"column"`
	Width  int `json:"width"`
	Height int `json:"height"`
}

// KPIDefinition defines Key Performance Indicators
type KPIDefinition struct {
	ID          string                 `json:"id" db:"id"`
	TenantID    string                 `json:"tenant_id" db:"tenant_id"`
	Name        string                 `json:"name" db:"name"`
	Description string                 `json:"description" db:"description"`
	Formula     string                 `json:"formula" db:"formula"`
	Target      float64                `json:"target" db:"target"`
	Unit        string                 `json:"unit" db:"unit"`
	Frequency   string                 `json:"frequency" db:"frequency"` // daily, weekly, monthly, quarterly
	Owner       string                 `json:"owner" db:"owner"`
	Category    string                 `json:"category" db:"category"`
	Priority    string                 `json:"priority" db:"priority"`
	Thresholds  *KPIThresholds         `json:"thresholds" db:"thresholds"`
	IsActive    bool                   `json:"is_active" db:"is_active"`
	CreatedAt   time.Time              `json:"created_at" db:"created_at"`
	UpdatedAt   time.Time              `json:"updated_at" db:"updated_at"`
	Metadata    map[string]interface{} `json:"metadata,omitempty" db:"metadata"`
}

// KPIThresholds defines performance thresholds
type KPIThresholds struct {
	Excellent float64 `json:"excellent"` // Green zone
	Good      float64 `json:"good"`      // Yellow zone
	Poor      float64 `json:"poor"`      // Red zone
	Critical  float64 `json:"critical"`  // Critical threshold
}

// KPIValue represents KPI measurement
type KPIValue struct {
	ID        string                 `json:"id" db:"id"`
	TenantID  string                 `json:"tenant_id" db:"tenant_id"`
	KPIID     string                 `json:"kpi_id" db:"kpi_id"`
	Timestamp time.Time              `json:"timestamp" db:"timestamp"`
	Value     float64                `json:"value" db:"value"`
	Target    float64                `json:"target" db:"target"`
	Status    string                 `json:"status" db:"status"` // excellent, good, poor, critical
	Trend     string                 `json:"trend" db:"trend"`   // up, down, stable
	Period    string                 `json:"period" db:"period"` // reporting period
	Metadata  map[string]interface{} `json:"metadata,omitempty" db:"metadata"`
}

// MetricCollector manages metrics collection and processing
type MetricCollector struct {
	db           *sql.DB
	logger       *zap.Logger
	config       *CollectorConfig
	calculators  map[string]MetricCalculator
	aggregators  map[string]MetricAggregator
	validators   map[string]MetricValidator
	alertManager AlertManager
	dashboardMgr DashboardManager
}

// CollectorConfig defines collector configuration
type CollectorConfig struct {
	CollectionInterval time.Duration `json:"collection_interval"`
	RetentionPeriod    time.Duration `json:"retention_period"`
	BatchSize          int           `json:"batch_size"`
	MaxConcurrency     int           `json:"max_concurrency"`
	EnableAlerts       bool          `json:"enable_alerts"`
	EnableDashboards   bool          `json:"enable_dashboards"`
	QualityThreshold   float64       `json:"quality_threshold"`
	ValidationEnabled  bool          `json:"validation_enabled"`
	CacheEnabled       bool          `json:"cache_enabled"`
	CacheTTL           time.Duration `json:"cache_ttl"`
}

// MetricCalculator interface for metric calculations
type MetricCalculator interface {
	Calculate(ctx context.Context, definition *MetricDefinition, params map[string]interface{}) (float64, error)
	ValidateDefinition(definition *MetricDefinition) error
}

// MetricAggregator interface for metric aggregation
type MetricAggregator interface {
	Aggregate(ctx context.Context, values []MetricValue, config *CalculationConfig) (*MetricValue, error)
	SupportedTypes() []MetricType
}

// MetricValidator interface for data validation
type MetricValidator interface {
	Validate(ctx context.Context, value *MetricValue, definition *MetricDefinition) (*DataQuality, error)
	ValidateThresholds(value float64, thresholds map[string]interface{}) error
}

// AlertManager interface for alerting
type AlertManager interface {
	EvaluateAlerts(ctx context.Context, metric *MetricValue) error
	CreateAlert(ctx context.Context, alert *MetricAlert) error
	UpdateAlert(ctx context.Context, alert *MetricAlert) error
	DeleteAlert(ctx context.Context, alertID string, tenantID string) error
}

// DashboardManager interface for dashboard management
type DashboardManager interface {
	CreateDashboard(ctx context.Context, dashboard *MetricDashboard) error
	UpdateDashboard(ctx context.Context, dashboard *MetricDashboard) error
	GetDashboard(ctx context.Context, dashboardID string, tenantID string) (*MetricDashboard, error)
	ListDashboards(ctx context.Context, tenantID string) ([]*MetricDashboard, error)
}

// NewMetricCollector creates a new metrics collector
func NewMetricCollector(db *sql.DB, logger *zap.Logger, config *CollectorConfig) *MetricCollector {
	collector := &MetricCollector{
		db:           db,
		logger:       logger,
		config:       config,
		calculators:  make(map[string]MetricCalculator),
		aggregators:  make(map[string]MetricAggregator),
		validators:   make(map[string]MetricValidator),
		alertManager: NewDefaultAlertManager(db, logger),
		dashboardMgr: NewDefaultDashboardManager(db, logger),
	}

	// Register default calculators
	collector.RegisterCalculator("vulnerability_count", NewVulnerabilityCountCalculator(db))
	collector.RegisterCalculator("remediation_time", NewRemediationTimeCalculator(db))
	collector.RegisterCalculator("risk_score", NewRiskScoreCalculator(db))
	collector.RegisterCalculator("compliance_score", NewComplianceScoreCalculator(db))
	collector.RegisterCalculator("sla_performance", NewSLAPerformanceCalculator(db))

	// Register aggregators
	collector.RegisterAggregator("time_series", NewTimeSeriesAggregator())
	collector.RegisterAggregator("statistical", NewStatisticalAggregator())

	// Register validators
	collector.RegisterValidator("range", NewRangeValidator())
	collector.RegisterValidator("statistical", NewStatisticalValidator())

	return collector
}

// RegisterCalculator registers a metric calculator
func (mc *MetricCollector) RegisterCalculator(name string, calculator MetricCalculator) {
	mc.calculators[name] = calculator
}

// RegisterAggregator registers a metric aggregator
func (mc *MetricCollector) RegisterAggregator(name string, aggregator MetricAggregator) {
	mc.aggregators[name] = aggregator
}

// RegisterValidator registers a metric validator
func (mc *MetricCollector) RegisterValidator(name string, validator MetricValidator) {
	mc.validators[name] = validator
}

// CollectMetric collects a single metric value
func (mc *MetricCollector) CollectMetric(ctx context.Context, tenantID string, metricID string) (*MetricValue, error) {
	// Get metric definition
	definition, err := mc.getMetricDefinition(ctx, metricID)
	if err != nil {
		return nil, fmt.Errorf("failed to get metric definition: %w", err)
	}

	if !definition.IsActive {
		return nil, fmt.Errorf("metric %s is not active", metricID)
	}

	// Calculate metric value
	calculator, exists := mc.calculators[definition.Type]
	if !exists {
		return nil, fmt.Errorf("no calculator found for metric type: %s", definition.Type)
	}

	value, err := calculator.Calculate(ctx, definition, nil)
	if err != nil {
		return nil, fmt.Errorf("failed to calculate metric: %w", err)
	}

	// Create metric value
	metricValue := &MetricValue{
		ID:        generateMetricValueID(),
		TenantID:  tenantID,
		MetricID:  metricID,
		Timestamp: time.Now(),
		Value:     value,
		Labels:    definition.Labels,
		Metadata:  make(map[string]interface{}),
	}

	// Validate if enabled
	if mc.config.ValidationEnabled {
		if validator, exists := mc.validators["range"]; exists {
			quality, err := validator.Validate(ctx, metricValue, definition)
			if err != nil {
				mc.logger.Warn("Metric validation failed", zap.Error(err))
			} else {
				metricValue.Quality = quality
			}
		}
	}

	// Store metric value
	if err := mc.storeMetricValue(ctx, metricValue); err != nil {
		return nil, fmt.Errorf("failed to store metric value: %w", err)
	}

	// Evaluate alerts if enabled
	if mc.config.EnableAlerts {
		if err := mc.alertManager.EvaluateAlerts(ctx, metricValue); err != nil {
			mc.logger.Warn("Failed to evaluate alerts", zap.Error(err))
		}
	}

	mc.logger.Debug("Metric collected successfully",
		zap.String("metric_id", metricID),
		zap.String("tenant_id", tenantID),
		zap.Float64("value", value))

	return metricValue, nil
}

// CollectAllMetrics collects all active metrics for a tenant
func (mc *MetricCollector) CollectAllMetrics(ctx context.Context, tenantID string) ([]*MetricValue, error) {
	// Get all active metric definitions
	definitions, err := mc.getActiveMetricDefinitions(ctx, tenantID)
	if err != nil {
		return nil, fmt.Errorf("failed to get metric definitions: %w", err)
	}

	values := make([]*MetricValue, 0, len(definitions))

	// Collect metrics concurrently
	type result struct {
		value *MetricValue
		err   error
	}

	results := make(chan result, len(definitions))
	semaphore := make(chan struct{}, mc.config.MaxConcurrency)

	for _, definition := range definitions {
		go func(def *MetricDefinition) {
			semaphore <- struct{}{}
			defer func() { <-semaphore }()

			value, err := mc.CollectMetric(ctx, tenantID, def.ID)
			results <- result{value: value, err: err}
		}(definition)
	}

	// Collect results
	for i := 0; i < len(definitions); i++ {
		result := <-results
		if result.err != nil {
			mc.logger.Warn("Failed to collect metric", zap.Error(result.err))
			continue
		}
		values = append(values, result.value)
	}

	return values, nil
}

// CreateMetricDefinition creates a new metric definition
func (mc *MetricCollector) CreateMetricDefinition(ctx context.Context, definition *MetricDefinition) error {
	// Validate the definition
	if definition.ID == "" {
		definition.ID = generateMetricDefinitionID()
	}

	definition.CreatedAt = time.Now()
	definition.UpdatedAt = time.Now()

	// Validate with appropriate calculator
	if calculator, exists := mc.calculators[string(definition.Type)]; exists {
		if err := calculator.ValidateDefinition(definition); err != nil {
			return fmt.Errorf("invalid metric definition: %w", err)
		}
	}

	// Store in database
	return mc.storeMetricDefinition(ctx, definition)
}

// GetMetricHistory retrieves historical metric values
func (mc *MetricCollector) GetMetricHistory(ctx context.Context, tenantID string, metricID string,
	start time.Time, end time.Time, granularity string) ([]*MetricValue, error) {

	query := `
		SELECT id, tenant_id, metric_id, timestamp, value, string_value, labels, metadata, quality
		FROM vulnerability_metric_values 
		WHERE tenant_id = $1 AND metric_id = $2 AND timestamp BETWEEN $3 AND $4
		ORDER BY timestamp ASC`

	rows, err := mc.db.QueryContext(ctx, query, tenantID, metricID, start, end)
	if err != nil {
		return nil, fmt.Errorf("failed to query metric history: %w", err)
	}
	defer rows.Close()

	var values []*MetricValue
	for rows.Next() {
		var value MetricValue
		var labelsJSON, metadataJSON, qualityJSON []byte

		err := rows.Scan(
			&value.ID, &value.TenantID, &value.MetricID, &value.Timestamp,
			&value.Value, &value.StringValue, &labelsJSON, &metadataJSON, &qualityJSON,
		)
		if err != nil {
			return nil, fmt.Errorf("failed to scan metric value: %w", err)
		}

		// Unmarshal JSON fields
		if len(labelsJSON) > 0 {
			json.Unmarshal(labelsJSON, &value.Labels)
		}
		if len(metadataJSON) > 0 {
			json.Unmarshal(metadataJSON, &value.Metadata)
		}
		if len(qualityJSON) > 0 {
			json.Unmarshal(qualityJSON, &value.Quality)
		}

		values = append(values, &value)
	}

	// Apply granularity aggregation if needed
	if granularity != "" && len(values) > 0 {
		aggregatedValues, err := mc.aggregateByGranularity(ctx, values, granularity)
		if err != nil {
			mc.logger.Warn("Failed to apply granularity", zap.Error(err))
			return values, nil // Return original values if aggregation fails
		}
		return aggregatedValues, nil
	}

	return values, nil
}

// CalculateKPI calculates a KPI value
func (mc *MetricCollector) CalculateKPI(ctx context.Context, tenantID string, kpiID string) (*KPIValue, error) {
	// Get KPI definition
	kpiDef, err := mc.getKPIDefinition(ctx, kpiID)
	if err != nil {
		return nil, fmt.Errorf("failed to get KPI definition: %w", err)
	}

	// Calculate KPI value using formula
	value, err := mc.evaluateKPIFormula(ctx, kpiDef.Formula, tenantID)
	if err != nil {
		return nil, fmt.Errorf("failed to evaluate KPI formula: %w", err)
	}

	// Determine status based on thresholds
	status := mc.determineKPIStatus(value, kpiDef.Thresholds)

	// Calculate trend (requires historical data)
	trend, err := mc.calculateKPITrend(ctx, tenantID, kpiID, value)
	if err != nil {
		mc.logger.Warn("Failed to calculate KPI trend", zap.Error(err))
		trend = "unknown"
	}

	kpiValue := &KPIValue{
		ID:        generateKPIValueID(),
		TenantID:  tenantID,
		KPIID:     kpiID,
		Timestamp: time.Now(),
		Value:     value,
		Target:    kpiDef.Target,
		Status:    status,
		Trend:     trend,
		Period:    mc.getCurrentPeriod(kpiDef.Frequency),
		Metadata:  make(map[string]interface{}),
	}

	// Store KPI value
	if err := mc.storeKPIValue(ctx, kpiValue); err != nil {
		return nil, fmt.Errorf("failed to store KPI value: %w", err)
	}

	return kpiValue, nil
}

// GetDashboardData retrieves data for a dashboard
func (mc *MetricCollector) GetDashboardData(ctx context.Context, dashboardID string, tenantID string) (map[string]interface{}, error) {
	// Get dashboard configuration
	dashboard, err := mc.dashboardMgr.GetDashboard(ctx, dashboardID, tenantID)
	if err != nil {
		return nil, fmt.Errorf("failed to get dashboard: %w", err)
	}

	data := make(map[string]interface{})

	// Collect data for each widget
	for _, widget := range dashboard.Widgets {
		widgetData, err := mc.getWidgetData(ctx, &widget, tenantID)
		if err != nil {
			mc.logger.Warn("Failed to get widget data",
				zap.String("widget_id", widget.ID),
				zap.Error(err))
			continue
		}
		data[widget.ID] = widgetData
	}

	return data, nil
}

// Helper methods

func (mc *MetricCollector) getMetricDefinition(ctx context.Context, metricID string) (*MetricDefinition, error) {
	query := `
		SELECT id, name, type, category, description, unit, query, calculation, 
		       thresholds, labels, is_active, created_at, updated_at
		FROM vulnerability_metric_definitions 
		WHERE id = $1`

	row := mc.db.QueryRowContext(ctx, query, metricID)

	var def MetricDefinition
	var calculationJSON, thresholdsJSON, labelsJSON []byte

	err := row.Scan(
		&def.ID, &def.Name, &def.Type, &def.Category, &def.Description,
		&def.Unit, &def.Query, &calculationJSON, &thresholdsJSON,
		&labelsJSON, &def.IsActive, &def.CreatedAt, &def.UpdatedAt,
	)
	if err != nil {
		return nil, err
	}

	// Unmarshal JSON fields
	if len(calculationJSON) > 0 {
		json.Unmarshal(calculationJSON, &def.Calculation)
	}
	if len(thresholdsJSON) > 0 {
		json.Unmarshal(thresholdsJSON, &def.Thresholds)
	}
	if len(labelsJSON) > 0 {
		json.Unmarshal(labelsJSON, &def.Labels)
	}

	return &def, nil
}

func (mc *MetricCollector) getActiveMetricDefinitions(ctx context.Context, tenantID string) ([]*MetricDefinition, error) {
	query := `
		SELECT id, name, type, category, description, unit, query, calculation,
		       thresholds, labels, is_active, created_at, updated_at
		FROM vulnerability_metric_definitions 
		WHERE is_active = true`

	rows, err := mc.db.QueryContext(ctx, query)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var definitions []*MetricDefinition
	for rows.Next() {
		var def MetricDefinition
		var calculationJSON, thresholdsJSON, labelsJSON []byte

		err := rows.Scan(
			&def.ID, &def.Name, &def.Type, &def.Category, &def.Description,
			&def.Unit, &def.Query, &calculationJSON, &thresholdsJSON,
			&labelsJSON, &def.IsActive, &def.CreatedAt, &def.UpdatedAt,
		)
		if err != nil {
			return nil, err
		}

		// Unmarshal JSON fields
		if len(calculationJSON) > 0 {
			json.Unmarshal(calculationJSON, &def.Calculation)
		}
		if len(thresholdsJSON) > 0 {
			json.Unmarshal(thresholdsJSON, &def.Thresholds)
		}
		if len(labelsJSON) > 0 {
			json.Unmarshal(labelsJSON, &def.Labels)
		}

		definitions = append(definitions, &def)
	}

	return definitions, nil
}

func (mc *MetricCollector) storeMetricValue(ctx context.Context, value *MetricValue) error {
	query := `
		INSERT INTO vulnerability_metric_values 
		(id, tenant_id, metric_id, timestamp, value, string_value, labels, metadata, quality)
		VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)`

	labelsJSON, _ := json.Marshal(value.Labels)
	metadataJSON, _ := json.Marshal(value.Metadata)
	qualityJSON, _ := json.Marshal(value.Quality)

	_, err := mc.db.ExecContext(ctx, query,
		value.ID, value.TenantID, value.MetricID, value.Timestamp,
		value.Value, value.StringValue, labelsJSON, metadataJSON, qualityJSON,
	)

	return err
}

func (mc *MetricCollector) storeMetricDefinition(ctx context.Context, definition *MetricDefinition) error {
	query := `
		INSERT INTO vulnerability_metric_definitions 
		(id, name, type, category, description, unit, query, calculation,
		 thresholds, labels, is_active, created_at, updated_at)
		VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13)
		ON CONFLICT (id) DO UPDATE SET
			name = EXCLUDED.name,
			type = EXCLUDED.type,
			category = EXCLUDED.category,
			description = EXCLUDED.description,
			unit = EXCLUDED.unit,
			query = EXCLUDED.query,
			calculation = EXCLUDED.calculation,
			thresholds = EXCLUDED.thresholds,
			labels = EXCLUDED.labels,
			is_active = EXCLUDED.is_active,
			updated_at = EXCLUDED.updated_at`

	calculationJSON, _ := json.Marshal(definition.Calculation)
	thresholdsJSON, _ := json.Marshal(definition.Thresholds)
	labelsJSON, _ := json.Marshal(definition.Labels)

	_, err := mc.db.ExecContext(ctx, query,
		definition.ID, definition.Name, definition.Type, definition.Category,
		definition.Description, definition.Unit, definition.Query,
		calculationJSON, thresholdsJSON, labelsJSON, definition.IsActive,
		definition.CreatedAt, definition.UpdatedAt,
	)

	return err
}

func (mc *MetricCollector) getKPIDefinition(ctx context.Context, kpiID string) (*KPIDefinition, error) {
	query := `
		SELECT id, tenant_id, name, description, formula, target, unit, frequency,
		       owner, category, priority, thresholds, is_active, created_at, updated_at, metadata
		FROM vulnerability_kpi_definitions 
		WHERE id = $1`

	row := mc.db.QueryRowContext(ctx, query, kpiID)

	var kpi KPIDefinition
	var thresholdsJSON, metadataJSON []byte

	err := row.Scan(
		&kpi.ID, &kpi.TenantID, &kpi.Name, &kpi.Description, &kpi.Formula,
		&kpi.Target, &kpi.Unit, &kpi.Frequency, &kpi.Owner, &kpi.Category,
		&kpi.Priority, &thresholdsJSON, &kpi.IsActive, &kpi.CreatedAt,
		&kpi.UpdatedAt, &metadataJSON,
	)
	if err != nil {
		return nil, err
	}

	// Unmarshal JSON fields
	if len(thresholdsJSON) > 0 {
		json.Unmarshal(thresholdsJSON, &kpi.Thresholds)
	}
	if len(metadataJSON) > 0 {
		json.Unmarshal(metadataJSON, &kpi.Metadata)
	}

	return &kpi, nil
}

func (mc *MetricCollector) storeKPIValue(ctx context.Context, value *KPIValue) error {
	query := `
		INSERT INTO vulnerability_kpi_values 
		(id, tenant_id, kpi_id, timestamp, value, target, status, trend, period, metadata)
		VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)`

	metadataJSON, _ := json.Marshal(value.Metadata)

	_, err := mc.db.ExecContext(ctx, query,
		value.ID, value.TenantID, value.KPIID, value.Timestamp,
		value.Value, value.Target, value.Status, value.Trend,
		value.Period, metadataJSON,
	)

	return err
}

func (mc *MetricCollector) aggregateByGranularity(ctx context.Context, values []*MetricValue, granularity string) ([]*MetricValue, error) {
	if aggregator, exists := mc.aggregators["time_series"]; exists {
		config := &CalculationConfig{
			Granularity: granularity,
			Aggregation: "avg", // Default aggregation
		}

		aggregatedValue, err := aggregator.Aggregate(ctx, values, config)
		if err != nil {
			return nil, err
		}

		return []*MetricValue{aggregatedValue}, nil
	}

	return values, nil
}

func (mc *MetricCollector) evaluateKPIFormula(ctx context.Context, formula string, tenantID string) (float64, error) {
	// This would implement formula evaluation
	// For now, return a placeholder value
	return 0.0, nil
}

func (mc *MetricCollector) determineKPIStatus(value float64, thresholds *KPIThresholds) string {
	if thresholds == nil {
		return "unknown"
	}

	if value >= thresholds.Excellent {
		return "excellent"
	} else if value >= thresholds.Good {
		return "good"
	} else if value >= thresholds.Poor {
		return "poor"
	}
	return "critical"
}

func (mc *MetricCollector) calculateKPITrend(ctx context.Context, tenantID string, kpiID string, currentValue float64) (string, error) {
	// Get previous value for trend calculation
	query := `
		SELECT value FROM vulnerability_kpi_values 
		WHERE tenant_id = $1 AND kpi_id = $2 
		ORDER BY timestamp DESC 
		LIMIT 1 OFFSET 1`

	var previousValue float64
	err := mc.db.QueryRowContext(ctx, query, tenantID, kpiID).Scan(&previousValue)
	if err != nil {
		if err == sql.ErrNoRows {
			return "unknown", nil
		}
		return "", err
	}

	diff := currentValue - previousValue
	threshold := math.Abs(previousValue) * 0.05 // 5% threshold

	if math.Abs(diff) <= threshold {
		return "stable", nil
	} else if diff > 0 {
		return "up", nil
	}
	return "down", nil
}

func (mc *MetricCollector) getCurrentPeriod(frequency string) string {
	now := time.Now()
	switch frequency {
	case "daily":
		return now.Format("2006-01-02")
	case "weekly":
		year, week := now.ISOWeek()
		return fmt.Sprintf("%d-W%02d", year, week)
	case "monthly":
		return now.Format("2006-01")
	case "quarterly":
		quarter := (int(now.Month())-1)/3 + 1
		return fmt.Sprintf("%d-Q%d", now.Year(), quarter)
	default:
		return now.Format("2006-01-02")
	}
}

func (mc *MetricCollector) getWidgetData(ctx context.Context, widget *DashboardWidget, tenantID string) (interface{}, error) {
	switch widget.Type {
	case "kpi":
		if widget.MetricID != "" {
			return mc.getLatestMetricValue(ctx, tenantID, widget.MetricID)
		}
	case "chart":
		if widget.MetricID != "" {
			// Get time series data for chart
			end := time.Now()
			start := end.AddDate(0, 0, -30) // Last 30 days
			return mc.GetMetricHistory(ctx, tenantID, widget.MetricID, start, end, "daily")
		}
	case "table":
		if widget.Query != "" {
			return mc.executeCustomQuery(ctx, widget.Query, tenantID)
		}
	}

	return nil, fmt.Errorf("unsupported widget type or missing configuration")
}

func (mc *MetricCollector) getLatestMetricValue(ctx context.Context, tenantID string, metricID string) (*MetricValue, error) {
	query := `
		SELECT id, tenant_id, metric_id, timestamp, value, string_value, labels, metadata, quality
		FROM vulnerability_metric_values 
		WHERE tenant_id = $1 AND metric_id = $2 
		ORDER BY timestamp DESC 
		LIMIT 1`

	row := mc.db.QueryRowContext(ctx, query, tenantID, metricID)

	var value MetricValue
	var labelsJSON, metadataJSON, qualityJSON []byte

	err := row.Scan(
		&value.ID, &value.TenantID, &value.MetricID, &value.Timestamp,
		&value.Value, &value.StringValue, &labelsJSON, &metadataJSON, &qualityJSON,
	)
	if err != nil {
		return nil, err
	}

	// Unmarshal JSON fields
	if len(labelsJSON) > 0 {
		json.Unmarshal(labelsJSON, &value.Labels)
	}
	if len(metadataJSON) > 0 {
		json.Unmarshal(metadataJSON, &value.Metadata)
	}
	if len(qualityJSON) > 0 {
		json.Unmarshal(qualityJSON, &value.Quality)
	}

	return &value, nil
}

func (mc *MetricCollector) executeCustomQuery(ctx context.Context, query string, tenantID string) (interface{}, error) {
	// Execute custom query for widget data
	// This would need proper query validation and sanitization
	rows, err := mc.db.QueryContext(ctx, query, tenantID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	// Convert rows to generic map structure
	columns, _ := rows.Columns()
	values := make([]map[string]interface{}, 0)

	for rows.Next() {
		columnValues := make([]interface{}, len(columns))
		columnPointers := make([]interface{}, len(columns))
		for i := range columnValues {
			columnPointers[i] = &columnValues[i]
		}

		if err := rows.Scan(columnPointers...); err != nil {
			return nil, err
		}

		row := make(map[string]interface{})
		for i, column := range columns {
			row[column] = columnValues[i]
		}
		values = append(values, row)
	}

	return values, nil
}

// Utility functions

func generateMetricDefinitionID() string {
	return fmt.Sprintf("metric_%d", time.Now().UnixNano())
}

func generateMetricValueID() string {
	return fmt.Sprintf("value_%d", time.Now().UnixNano())
}

func generateKPIValueID() string {
	return fmt.Sprintf("kpi_%d", time.Now().UnixNano())
}

// Default implementations for interfaces

type DefaultAlertManager struct {
	db     *sql.DB
	logger *zap.Logger
}

func NewDefaultAlertManager(db *sql.DB, logger *zap.Logger) *DefaultAlertManager {
	return &DefaultAlertManager{db: db, logger: logger}
}

func (am *DefaultAlertManager) EvaluateAlerts(ctx context.Context, metric *MetricValue) error {
	// Implementation for alert evaluation
	return nil
}

func (am *DefaultAlertManager) CreateAlert(ctx context.Context, alert *MetricAlert) error {
	// Implementation for alert creation
	return nil
}

func (am *DefaultAlertManager) UpdateAlert(ctx context.Context, alert *MetricAlert) error {
	// Implementation for alert update
	return nil
}

func (am *DefaultAlertManager) DeleteAlert(ctx context.Context, alertID string, tenantID string) error {
	// Implementation for alert deletion
	return nil
}

type DefaultDashboardManager struct {
	db     *sql.DB
	logger *zap.Logger
}

func NewDefaultDashboardManager(db *sql.DB, logger *zap.Logger) *DefaultDashboardManager {
	return &DefaultDashboardManager{db: db, logger: logger}
}

func (dm *DefaultDashboardManager) CreateDashboard(ctx context.Context, dashboard *MetricDashboard) error {
	// Implementation for dashboard creation
	return nil
}

func (dm *DefaultDashboardManager) UpdateDashboard(ctx context.Context, dashboard *MetricDashboard) error {
	// Implementation for dashboard update
	return nil
}

func (dm *DefaultDashboardManager) GetDashboard(ctx context.Context, dashboardID string, tenantID string) (*MetricDashboard, error) {
	// Implementation for dashboard retrieval
	return nil, nil
}

func (dm *DefaultDashboardManager) ListDashboards(ctx context.Context, tenantID string) ([]*MetricDashboard, error) {
	// Implementation for dashboard listing
	return nil, nil
}

// Placeholder calculator implementations

type VulnerabilityCountCalculator struct {
	db *sql.DB
}

func NewVulnerabilityCountCalculator(db *sql.DB) *VulnerabilityCountCalculator {
	return &VulnerabilityCountCalculator{db: db}
}

func (calc *VulnerabilityCountCalculator) Calculate(ctx context.Context, definition *MetricDefinition, params map[string]interface{}) (float64, error) {
	// Implementation for vulnerability count calculation
	return 0.0, nil
}

func (calc *VulnerabilityCountCalculator) ValidateDefinition(definition *MetricDefinition) error {
	// Implementation for definition validation
	return nil
}

type RemediationTimeCalculator struct {
	db *sql.DB
}

func NewRemediationTimeCalculator(db *sql.DB) *RemediationTimeCalculator {
	return &RemediationTimeCalculator{db: db}
}

func (calc *RemediationTimeCalculator) Calculate(ctx context.Context, definition *MetricDefinition, params map[string]interface{}) (float64, error) {
	// Implementation for remediation time calculation
	return 0.0, nil
}

func (calc *RemediationTimeCalculator) ValidateDefinition(definition *MetricDefinition) error {
	// Implementation for definition validation
	return nil
}

type RiskScoreCalculator struct {
	db *sql.DB
}

func NewRiskScoreCalculator(db *sql.DB) *RiskScoreCalculator {
	return &RiskScoreCalculator{db: db}
}

func (calc *RiskScoreCalculator) Calculate(ctx context.Context, definition *MetricDefinition, params map[string]interface{}) (float64, error) {
	// Implementation for risk score calculation
	return 0.0, nil
}

func (calc *RiskScoreCalculator) ValidateDefinition(definition *MetricDefinition) error {
	// Implementation for definition validation
	return nil
}

type ComplianceScoreCalculator struct {
	db *sql.DB
}

func NewComplianceScoreCalculator(db *sql.DB) *ComplianceScoreCalculator {
	return &ComplianceScoreCalculator{db: db}
}

func (calc *ComplianceScoreCalculator) Calculate(ctx context.Context, definition *MetricDefinition, params map[string]interface{}) (float64, error) {
	// Implementation for compliance score calculation
	return 0.0, nil
}

func (calc *ComplianceScoreCalculator) ValidateDefinition(definition *MetricDefinition) error {
	// Implementation for definition validation
	return nil
}

type SLAPerformanceCalculator struct {
	db *sql.DB
}

func NewSLAPerformanceCalculator(db *sql.DB) *SLAPerformanceCalculator {
	return &SLAPerformanceCalculator{db: db}
}

func (calc *SLAPerformanceCalculator) Calculate(ctx context.Context, definition *MetricDefinition, params map[string]interface{}) (float64, error) {
	// Implementation for SLA performance calculation
	return 0.0, nil
}

func (calc *SLAPerformanceCalculator) ValidateDefinition(definition *MetricDefinition) error {
	// Implementation for definition validation
	return nil
}

// Placeholder aggregator implementations

type TimeSeriesAggregator struct{}

func NewTimeSeriesAggregator() *TimeSeriesAggregator {
	return &TimeSeriesAggregator{}
}

func (agg *TimeSeriesAggregator) Aggregate(ctx context.Context, values []MetricValue, config *CalculationConfig) (*MetricValue, error) {
	// Implementation for time series aggregation
	return nil, nil
}

func (agg *TimeSeriesAggregator) SupportedTypes() []MetricType {
	return []MetricType{MetricCounter, MetricGauge, MetricHistogram}
}

type StatisticalAggregator struct{}

func NewStatisticalAggregator() *StatisticalAggregator {
	return &StatisticalAggregator{}
}

func (agg *StatisticalAggregator) Aggregate(ctx context.Context, values []MetricValue, config *CalculationConfig) (*MetricValue, error) {
	// Implementation for statistical aggregation
	return nil, nil
}

func (agg *StatisticalAggregator) SupportedTypes() []MetricType {
	return []MetricType{MetricGauge, MetricSummary}
}

// Placeholder validator implementations

type RangeValidator struct{}

func NewRangeValidator() *RangeValidator {
	return &RangeValidator{}
}

func (v *RangeValidator) Validate(ctx context.Context, value *MetricValue, definition *MetricDefinition) (*DataQuality, error) {
	// Implementation for range validation
	return &DataQuality{
		Score:        1.0,
		Completeness: 1.0,
		Accuracy:     1.0,
		Timeliness:   1.0,
		Source:       "validator",
		Validated:    true,
		ValidatedAt:  time.Now(),
	}, nil
}

func (v *RangeValidator) ValidateThresholds(value float64, thresholds map[string]interface{}) error {
	// Implementation for threshold validation
	return nil
}

type StatisticalValidator struct{}

func NewStatisticalValidator() *StatisticalValidator {
	return &StatisticalValidator{}
}

func (v *StatisticalValidator) Validate(ctx context.Context, value *MetricValue, definition *MetricDefinition) (*DataQuality, error) {
	// Implementation for statistical validation
	return &DataQuality{
		Score:        1.0,
		Completeness: 1.0,
		Accuracy:     1.0,
		Timeliness:   1.0,
		Source:       "statistical_validator",
		Validated:    true,
		ValidatedAt:  time.Now(),
	}, nil
}

func (v *StatisticalValidator) ValidateThresholds(value float64, thresholds map[string]interface{}) error {
	// Implementation for threshold validation
	return nil
}
