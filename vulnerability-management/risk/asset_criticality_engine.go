package risk

import (
	"context"
	"fmt"
	"log/slog"
	"math"
	"strings"
	"sync"
	"time"
)

// AssetCriticalityEngine evaluates the criticality of assets in the context of business operations
type AssetCriticalityEngine struct {
	config                 AssetCriticalityConfig
	logger                 *slog.Logger
	assetRepository        AssetRepository
	dependencyMap          *AssetDependencyMap
	businessValueCalculator *BusinessValueCalculator
	criticalityCalculator  *CriticalityCalculator
	networkAnalyzer        *NetworkCriticalityAnalyzer
	dataClassificationEngine *DataClassificationEngine
	statistics             AssetCriticalityStatistics
	cache                  AssetCriticalityCache
	mutex                  sync.RWMutex
}

// AssetCriticalityConfig defines configuration for asset criticality assessment
type AssetCriticalityConfig struct {
	OrganizationProfile    OrganizationProfile     `json:"organization_profile"`
	BusinessObjectives     []BusinessObjective     `json:"business_objectives"`
	
	// Criticality calculation settings
	EnableDependencyAnalysis    bool                   `json:"enable_dependency_analysis"`
	EnableNetworkAnalysis       bool                   `json:"enable_network_analysis"`
	EnableDataClassification    bool                   `json:"enable_data_classification"`
	EnableBusinessValueMapping  bool                   `json:"enable_business_value_mapping"`
	EnableComplianceMapping     bool                   `json:"enable_compliance_mapping"`
	
	// Calculation weights
	BusinessValueWeight         float64                `json:"business_value_weight"`
	DependencyWeight           float64                `json:"dependency_weight"`
	DataSensitivityWeight      float64                `json:"data_sensitivity_weight"`
	NetworkExposureWeight      float64                `json:"network_exposure_weight"`
	ComplianceScopeWeight      float64                `json:"compliance_scope_weight"`
	AvailabilityRequirementWeight float64             `json:"availability_requirement_weight"`
	
	// Asset classification rules
	AssetClassificationRules   []AssetClassificationRule `json:"asset_classification_rules"`
	CriticalityThresholds      CriticalityThresholds     `json:"criticality_thresholds"`
	BusinessFunctionMapping    map[string]float64        `json:"business_function_mapping"`
	
	// Time-based factors
	BusinessHours              []BusinessHourWindow      `json:"business_hours"`
	PeakUsagePeriods          []PeakUsagePeriod         `json:"peak_usage_periods"`
	MaintenanceWindows        []MaintenanceWindow       `json:"maintenance_windows"`
	
	// Performance settings
	CacheEnabled               bool                      `json:"cache_enabled"`
	CacheExpiration            time.Duration             `json:"cache_expiration"`
	CacheMaxSize               int                       `json:"cache_max_size"`
	AnalysisTimeout            time.Duration             `json:"analysis_timeout"`
	
	// iSECTECH specific
	CustomCriticalityModels    []CustomCriticalityModel  `json:"custom_criticality_models"`
	IndustrySpecificFactors    bool                      `json:"industry_specific_factors"`
	RegulatoryRequirements     []string                  `json:"regulatory_requirements"`
	AssetTierDefinitions       []AssetTierDefinition     `json:"asset_tier_definitions"`
}

// AssetCriticalityResult contains asset criticality assessment results
type AssetCriticalityResult struct {
	AssetID                    string                    `json:"asset_id"`
	CriticalityScore           float64                   `json:"criticality_score"`
	CriticalityLevel           string                    `json:"criticality_level"`
	AssetTier                  string                    `json:"asset_tier"`
	Confidence                 float64                   `json:"confidence"`
	
	// Component scores
	BusinessValueScore         float64                   `json:"business_value_score"`
	DependencyScore            float64                   `json:"dependency_score"`
	DataSensitivityScore       float64                   `json:"data_sensitivity_score"`
	NetworkExposureScore       float64                   `json:"network_exposure_score"`
	ComplianceScopeScore       float64                   `json:"compliance_scope_score"`
	AvailabilityRequirementScore float64                 `json:"availability_requirement_score"`
	
	// Detailed analysis
	BusinessValueAnalysis      *BusinessValueAnalysis    `json:"business_value_analysis,omitempty"`
	DependencyAnalysis         *DependencyAnalysis       `json:"dependency_analysis,omitempty"`
	DataClassificationAnalysis *DataClassificationAnalysis `json:"data_classification_analysis,omitempty"`
	NetworkAnalysis           *NetworkCriticalityAnalysis `json:"network_analysis,omitempty"`
	ComplianceAnalysis        *ComplianceAnalysis       `json:"compliance_analysis,omitempty"`
	
	// Asset characteristics
	AssetType                  string                    `json:"asset_type"`
	BusinessFunction           string                    `json:"business_function"`
	Owner                      string                    `json:"owner"`
	Environment                string                    `json:"environment"`
	DataClassification         string                    `json:"data_classification"`
	
	// Dependencies and relationships
	CriticalDependencies       []string                  `json:"critical_dependencies"`
	DependentAssets           []string                  `json:"dependent_assets"`
	BusinessProcesses         []string                  `json:"business_processes"`
	ServiceLevelAgreements    []SLARequirement          `json:"service_level_agreements"`
	
	// Risk factors
	CriticalityFactors        []CriticalityFactor       `json:"criticality_factors"`
	MitigatingFactors         []CriticalityMitigatingFactor `json:"mitigating_factors"`
	
	// Context and recommendations
	BusinessContext           AssetBusinessContext      `json:"business_context"`
	CriticalityJustification  []string                  `json:"criticality_justification"`
	ManagementRecommendations []AssetManagementRecommendation `json:"management_recommendations"`
	ProcessingTime            time.Duration             `json:"processing_time"`
	Timestamp                 time.Time                 `json:"timestamp"`
}

// Supporting data structures
type AssetClassificationRule struct {
	ID                string                 `json:"id"`
	Name              string                 `json:"name"`
	Conditions        []AssetCondition       `json:"conditions"`
	CriticalityBonus  float64               `json:"criticality_bonus"`
	AssetTier         string                `json:"asset_tier"`
	Enabled           bool                  `json:"enabled"`
	Priority          int                   `json:"priority"`
	Metadata          map[string]interface{} `json:"metadata"`
}

type AssetCondition struct {
	Field     string      `json:"field"`
	Operator  string      `json:"operator"`
	Value     interface{} `json:"value"`
	LogicalOp string      `json:"logical_op,omitempty"`
}

type CriticalityThresholds struct {
	Critical   float64 `json:"critical"`
	High       float64 `json:"high"`
	Medium     float64 `json:"medium"`
	Low        float64 `json:"low"`
}

type PeakUsagePeriod struct {
	Name        string        `json:"name"`
	StartTime   string        `json:"start_time"`
	EndTime     string        `json:"end_time"`
	TimeZone    string        `json:"timezone"`
	DaysOfWeek  []string      `json:"days_of_week"`
	Multiplier  float64       `json:"multiplier"`
	Description string        `json:"description"`
}

type MaintenanceWindow struct {
	Name        string        `json:"name"`
	StartTime   string        `json:"start_time"`
	EndTime     string        `json:"end_time"`
	TimeZone    string        `json:"timezone"`
	DaysOfWeek  []string      `json:"days_of_week"`
	AssetTypes  []string      `json:"asset_types"`
	Frequency   string        `json:"frequency"`
}

type CustomCriticalityModel struct {
	ID               string                 `json:"id"`
	Name             string                 `json:"name"`
	Description      string                 `json:"description"`
	Conditions       []AssetCondition       `json:"conditions"`
	Formula          string                 `json:"formula"`
	Weight           float64                `json:"weight"`
	Enabled          bool                   `json:"enabled"`
	AssetTypes       []string               `json:"asset_types"`
	BusinessFunctions []string              `json:"business_functions"`
	Metadata         map[string]interface{} `json:"metadata"`
}

type AssetTierDefinition struct {
	Tier            string                 `json:"tier"`
	Name            string                 `json:"name"`
	Description     string                 `json:"description"`
	MinScore        float64                `json:"min_score"`
	MaxScore        float64                `json:"max_score"`
	SLARequirements []SLARequirement       `json:"sla_requirements"`
	SecurityLevel   string                 `json:"security_level"`
	MonitoringLevel string                 `json:"monitoring_level"`
	BackupFrequency string                 `json:"backup_frequency"`
	Metadata        map[string]interface{} `json:"metadata"`
}

type BusinessValueAnalysis struct {
	DirectBusinessValue    float64                `json:"direct_business_value"`
	IndirectBusinessValue  float64                `json:"indirect_business_value"`
	RevenueContribution    float64                `json:"revenue_contribution"`
	CostOfDowntime         float64                `json:"cost_of_downtime"`
	BusinessProcessValue   float64                `json:"business_process_value"`
	CustomerImpactValue    float64                `json:"customer_impact_value"`
	CompetitiveAdvantageValue float64             `json:"competitive_advantage_value"`
	IntellectualPropertyValue float64             `json:"intellectual_property_value"`
	BrandValue             float64                `json:"brand_value"`
	BusinessValueFactors   []BusinessValueFactor  `json:"business_value_factors"`
	ConfidenceLevel        float64                `json:"confidence_level"`
}

type BusinessValueFactor struct {
	Factor      string                 `json:"factor"`
	Value       float64                `json:"value"`
	Weight      float64                `json:"weight"`
	Confidence  float64                `json:"confidence"`
	Source      string                 `json:"source"`
	Metadata    map[string]interface{} `json:"metadata"`
}

type DependencyAnalysis struct {
	UpstreamDependencies     []AssetDependency      `json:"upstream_dependencies"`
	DownstreamDependencies   []AssetDependency      `json:"downstream_dependencies"`
	CriticalDependencyPaths  []DependencyPath       `json:"critical_dependency_paths"`
	DependencyScore          float64                `json:"dependency_score"`
	SinglePointOfFailure     bool                   `json:"single_point_of_failure"`
	DependencyComplexity     float64                `json:"dependency_complexity"`
	DependencyRiskFactors    []DependencyRiskFactor `json:"dependency_risk_factors"`
	RedundancyLevel          float64                `json:"redundancy_level"`
	FailoverCapability       float64                `json:"failover_capability"`
	ConfidenceLevel          float64                `json:"confidence_level"`
}

type AssetDependency struct {
	AssetID          string                 `json:"asset_id"`
	DependencyType   string                 `json:"dependency_type"`
	CriticalityLevel string                 `json:"criticality_level"`
	FailureImpact    float64                `json:"failure_impact"`
	RedundancyExists bool                   `json:"redundancy_exists"`
	RPO              time.Duration          `json:"rpo"` // Recovery Point Objective
	RTO              time.Duration          `json:"rto"` // Recovery Time Objective
	Metadata         map[string]interface{} `json:"metadata"`
}

type DependencyPath struct {
	PathID           string             `json:"path_id"`
	AssetChain       []string           `json:"asset_chain"`
	CriticalityLevel string             `json:"criticality_level"`
	FailureImpact    float64            `json:"failure_impact"`
	PathLength       int                `json:"path_length"`
	RedundantPaths   int                `json:"redundant_paths"`
}

type DependencyRiskFactor struct {
	Factor      string                 `json:"factor"`
	Impact      float64                `json:"impact"`
	Likelihood  float64                `json:"likelihood"`
	Mitigation  string                 `json:"mitigation"`
	Metadata    map[string]interface{} `json:"metadata"`
}

type DataClassificationAnalysis struct {
	DataTypes                []DataTypeInfo         `json:"data_types"`
	SensitivityLevel         string                 `json:"sensitivity_level"`
	ComplianceRequirements   []string               `json:"compliance_requirements"`
	DataProtectionRequirements []string             `json:"data_protection_requirements"`
	PrivacyImpact           float64                `json:"privacy_impact"`
	RegulatoryImpact        float64                `json:"regulatory_impact"`
	DataVolumeScore         float64                `json:"data_volume_score"`
	DataQualityScore        float64                `json:"data_quality_score"`
	DataAccessibility       float64                `json:"data_accessibility"`
	DataRetentionScore      float64                `json:"data_retention_score"`
	ConfidenceLevel         float64                `json:"confidence_level"`
}

type DataTypeInfo struct {
	Type                   string                 `json:"type"`
	Classification         string                 `json:"classification"`
	Volume                 int64                  `json:"volume"`
	SensitivityScore       float64                `json:"sensitivity_score"`
	ComplianceRequirements []string               `json:"compliance_requirements"`
	ProtectionRequirements []string               `json:"protection_requirements"`
	Metadata               map[string]interface{} `json:"metadata"`
}

type NetworkCriticalityAnalysis struct {
	NetworkPosition         string                 `json:"network_position"`
	ExternalExposure        float64                `json:"external_exposure"`
	InternalConnectivity    float64                `json:"internal_connectivity"`
	NetworkSegmentation     float64                `json:"network_segmentation"`
	TrafficVolume          float64                `json:"traffic_volume"`
	NetworkDependencies    []NetworkDependency    `json:"network_dependencies"`
	SecurityControlsScore  float64                `json:"security_controls_score"`
	MonitoringCoverage     float64                `json:"monitoring_coverage"`
	NetworkRiskFactors     []NetworkRiskFactor    `json:"network_risk_factors"`
	ConfidenceLevel        float64                `json:"confidence_level"`
}

type NetworkDependency struct {
	DependentAsset    string                 `json:"dependent_asset"`
	ConnectionType    string                 `json:"connection_type"`
	TrafficType       string                 `json:"traffic_type"`
	Bandwidth         int64                  `json:"bandwidth"`
	Latency           time.Duration          `json:"latency"`
	Availability      float64                `json:"availability"`
	SecurityLevel     string                 `json:"security_level"`
	Redundancy        bool                   `json:"redundancy"`
	Metadata          map[string]interface{} `json:"metadata"`
}

type NetworkRiskFactor struct {
	Factor      string                 `json:"factor"`
	RiskLevel   string                 `json:"risk_level"`
	Impact      float64                `json:"impact"`
	Mitigation  string                 `json:"mitigation"`
	Metadata    map[string]interface{} `json:"metadata"`
}

type ComplianceAnalysis struct {
	ApplicableStandards    []string               `json:"applicable_standards"`
	ComplianceScore        float64                `json:"compliance_score"`
	ControlRequirements    []ControlRequirement   `json:"control_requirements"`
	AuditRequirements      []AuditRequirement     `json:"audit_requirements"`
	RegulatoryRisk         float64                `json:"regulatory_risk"`
	ComplianceGaps         []ComplianceGap        `json:"compliance_gaps"`
	RemediationRequirements []string              `json:"remediation_requirements"`
	ConfidenceLevel        float64                `json:"confidence_level"`
}

type ControlRequirement struct {
	Standard       string                 `json:"standard"`
	Control        string                 `json:"control"`
	Requirement    string                 `json:"requirement"`
	Implementation string                 `json:"implementation"`
	TestingFrequency string               `json:"testing_frequency"`
	Criticality    string                 `json:"criticality"`
	Status         string                 `json:"status"`
	Metadata       map[string]interface{} `json:"metadata"`
}

type AuditRequirement struct {
	Type           string                 `json:"type"`
	Frequency      string                 `json:"frequency"`
	Scope          string                 `json:"scope"`
	Requirements   []string               `json:"requirements"`
	LastAudit      *time.Time             `json:"last_audit,omitempty"`
	NextAudit      *time.Time             `json:"next_audit,omitempty"`
	AuditorType    string                 `json:"auditor_type"`
	Metadata       map[string]interface{} `json:"metadata"`
}

type ComplianceGap struct {
	Standard       string                 `json:"standard"`
	Control        string                 `json:"control"`
	GapDescription string                 `json:"gap_description"`
	RiskLevel      string                 `json:"risk_level"`
	Priority       string                 `json:"priority"`
	Remediation    []string               `json:"remediation"`
	Timeline       string                 `json:"timeline"`
	Metadata       map[string]interface{} `json:"metadata"`
}

type CriticalityFactor struct {
	Type        string                 `json:"type"`
	Category    string                 `json:"category"`
	Description string                 `json:"description"`
	Impact      float64                `json:"impact"`
	Weight      float64                `json:"weight"`
	Confidence  float64                `json:"confidence"`
	Source      string                 `json:"source"`
	Metadata    map[string]interface{} `json:"metadata"`
}

type CriticalityMitigatingFactor struct {
	Type           string                 `json:"type"`
	Description    string                 `json:"description"`
	Effectiveness  float64                `json:"effectiveness"`
	Coverage       float64                `json:"coverage"`
	Confidence     float64                `json:"confidence"`
	Implementation string                 `json:"implementation"`
	Metadata       map[string]interface{} `json:"metadata"`
}

type AssetBusinessContext struct {
	BusinessOwner          string                 `json:"business_owner"`
	TechnicalOwner         string                 `json:"technical_owner"`
	BusinessUnit           string                 `json:"business_unit"`
	CostCenter             string                 `json:"cost_center"`
	ProjectAssociation     []string               `json:"project_association"`
	LifecycleStage         string                 `json:"lifecycle_stage"`
	PlannedRetirement      *time.Time             `json:"planned_retirement,omitempty"`
	InvestmentValue        float64                `json:"investment_value"`
	OperationalCost        float64                `json:"operational_cost"`
	MaintenanceCost        float64                `json:"maintenance_cost"`
	BusinessCriticality    string                 `json:"business_criticality"`
	StrategicImportance    string                 `json:"strategic_importance"`
	Metadata               map[string]interface{} `json:"metadata"`
}

type AssetManagementRecommendation struct {
	Type            string                 `json:"type"`
	Priority        string                 `json:"priority"`
	Recommendation  string                 `json:"recommendation"`
	Justification   string                 `json:"justification"`
	Implementation  []string               `json:"implementation"`
	Timeline        string                 `json:"timeline"`
	CostEstimate    float64                `json:"cost_estimate"`
	RiskReduction   float64                `json:"risk_reduction"`
	BusinessValue   float64                `json:"business_value"`
	Stakeholders    []string               `json:"stakeholders"`
	Dependencies    []string               `json:"dependencies"`
	Metadata        map[string]interface{} `json:"metadata"`
}

type AssetCriticalityStatistics struct {
	TotalAssessments         int64                    `json:"total_assessments"`
	AverageCriticalityScore  float64                  `json:"average_criticality_score"`
	CriticalityDistribution  map[string]int64         `json:"criticality_distribution"`
	AssetTierDistribution    map[string]int64         `json:"asset_tier_distribution"`
	ProcessingTime           float64                  `json:"processing_time"`
	ComponentPerformance     map[string]ComponentStat `json:"component_performance"`
	CacheHitRate             float64                  `json:"cache_hit_rate"`
	LastUpdate               time.Time                `json:"last_update"`
}

type AssetCriticalityCache struct {
	cache     map[string]*AssetCriticalityResult
	ttl       map[string]time.Time
	mutex     sync.RWMutex
	maxSize   int
	enabled   bool
	hitCount  int64
	missCount int64
}

// Supporting engines and analyzers
type AssetDependencyMap struct {
	dependencies map[string][]AssetDependency
	logger       *slog.Logger
	mutex        sync.RWMutex
}

type BusinessValueCalculator struct {
	config BusinessImpactConfig
	logger *slog.Logger
}

type CriticalityCalculator struct {
	config AssetCriticalityConfig
	logger *slog.Logger
}

type NetworkCriticalityAnalyzer struct {
	config AssetCriticalityConfig
	logger *slog.Logger
}

type DataClassificationEngine struct {
	config AssetCriticalityConfig
	logger *slog.Logger
}

// NewAssetCriticalityEngine creates a new asset criticality engine
func NewAssetCriticalityEngine(config AssetCriticalityConfig, logger *slog.Logger) (*AssetCriticalityEngine, error) {
	if logger == nil {
		logger = slog.Default()
	}

	// Initialize cache
	cache := AssetCriticalityCache{
		cache:   make(map[string]*AssetCriticalityResult),
		ttl:     make(map[string]time.Time),
		maxSize: config.CacheMaxSize,
		enabled: config.CacheEnabled,
	}

	engine := &AssetCriticalityEngine{
		config: config,
		logger: logger,
		cache:  cache,
		statistics: AssetCriticalityStatistics{
			CriticalityDistribution: make(map[string]int64),
			AssetTierDistribution:   make(map[string]int64),
			ComponentPerformance:    make(map[string]ComponentStat),
			LastUpdate:              time.Now(),
		},
	}

	// Initialize sub-components
	if err := engine.initializeComponents(); err != nil {
		return nil, fmt.Errorf("failed to initialize components: %w", err)
	}

	return engine, nil
}

// AssessAssetCriticality performs comprehensive asset criticality assessment
func (ace *AssetCriticalityEngine) AssessAssetCriticality(ctx context.Context, vuln *Vulnerability) (*AssetCriticalityResult, error) {
	startTime := time.Now()

	// Check cache first
	if ace.config.CacheEnabled {
		if cached := ace.getCachedResult(vuln.AssetID); cached != nil {
			ace.updateCacheHitStats(true)
			return cached, nil
		}
		ace.updateCacheHitStats(false)
	}

	// Create analysis context
	analysisCtx, cancel := context.WithTimeout(ctx, ace.config.AnalysisTimeout)
	defer cancel()

	// Get detailed asset information
	asset, err := ace.getDetailedAssetInfo(analysisCtx, vuln.AssetID)
	if err != nil {
		ace.logger.Warn("Failed to get detailed asset info",
			"asset_id", vuln.AssetID,
			"error", err)
		// Use basic asset information derived from vulnerability
		asset = ace.createBasicAssetInfo(vuln)
	}

	// Initialize result
	result := &AssetCriticalityResult{
		AssetID:                   vuln.AssetID,
		AssetType:                asset.Type,
		BusinessFunction:          asset.BusinessFunction,
		Owner:                     asset.Owner,
		Environment:              asset.Environment,
		DataClassification:       asset.DataClassification,
		CriticalDependencies:     make([]string, 0),
		DependentAssets:          make([]string, 0),
		BusinessProcesses:        asset.BusinessProcesses,
		ServiceLevelAgreements:   make([]SLARequirement, 0),
		CriticalityFactors:       make([]CriticalityFactor, 0),
		MitigatingFactors:        make([]CriticalityMitigatingFactor, 0),
		CriticalityJustification: make([]string, 0),
		ManagementRecommendations: make([]AssetManagementRecommendation, 0),
		Timestamp:                time.Now(),
	}

	// Perform business value analysis
	if ace.config.EnableBusinessValueMapping {
		businessAnalysis, err := ace.performBusinessValueAnalysis(analysisCtx, asset, vuln)
		if err != nil {
			ace.logger.Warn("Business value analysis failed", "error", err)
		} else {
			result.BusinessValueAnalysis = businessAnalysis
			result.BusinessValueScore = businessAnalysis.DirectBusinessValue
		}
	}

	// Perform dependency analysis
	if ace.config.EnableDependencyAnalysis {
		dependencyAnalysis, err := ace.performDependencyAnalysis(analysisCtx, asset, vuln)
		if err != nil {
			ace.logger.Warn("Dependency analysis failed", "error", err)
		} else {
			result.DependencyAnalysis = dependencyAnalysis
			result.DependencyScore = dependencyAnalysis.DependencyScore
			result.CriticalDependencies = ace.extractCriticalDependencies(dependencyAnalysis)
			result.DependentAssets = ace.extractDependentAssets(dependencyAnalysis)
		}
	}

	// Perform data classification analysis
	if ace.config.EnableDataClassification {
		dataAnalysis, err := ace.performDataClassificationAnalysis(analysisCtx, asset, vuln)
		if err != nil {
			ace.logger.Warn("Data classification analysis failed", "error", err)
		} else {
			result.DataClassificationAnalysis = dataAnalysis
			result.DataSensitivityScore = ace.calculateDataSensitivityScore(dataAnalysis)
			result.DataClassification = dataAnalysis.SensitivityLevel
		}
	}

	// Perform network analysis
	if ace.config.EnableNetworkAnalysis {
		networkAnalysis, err := ace.performNetworkAnalysis(analysisCtx, asset, vuln)
		if err != nil {
			ace.logger.Warn("Network analysis failed", "error", err)
		} else {
			result.NetworkAnalysis = networkAnalysis
			result.NetworkExposureScore = ace.calculateNetworkExposureScore(networkAnalysis)
		}
	}

	// Perform compliance analysis
	if ace.config.EnableComplianceMapping {
		complianceAnalysis, err := ace.performComplianceAnalysis(analysisCtx, asset, vuln)
		if err != nil {
			ace.logger.Warn("Compliance analysis failed", "error", err)
		} else {
			result.ComplianceAnalysis = complianceAnalysis
			result.ComplianceScopeScore = complianceAnalysis.ComplianceScore
		}
	}

	// Calculate availability requirement score
	result.AvailabilityRequirementScore = ace.calculateAvailabilityRequirementScore(asset, result)

	// Apply custom criticality models
	ace.applyCustomCriticalityModels(result, asset, vuln)

	// Calculate overall criticality score
	result.CriticalityScore = ace.calculateOverallCriticalityScore(result, asset)
	result.CriticalityLevel = ace.determineCriticalityLevel(result.CriticalityScore)
	result.AssetTier = ace.determineAssetTier(result.CriticalityScore)
	result.Confidence = ace.calculateConfidence(result)

	// Generate business context
	result.BusinessContext = ace.generateBusinessContext(asset, result)

	// Generate criticality factors
	ace.generateCriticalityFactors(result, asset, vuln)

	// Generate mitigating factors
	ace.generateMitigatingFactors(result, asset, vuln)

	// Generate criticality justification
	ace.generateCriticalityJustification(result, asset, vuln)

	// Generate management recommendations
	ace.generateManagementRecommendations(result, asset, vuln)

	result.ProcessingTime = time.Since(startTime)

	// Cache result
	if ace.config.CacheEnabled {
		ace.cacheResult(vuln.AssetID, result)
	}

	// Update statistics
	ace.updateStatistics(result)

	ace.logger.Info("Asset criticality assessment completed",
		"asset_id", vuln.AssetID,
		"criticality_score", result.CriticalityScore,
		"criticality_level", result.CriticalityLevel,
		"asset_tier", result.AssetTier,
		"processing_time", result.ProcessingTime)

	return result, nil
}

// initializeComponents initializes sub-components
func (ace *AssetCriticalityEngine) initializeComponents() error {
	// Initialize dependency map
	ace.dependencyMap = &AssetDependencyMap{
		dependencies: make(map[string][]AssetDependency),
		logger:       ace.logger,
	}

	// Initialize business value calculator
	ace.businessValueCalculator = &BusinessValueCalculator{
		config: BusinessImpactConfig{}, // Would be populated from config
		logger: ace.logger,
	}

	// Initialize criticality calculator
	ace.criticalityCalculator = &CriticalityCalculator{
		config: ace.config,
		logger: ace.logger,
	}

	// Initialize network analyzer
	ace.networkAnalyzer = &NetworkCriticalityAnalyzer{
		config: ace.config,
		logger: ace.logger,
	}

	// Initialize data classification engine
	ace.dataClassificationEngine = &DataClassificationEngine{
		config: ace.config,
		logger: ace.logger,
	}

	return nil
}

// getDetailedAssetInfo retrieves comprehensive asset information
func (ace *AssetCriticalityEngine) getDetailedAssetInfo(ctx context.Context, assetID string) (*Asset, error) {
	if ace.assetRepository != nil {
		return ace.assetRepository.GetAsset(ctx, assetID)
	}

	// Create comprehensive asset info from ID analysis
	return ace.createDetailedAssetInfo(assetID), nil
}

// createBasicAssetInfo creates basic asset info from vulnerability
func (ace *AssetCriticalityEngine) createBasicAssetInfo(vuln *Vulnerability) *Asset {
	return &Asset{
		ID:            vuln.AssetID,
		Name:          fmt.Sprintf("Asset_%s", vuln.AssetID),
		Type:          ace.inferAssetType(vuln.AssetID),
		BusinessValue: ace.inferBusinessValue(vuln.AssetID),
		Criticality:   "medium",
		Environment:   ace.inferEnvironment(vuln.AssetID),
		Dependencies:  make([]string, 0),
		BusinessProcesses: make([]string, 0),
		ComplianceScope: make([]string, 0),
		Metadata: map[string]interface{}{
			"inferred": true,
			"source":   "vulnerability_context",
		},
	}
}

// createDetailedAssetInfo creates detailed asset info from analysis
func (ace *AssetCriticalityEngine) createDetailedAssetInfo(assetID string) *Asset {
	baseAsset := ace.createBasicAssetInfo(&Vulnerability{AssetID: assetID})
	
	// Enhanced analysis based on asset ID patterns
	baseAsset.BusinessFunction = ace.inferBusinessFunction(assetID, baseAsset.Type)
	baseAsset.DataClassification = ace.inferDataClassification(assetID, baseAsset.Type)
	baseAsset.Owner = ace.inferOwner(assetID, baseAsset.Type)
	
	// Add business processes based on asset type
	baseAsset.BusinessProcesses = ace.inferBusinessProcesses(assetID, baseAsset.Type)
	
	// Add compliance scope based on asset characteristics
	baseAsset.ComplianceScope = ace.inferComplianceScope(assetID, baseAsset.Type, baseAsset.DataClassification)
	
	return baseAsset
}

// Asset inference methods
func (ace *AssetCriticalityEngine) inferAssetType(assetID string) string {
	lowerID := strings.ToLower(assetID)
	
	typePatterns := map[string]string{
		"db":         "database",
		"database":   "database",
		"sql":        "database",
		"mongo":      "database",
		"redis":      "cache_server",
		"cache":      "cache_server",
		"web":        "web_server",
		"www":        "web_server",
		"nginx":      "web_server",
		"apache":     "web_server",
		"api":        "api_server",
		"service":    "api_server",
		"rest":       "api_server",
		"graphql":    "api_server",
		"load":       "load_balancer",
		"lb":         "load_balancer",
		"proxy":      "proxy_server",
		"auth":       "authentication_server",
		"ldap":       "authentication_server",
		"ad":         "authentication_server",
		"file":       "file_server",
		"storage":    "file_server",
		"nfs":        "file_server",
		"mail":       "mail_server",
		"email":      "mail_server",
		"smtp":       "mail_server",
		"dns":        "dns_server",
		"monitor":    "monitoring_server",
		"log":        "logging_server",
		"backup":     "backup_server",
		"firewall":   "security_appliance",
		"vpn":        "security_appliance",
		"switch":     "network_device",
		"router":     "network_device",
	}
	
	for pattern, assetType := range typePatterns {
		if strings.Contains(lowerID, pattern) {
			return assetType
		}
	}
	
	return "server"
}

func (ace *AssetCriticalityEngine) inferBusinessValue(assetID string) float64 {
	assetType := ace.inferAssetType(assetID)
	lowerID := strings.ToLower(assetID)
	
	// Base values by asset type
	typeValues := map[string]float64{
		"database":              8.5,
		"authentication_server": 8.0,
		"api_server":           7.5,
		"web_server":           7.0,
		"load_balancer":        6.5,
		"security_appliance":   6.5,
		"mail_server":          6.0,
		"dns_server":           6.0,
		"file_server":          5.5,
		"cache_server":         5.5,
		"monitoring_server":    5.0,
		"logging_server":       4.5,
		"backup_server":        4.0,
		"network_device":       5.5,
		"proxy_server":         5.0,
		"server":               4.0,
	}
	
	baseValue := typeValues[assetType]
	
	// Adjust based on naming patterns
	if strings.Contains(lowerID, "prod") || strings.Contains(lowerID, "production") {
		baseValue += 1.5
	}
	if strings.Contains(lowerID, "critical") || strings.Contains(lowerID, "core") {
		baseValue += 2.0
	}
	if strings.Contains(lowerID, "main") || strings.Contains(lowerID, "primary") {
		baseValue += 1.0
	}
	if strings.Contains(lowerID, "master") {
		baseValue += 1.5
	}
	if strings.Contains(lowerID, "backup") || strings.Contains(lowerID, "secondary") {
		baseValue -= 1.0
	}
	if strings.Contains(lowerID, "test") || strings.Contains(lowerID, "dev") || strings.Contains(lowerID, "staging") {
		baseValue -= 2.0
	}
	
	// Ensure value is within bounds
	return math.Max(1.0, math.Min(10.0, baseValue))
}

func (ace *AssetCriticalityEngine) inferEnvironment(assetID string) string {
	lowerID := strings.ToLower(assetID)
	
	if strings.Contains(lowerID, "prod") || strings.Contains(lowerID, "production") {
		return "production"
	}
	if strings.Contains(lowerID, "stage") || strings.Contains(lowerID, "staging") {
		return "staging"
	}
	if strings.Contains(lowerID, "test") || strings.Contains(lowerID, "testing") {
		return "testing"
	}
	if strings.Contains(lowerID, "dev") || strings.Contains(lowerID, "development") {
		return "development"
	}
	if strings.Contains(lowerID, "demo") {
		return "demo"
	}
	
	return "production" // Default assumption for unknown
}

func (ace *AssetCriticalityEngine) inferBusinessFunction(assetID, assetType string) string {
	lowerID := strings.ToLower(assetID)
	
	// Function patterns
	functionPatterns := map[string]string{
		"crm":        "customer_relationship_management",
		"erp":        "enterprise_resource_planning",
		"hr":         "human_resources",
		"finance":    "financial_systems",
		"accounting": "financial_systems",
		"billing":    "billing_systems",
		"payment":    "payment_processing",
		"inventory":  "inventory_management",
		"supply":     "supply_chain",
		"logistics":  "logistics",
		"support":    "customer_support",
		"helpdesk":   "customer_support",
		"sales":      "sales_systems",
		"marketing":  "marketing_systems",
		"analytics":  "business_intelligence",
		"reporting":  "business_intelligence",
		"security":   "security_services",
		"monitor":    "monitoring_services",
		"backup":     "backup_services",
	}
	
	for pattern, function := range functionPatterns {
		if strings.Contains(lowerID, pattern) {
			return function
		}
	}
	
	// Default based on asset type
	switch assetType {
	case "database":
		return "data_management"
	case "web_server":
		return "web_services"
	case "api_server":
		return "application_services"
	case "authentication_server":
		return "identity_management"
	case "mail_server":
		return "communication_services"
	case "file_server":
		return "file_services"
	default:
		return "infrastructure_services"
	}
}

func (ace *AssetCriticalityEngine) inferDataClassification(assetID, assetType string) string {
	lowerID := strings.ToLower(assetID)
	
	// High sensitivity indicators
	if strings.Contains(lowerID, "finance") || strings.Contains(lowerID, "payment") ||
	   strings.Contains(lowerID, "hr") || strings.Contains(lowerID, "personnel") ||
	   strings.Contains(lowerID, "customer") || strings.Contains(lowerID, "personal") {
		return "confidential"
	}
	
	// Medium sensitivity indicators
	if strings.Contains(lowerID, "internal") || strings.Contains(lowerID, "business") ||
	   assetType == "database" || assetType == "authentication_server" {
		return "internal"
	}
	
	// Low sensitivity indicators
	if strings.Contains(lowerID, "public") || strings.Contains(lowerID, "marketing") ||
	   assetType == "web_server" {
		return "public"
	}
	
	return "internal" // Default classification
}

func (ace *AssetCriticalityEngine) inferOwner(assetID, assetType string) string {
	lowerID := strings.ToLower(assetID)
	
	// Owner patterns
	ownerPatterns := map[string]string{
		"finance":   "finance_team",
		"hr":        "hr_team",
		"sales":     "sales_team",
		"marketing": "marketing_team",
		"support":   "support_team",
		"security":  "security_team",
		"it":        "it_operations",
		"ops":       "it_operations",
		"dev":       "development_team",
		"api":       "development_team",
		"web":       "development_team",
	}
	
	for pattern, owner := range ownerPatterns {
		if strings.Contains(lowerID, pattern) {
			return owner
		}
	}
	
	// Default based on asset type
	switch assetType {
	case "database", "authentication_server":
		return "it_operations"
	case "web_server", "api_server":
		return "development_team"
	case "security_appliance":
		return "security_team"
	case "network_device":
		return "network_team"
	default:
		return "it_operations"
	}
}

func (ace *AssetCriticalityEngine) inferBusinessProcesses(assetID, assetType string) []string {
	processes := make([]string, 0)
	lowerID := strings.ToLower(assetID)
	
	// Process associations
	if strings.Contains(lowerID, "customer") || strings.Contains(lowerID, "crm") {
		processes = append(processes, "customer_management")
	}
	if strings.Contains(lowerID, "order") || strings.Contains(lowerID, "sales") {
		processes = append(processes, "order_processing")
	}
	if strings.Contains(lowerID, "payment") || strings.Contains(lowerID, "billing") {
		processes = append(processes, "payment_processing")
	}
	if strings.Contains(lowerID, "inventory") || strings.Contains(lowerID, "stock") {
		processes = append(processes, "inventory_management")
	}
	if strings.Contains(lowerID, "hr") || strings.Contains(lowerID, "employee") {
		processes = append(processes, "human_resources")
	}
	if strings.Contains(lowerID, "finance") || strings.Contains(lowerID, "accounting") {
		processes = append(processes, "financial_management")
	}
	
	// Default processes based on asset type
	switch assetType {
	case "web_server":
		if len(processes) == 0 {
			processes = append(processes, "customer_interaction")
		}
	case "database":
		if len(processes) == 0 {
			processes = append(processes, "data_management")
		}
	case "authentication_server":
		processes = append(processes, "identity_management")
	case "mail_server":
		processes = append(processes, "communication")
	}
	
	if len(processes) == 0 {
		processes = append(processes, "general_operations")
	}
	
	return processes
}

func (ace *AssetCriticalityEngine) inferComplianceScope(assetID, assetType, dataClassification string) []string {
	scope := make([]string, 0)
	lowerID := strings.ToLower(assetID)
	
	// High-sensitivity data requires multiple compliance frameworks
	if dataClassification == "confidential" {
		scope = append(scope, "SOX", "PCI-DSS", "GDPR", "ISO27001")
	} else if dataClassification == "internal" {
		scope = append(scope, "ISO27001", "SOC2")
	}
	
	// Specific compliance based on function
	if strings.Contains(lowerID, "payment") || strings.Contains(lowerID, "card") {
		scope = append(scope, "PCI-DSS")
	}
	if strings.Contains(lowerID, "health") || strings.Contains(lowerID, "medical") {
		scope = append(scope, "HIPAA")
	}
	if strings.Contains(lowerID, "finance") || strings.Contains(lowerID, "financial") {
		scope = append(scope, "SOX", "GLBA")
	}
	if strings.Contains(lowerID, "personal") || strings.Contains(lowerID, "customer") {
		scope = append(scope, "GDPR", "CCPA")
	}
	
	// Asset type specific compliance
	if assetType == "database" || assetType == "authentication_server" {
		if !ace.containsString(scope, "ISO27001") {
			scope = append(scope, "ISO27001")
		}
	}
	
	return scope
}

// Analysis methods
func (ace *AssetCriticalityEngine) performBusinessValueAnalysis(ctx context.Context, asset *Asset, vuln *Vulnerability) (*BusinessValueAnalysis, error) {
	analysis := &BusinessValueAnalysis{
		BusinessValueFactors: make([]BusinessValueFactor, 0),
		ConfidenceLevel:      0.7,
	}

	// Calculate direct business value
	analysis.DirectBusinessValue = asset.BusinessValue

	// Calculate indirect business value based on dependencies
	analysis.IndirectBusinessValue = ace.calculateIndirectBusinessValue(asset)

	// Calculate revenue contribution
	analysis.RevenueContribution = ace.calculateRevenueContribution(asset)

	// Calculate cost of downtime
	analysis.CostOfDowntime = ace.calculateCostOfDowntime(asset)

	// Calculate business process value
	analysis.BusinessProcessValue = ace.calculateBusinessProcessValue(asset)

	// Calculate customer impact value
	analysis.CustomerImpactValue = asset.CustomerImpact

	// Calculate competitive advantage value
	analysis.CompetitiveAdvantageValue = ace.calculateCompetitiveAdvantageValue(asset)

	// Calculate intellectual property value
	analysis.IntellectualPropertyValue = ace.calculateIntellectualPropertyValue(asset)

	// Calculate brand value impact
	analysis.BrandValue = ace.calculateBrandValue(asset)

	// Generate business value factors
	ace.generateBusinessValueFactors(analysis, asset)

	return analysis, nil
}

func (ace *AssetCriticalityEngine) performDependencyAnalysis(ctx context.Context, asset *Asset, vuln *Vulnerability) (*DependencyAnalysis, error) {
	analysis := &DependencyAnalysis{
		UpstreamDependencies:   make([]AssetDependency, 0),
		DownstreamDependencies: make([]AssetDependency, 0),
		CriticalDependencyPaths: make([]DependencyPath, 0),
		DependencyRiskFactors:  make([]DependencyRiskFactor, 0),
		ConfidenceLevel:        0.6,
	}

	// Analyze upstream dependencies (assets this asset depends on)
	analysis.UpstreamDependencies = ace.getUpstreamDependencies(asset)

	// Analyze downstream dependencies (assets that depend on this asset)
	analysis.DownstreamDependencies = ace.getDownstreamDependencies(asset)

	// Find critical dependency paths
	analysis.CriticalDependencyPaths = ace.findCriticalDependencyPaths(asset, analysis)

	// Calculate dependency score
	analysis.DependencyScore = ace.calculateDependencyScore(analysis)

	// Check if single point of failure
	analysis.SinglePointOfFailure = ace.isSinglePointOfFailure(asset, analysis)

	// Calculate dependency complexity
	analysis.DependencyComplexity = ace.calculateDependencyComplexity(analysis)

	// Generate dependency risk factors
	ace.generateDependencyRiskFactors(analysis, asset)

	// Calculate redundancy level
	analysis.RedundancyLevel = ace.calculateRedundancyLevel(asset, analysis)

	// Calculate failover capability
	analysis.FailoverCapability = ace.calculateFailoverCapability(asset, analysis)

	return analysis, nil
}

func (ace *AssetCriticalityEngine) performDataClassificationAnalysis(ctx context.Context, asset *Asset, vuln *Vulnerability) (*DataClassificationAnalysis, error) {
	analysis := &DataClassificationAnalysis{
		DataTypes:                  make([]DataTypeInfo, 0),
		SensitivityLevel:          asset.DataClassification,
		ComplianceRequirements:    asset.ComplianceScope,
		DataProtectionRequirements: make([]string, 0),
		ConfidenceLevel:           0.8,
	}

	// Analyze data types
	analysis.DataTypes = ace.analyzeDataTypes(asset)

	// Calculate privacy impact
	analysis.PrivacyImpact = ace.calculatePrivacyImpact(asset, analysis)

	// Calculate regulatory impact
	analysis.RegulatoryImpact = ace.calculateRegulatoryImpact(asset, analysis)

	// Calculate data volume score
	analysis.DataVolumeScore = ace.calculateDataVolumeScore(asset, analysis)

	// Calculate data quality score
	analysis.DataQualityScore = ace.calculateDataQualityScore(asset, analysis)

	// Calculate data accessibility
	analysis.DataAccessibility = ace.calculateDataAccessibility(asset, analysis)

	// Calculate data retention score
	analysis.DataRetentionScore = ace.calculateDataRetentionScore(asset, analysis)

	// Generate data protection requirements
	analysis.DataProtectionRequirements = ace.generateDataProtectionRequirements(asset, analysis)

	return analysis, nil
}

func (ace *AssetCriticalityEngine) performNetworkAnalysis(ctx context.Context, asset *Asset, vuln *Vulnerability) (*NetworkCriticalityAnalysis, error) {
	analysis := &NetworkCriticalityAnalysis{
		NetworkDependencies: make([]NetworkDependency, 0),
		NetworkRiskFactors:  make([]NetworkRiskFactor, 0),
		ConfidenceLevel:     0.7,
	}

	// Determine network position
	analysis.NetworkPosition = ace.determineNetworkPosition(asset, vuln)

	// Calculate external exposure
	analysis.ExternalExposure = ace.calculateExternalExposure(asset, vuln)

	// Calculate internal connectivity
	analysis.InternalConnectivity = ace.calculateInternalConnectivity(asset, vuln)

	// Calculate network segmentation score
	analysis.NetworkSegmentation = ace.calculateNetworkSegmentation(asset, vuln)

	// Calculate traffic volume
	analysis.TrafficVolume = ace.calculateTrafficVolume(asset, vuln)

	// Analyze network dependencies
	analysis.NetworkDependencies = ace.analyzeNetworkDependencies(asset, vuln)

	// Calculate security controls score
	analysis.SecurityControlsScore = ace.calculateSecurityControlsScore(asset, vuln)

	// Calculate monitoring coverage
	analysis.MonitoringCoverage = ace.calculateMonitoringCoverage(asset, vuln)

	// Generate network risk factors
	ace.generateNetworkRiskFactors(analysis, asset, vuln)

	return analysis, nil
}

func (ace *AssetCriticalityEngine) performComplianceAnalysis(ctx context.Context, asset *Asset, vuln *Vulnerability) (*ComplianceAnalysis, error) {
	analysis := &ComplianceAnalysis{
		ApplicableStandards:     asset.ComplianceScope,
		ControlRequirements:     make([]ControlRequirement, 0),
		AuditRequirements:      make([]AuditRequirement, 0),
		ComplianceGaps:         make([]ComplianceGap, 0),
		RemediationRequirements: make([]string, 0),
		ConfidenceLevel:        0.8,
	}

	// Calculate compliance score
	analysis.ComplianceScore = ace.calculateComplianceScore(asset)

	// Generate control requirements
	analysis.ControlRequirements = ace.generateControlRequirements(asset, analysis)

	// Generate audit requirements
	analysis.AuditRequirements = ace.generateAuditRequirements(asset, analysis)

	// Calculate regulatory risk
	analysis.RegulatoryRisk = ace.calculateRegulatoryRisk(asset, analysis)

	// Identify compliance gaps
	analysis.ComplianceGaps = ace.identifyComplianceGaps(asset, analysis)

	// Generate remediation requirements
	analysis.RemediationRequirements = ace.generateComplianceRemediationRequirements(asset, analysis)

	return analysis, nil
}

// Calculate overall criticality score using weighted components
func (ace *AssetCriticalityEngine) calculateOverallCriticalityScore(result *AssetCriticalityResult, asset *Asset) float64 {
	score := 0.0
	totalWeight := 0.0

	// Business value component
	if result.BusinessValueScore > 0 {
		score += result.BusinessValueScore * ace.config.BusinessValueWeight
		totalWeight += ace.config.BusinessValueWeight
	}

	// Dependency component
	if result.DependencyScore > 0 {
		score += result.DependencyScore * ace.config.DependencyWeight
		totalWeight += ace.config.DependencyWeight
	}

	// Data sensitivity component
	if result.DataSensitivityScore > 0 {
		score += result.DataSensitivityScore * ace.config.DataSensitivityWeight
		totalWeight += ace.config.DataSensitivityWeight
	}

	// Network exposure component
	if result.NetworkExposureScore > 0 {
		score += result.NetworkExposureScore * ace.config.NetworkExposureWeight
		totalWeight += ace.config.NetworkExposureWeight
	}

	// Compliance scope component
	if result.ComplianceScopeScore > 0 {
		score += result.ComplianceScopeScore * ace.config.ComplianceScopeWeight
		totalWeight += ace.config.ComplianceScopeWeight
	}

	// Availability requirement component
	if result.AvailabilityRequirementScore > 0 {
		score += result.AvailabilityRequirementScore * ace.config.AvailabilityRequirementWeight
		totalWeight += ace.config.AvailabilityRequirementWeight
	}

	// Calculate weighted average
	if totalWeight > 0 {
		score = score / totalWeight
	} else {
		score = asset.BusinessValue // Fallback to asset business value
	}

	// Apply time-based factors
	score = ace.applyTimeBasedFactors(score, asset)

	// Apply organizational factors
	score = ace.applyOrganizationalFactors(score, asset)

	return math.Min(score, 10.0)
}

// Helper calculation methods (simplified implementations)
func (ace *AssetCriticalityEngine) calculateIndirectBusinessValue(asset *Asset) float64 {
	// Calculate based on dependencies and network effects
	baseValue := asset.BusinessValue * 0.3
	dependencyCount := float64(len(asset.Dependencies))
	return baseValue + (dependencyCount * 0.5)
}

func (ace *AssetCriticalityEngine) calculateRevenueContribution(asset *Asset) float64 {
	// Revenue contribution based on asset type and business function
	baseContribution := asset.BusinessValue * 0.4
	
	if asset.BusinessFunction == "payment_processing" || 
	   asset.BusinessFunction == "customer_interaction" {
		baseContribution *= 1.5
	}
	
	return baseContribution
}

func (ace *AssetCriticalityEngine) calculateCostOfDowntime(asset *Asset) float64 {
	// Calculate based on asset criticality and business value
	hourlyRate := 1000.0 // Default hourly cost
	return asset.BusinessValue * hourlyRate
}

func (ace *AssetCriticalityEngine) calculateBusinessProcessValue(asset *Asset) float64 {
	// Value based on number and importance of business processes
	processValue := 0.0
	for _, process := range asset.BusinessProcesses {
		switch process {
		case "payment_processing", "customer_management":
			processValue += 3.0
		case "order_processing", "inventory_management":
			processValue += 2.0
		case "communication", "data_management":
			processValue += 1.5
		default:
			processValue += 1.0
		}
	}
	return math.Min(processValue, 10.0)
}

func (ace *AssetCriticalityEngine) calculateCompetitiveAdvantageValue(asset *Asset) float64 {
	// Competitive advantage based on asset uniqueness and business function
	baseValue := 3.0
	
	if asset.Type == "api_server" || asset.Type == "database" {
		baseValue += 2.0
	}
	
	if asset.BusinessFunction == "business_intelligence" ||
	   asset.BusinessFunction == "analytics" {
		baseValue += 2.5
	}
	
	return math.Min(baseValue, 10.0)
}

func (ace *AssetCriticalityEngine) calculateIntellectualPropertyValue(asset *Asset) float64 {
	// IP value based on asset type and data classification
	baseValue := 2.0
	
	if asset.DataClassification == "confidential" {
		baseValue += 3.0
	}
	
	if asset.Type == "database" || asset.Type == "file_server" {
		baseValue += 2.0
	}
	
	return math.Min(baseValue, 10.0)
}

func (ace *AssetCriticalityEngine) calculateBrandValue(asset *Asset) float64 {
	// Brand value impact based on customer-facing nature
	baseValue := 2.0
	
	if asset.Type == "web_server" || asset.Type == "api_server" {
		baseValue += 3.0
	}
	
	if asset.BusinessFunction == "customer_interaction" ||
	   asset.BusinessFunction == "customer_support" {
		baseValue += 2.0
	}
	
	return math.Min(baseValue, 10.0)
}

// Additional helper methods would be implemented similarly...
// For brevity, I'll include placeholder implementations

func (ace *AssetCriticalityEngine) generateBusinessValueFactors(analysis *BusinessValueAnalysis, asset *Asset) {
	// Generate detailed business value factors
	factors := make([]BusinessValueFactor, 0)
	
	factors = append(factors, BusinessValueFactor{
		Factor:     "direct_business_value",
		Value:      analysis.DirectBusinessValue,
		Weight:     0.4,
		Confidence: 0.8,
		Source:     "asset_analysis",
	})
	
	analysis.BusinessValueFactors = factors
}

func (ace *AssetCriticalityEngine) getUpstreamDependencies(asset *Asset) []AssetDependency {
	dependencies := make([]AssetDependency, 0)
	for _, depID := range asset.Dependencies {
		dependencies = append(dependencies, AssetDependency{
			AssetID:          depID,
			DependencyType:   "service",
			CriticalityLevel: "medium",
			FailureImpact:    0.7,
			RedundancyExists: false,
			RPO:              time.Hour,
			RTO:              time.Hour * 4,
		})
	}
	return dependencies
}

func (ace *AssetCriticalityEngine) getDownstreamDependencies(asset *Asset) []AssetDependency {
	// This would query the dependency map to find assets that depend on this one
	return make([]AssetDependency, 0)
}

func (ace *AssetCriticalityEngine) findCriticalDependencyPaths(asset *Asset, analysis *DependencyAnalysis) []DependencyPath {
	return make([]DependencyPath, 0)
}

func (ace *AssetCriticalityEngine) calculateDependencyScore(analysis *DependencyAnalysis) float64 {
	upstreamCount := float64(len(analysis.UpstreamDependencies))
	downstreamCount := float64(len(analysis.DownstreamDependencies))
	
	// More dependencies generally mean higher criticality
	score := (upstreamCount * 0.3) + (downstreamCount * 0.7)
	return math.Min(score, 10.0)
}

func (ace *AssetCriticalityEngine) isSinglePointOfFailure(asset *Asset, analysis *DependencyAnalysis) bool {
	// Simple heuristic: if many assets depend on this one and no redundancy
	return len(analysis.DownstreamDependencies) > 3
}

func (ace *AssetCriticalityEngine) calculateDependencyComplexity(analysis *DependencyAnalysis) float64 {
	totalDeps := float64(len(analysis.UpstreamDependencies) + len(analysis.DownstreamDependencies))
	pathComplexity := float64(len(analysis.CriticalDependencyPaths))
	
	return math.Min((totalDeps * 0.5) + (pathComplexity * 0.5), 10.0)
}

func (ace *AssetCriticalityEngine) generateDependencyRiskFactors(analysis *DependencyAnalysis, asset *Asset) {
	factors := make([]DependencyRiskFactor, 0)
	
	if analysis.SinglePointOfFailure {
		factors = append(factors, DependencyRiskFactor{
			Factor:     "single_point_of_failure",
			Impact:     8.0,
			Likelihood: 0.3,
			Mitigation: "implement_redundancy",
		})
	}
	
	analysis.DependencyRiskFactors = factors
}

func (ace *AssetCriticalityEngine) calculateRedundancyLevel(asset *Asset, analysis *DependencyAnalysis) float64 {
	// Calculate based on available redundant paths and backup systems
	redundantCount := 0
	for _, dep := range analysis.UpstreamDependencies {
		if dep.RedundancyExists {
			redundantCount++
		}
	}
	
	if len(analysis.UpstreamDependencies) == 0 {
		return 5.0 // Default medium redundancy
	}
	
	return float64(redundantCount) / float64(len(analysis.UpstreamDependencies)) * 10.0
}

func (ace *AssetCriticalityEngine) calculateFailoverCapability(asset *Asset, analysis *DependencyAnalysis) float64 {
	// Simplified calculation based on asset type and redundancy
	baseCapability := 5.0
	
	if asset.Type == "load_balancer" || asset.Type == "proxy_server" {
		baseCapability += 3.0
	}
	
	if analysis.RedundancyLevel > 7.0 {
		baseCapability += 2.0
	}
	
	return math.Min(baseCapability, 10.0)
}

// Additional methods would be implemented similarly...
// This provides a comprehensive but simplified implementation

func (ace *AssetCriticalityEngine) containsString(slice []string, item string) bool {
	for _, s := range slice {
		if s == item {
			return true
		}
	}
	return false
}

// Placeholder implementations for remaining methods
func (ace *AssetCriticalityEngine) analyzeDataTypes(asset *Asset) []DataTypeInfo { return []DataTypeInfo{} }
func (ace *AssetCriticalityEngine) calculatePrivacyImpact(asset *Asset, analysis *DataClassificationAnalysis) float64 { return 5.0 }
func (ace *AssetCriticalityEngine) calculateRegulatoryImpact(asset *Asset, analysis *DataClassificationAnalysis) float64 { return 5.0 }
func (ace *AssetCriticalityEngine) calculateDataVolumeScore(asset *Asset, analysis *DataClassificationAnalysis) float64 { return 5.0 }
func (ace *AssetCriticalityEngine) calculateDataQualityScore(asset *Asset, analysis *DataClassificationAnalysis) float64 { return 5.0 }
func (ace *AssetCriticalityEngine) calculateDataAccessibility(asset *Asset, analysis *DataClassificationAnalysis) float64 { return 5.0 }
func (ace *AssetCriticalityEngine) calculateDataRetentionScore(asset *Asset, analysis *DataClassificationAnalysis) float64 { return 5.0 }
func (ace *AssetCriticalityEngine) generateDataProtectionRequirements(asset *Asset, analysis *DataClassificationAnalysis) []string { return []string{} }
func (ace *AssetCriticalityEngine) determineNetworkPosition(asset *Asset, vuln *Vulnerability) string { return "internal" }
func (ace *AssetCriticalityEngine) calculateExternalExposure(asset *Asset, vuln *Vulnerability) float64 { 
	if vuln.NetworkContext.IsExternalFacing { return 8.0 }
	return 2.0
}
func (ace *AssetCriticalityEngine) calculateInternalConnectivity(asset *Asset, vuln *Vulnerability) float64 { return 5.0 }
func (ace *AssetCriticalityEngine) calculateNetworkSegmentation(asset *Asset, vuln *Vulnerability) float64 { return 5.0 }
func (ace *AssetCriticalityEngine) calculateTrafficVolume(asset *Asset, vuln *Vulnerability) float64 { return 5.0 }
func (ace *AssetCriticalityEngine) analyzeNetworkDependencies(asset *Asset, vuln *Vulnerability) []NetworkDependency { return []NetworkDependency{} }
func (ace *AssetCriticalityEngine) calculateSecurityControlsScore(asset *Asset, vuln *Vulnerability) float64 { return 5.0 }
func (ace *AssetCriticalityEngine) calculateMonitoringCoverage(asset *Asset, vuln *Vulnerability) float64 { return 5.0 }
func (ace *AssetCriticalityEngine) generateNetworkRiskFactors(analysis *NetworkCriticalityAnalysis, asset *Asset, vuln *Vulnerability) {}
func (ace *AssetCriticalityEngine) calculateComplianceScore(asset *Asset) float64 { return float64(len(asset.ComplianceScope)) * 2.0 }
func (ace *AssetCriticalityEngine) generateControlRequirements(asset *Asset, analysis *ComplianceAnalysis) []ControlRequirement { return []ControlRequirement{} }
func (ace *AssetCriticalityEngine) generateAuditRequirements(asset *Asset, analysis *ComplianceAnalysis) []AuditRequirement { return []AuditRequirement{} }
func (ace *AssetCriticalityEngine) calculateRegulatoryRisk(asset *Asset, analysis *ComplianceAnalysis) float64 { return analysis.ComplianceScore * 0.8 }
func (ace *AssetCriticalityEngine) identifyComplianceGaps(asset *Asset, analysis *ComplianceAnalysis) []ComplianceGap { return []ComplianceGap{} }
func (ace *AssetCriticalityEngine) generateComplianceRemediationRequirements(asset *Asset, analysis *ComplianceAnalysis) []string { return []string{} }
func (ace *AssetCriticalityEngine) calculateDataSensitivityScore(analysis *DataClassificationAnalysis) float64 { 
	switch analysis.SensitivityLevel {
	case "confidential": return 9.0
	case "internal": return 6.0
	case "public": return 3.0
	default: return 5.0
	}
}
func (ace *AssetCriticalityEngine) calculateNetworkExposureScore(analysis *NetworkCriticalityAnalysis) float64 { return analysis.ExternalExposure }
func (ace *AssetCriticalityEngine) calculateAvailabilityRequirementScore(asset *Asset, result *AssetCriticalityResult) float64 { return asset.BusinessValue * 0.8 }
func (ace *AssetCriticalityEngine) applyCustomCriticalityModels(result *AssetCriticalityResult, asset *Asset, vuln *Vulnerability) {}
func (ace *AssetCriticalityEngine) determineCriticalityLevel(score float64) string {
	if score >= ace.config.CriticalityThresholds.Critical { return "critical" }
	if score >= ace.config.CriticalityThresholds.High { return "high" }
	if score >= ace.config.CriticalityThresholds.Medium { return "medium" }
	return "low"
}
func (ace *AssetCriticalityEngine) determineAssetTier(score float64) string {
	for _, tier := range ace.config.AssetTierDefinitions {
		if score >= tier.MinScore && score <= tier.MaxScore {
			return tier.Tier
		}
	}
	return "tier3"
}
func (ace *AssetCriticalityEngine) calculateConfidence(result *AssetCriticalityResult) float64 { return 0.8 }
func (ace *AssetCriticalityEngine) generateBusinessContext(asset *Asset, result *AssetCriticalityResult) AssetBusinessContext { 
	return AssetBusinessContext{
		BusinessOwner: asset.Owner,
		TechnicalOwner: asset.Owner,
		BusinessUnit: "unknown",
		LifecycleStage: "production",
		BusinessCriticality: result.CriticalityLevel,
		StrategicImportance: result.CriticalityLevel,
	}
}
func (ace *AssetCriticalityEngine) generateCriticalityFactors(result *AssetCriticalityResult, asset *Asset, vuln *Vulnerability) {}
func (ace *AssetCriticalityEngine) generateMitigatingFactors(result *AssetCriticalityResult, asset *Asset, vuln *Vulnerability) {}
func (ace *AssetCriticalityEngine) generateCriticalityJustification(result *AssetCriticalityResult, asset *Asset, vuln *Vulnerability) {}
func (ace *AssetCriticalityEngine) generateManagementRecommendations(result *AssetCriticalityResult, asset *Asset, vuln *Vulnerability) {}
func (ace *AssetCriticalityEngine) extractCriticalDependencies(analysis *DependencyAnalysis) []string {
	deps := make([]string, 0)
	for _, dep := range analysis.UpstreamDependencies {
		if dep.CriticalityLevel == "critical" || dep.CriticalityLevel == "high" {
			deps = append(deps, dep.AssetID)
		}
	}
	return deps
}
func (ace *AssetCriticalityEngine) extractDependentAssets(analysis *DependencyAnalysis) []string {
	deps := make([]string, 0)
	for _, dep := range analysis.DownstreamDependencies {
		deps = append(deps, dep.AssetID)
	}
	return deps
}
func (ace *AssetCriticalityEngine) applyTimeBasedFactors(score float64, asset *Asset) float64 { return score }
func (ace *AssetCriticalityEngine) applyOrganizationalFactors(score float64, asset *Asset) float64 { return score }

// Cache and statistics methods
func (ace *AssetCriticalityEngine) getCachedResult(assetID string) *AssetCriticalityResult {
	ace.cache.mutex.RLock()
	defer ace.cache.mutex.RUnlock()
	
	if !ace.cache.enabled {
		return nil
	}
	
	result, exists := ace.cache.cache[assetID]
	if !exists {
		return nil
	}
	
	if ttl, exists := ace.cache.ttl[assetID]; exists {
		if time.Now().After(ttl) {
			delete(ace.cache.cache, assetID)
			delete(ace.cache.ttl, assetID)
			return nil
		}
	}
	
	return result
}

func (ace *AssetCriticalityEngine) cacheResult(assetID string, result *AssetCriticalityResult) {
	ace.cache.mutex.Lock()
	defer ace.cache.mutex.Unlock()
	
	if !ace.cache.enabled {
		return
	}
	
	if len(ace.cache.cache) >= ace.cache.maxSize {
		// Simple eviction
		for id := range ace.cache.cache {
			delete(ace.cache.cache, id)
			delete(ace.cache.ttl, id)
			break
		}
	}
	
	ace.cache.cache[assetID] = result
	ace.cache.ttl[assetID] = time.Now().Add(ace.config.CacheExpiration)
}

func (ace *AssetCriticalityEngine) updateCacheHitStats(hit bool) {
	ace.cache.mutex.Lock()
	defer ace.cache.mutex.Unlock()
	
	if hit {
		ace.cache.hitCount++
	} else {
		ace.cache.missCount++
	}
}

func (ace *AssetCriticalityEngine) updateStatistics(result *AssetCriticalityResult) {
	ace.mutex.Lock()
	defer ace.mutex.Unlock()
	
	ace.statistics.TotalAssessments++
	
	// Update average criticality score
	totalScore := ace.statistics.AverageCriticalityScore * float64(ace.statistics.TotalAssessments-1)
	totalScore += result.CriticalityScore
	ace.statistics.AverageCriticalityScore = totalScore / float64(ace.statistics.TotalAssessments)
	
	// Update distributions
	ace.statistics.CriticalityDistribution[result.CriticalityLevel]++
	ace.statistics.AssetTierDistribution[result.AssetTier]++
	
	// Update cache hit rate
	total := ace.cache.hitCount + ace.cache.missCount
	if total > 0 {
		ace.statistics.CacheHitRate = float64(ace.cache.hitCount) / float64(total)
	}
	
	ace.statistics.LastUpdate = time.Now()
}

// GetStatistics returns current asset criticality statistics
func (ace *AssetCriticalityEngine) GetStatistics() AssetCriticalityStatistics {
	ace.mutex.RLock()
	defer ace.mutex.RUnlock()
	return ace.statistics
}