#!/usr/bin/env python3
"""
iSECTECH Vulnerability Correlation and Contextualization Engine

This module provides comprehensive vulnerability correlation capabilities for the
network security monitoring platform. It integrates vulnerability data with
network monitoring to enhance threat detection and prioritization.

Author: iSECTECH Security Team
Version: 1.0.0
"""

import asyncio
import json
import logging
import sqlite3
import threading
import time
import xml.etree.ElementTree as ET
from collections import defaultdict, namedtuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Set, Optional, Tuple, Any, Union
import csv
import re

import redis
import requests
import yaml

# Third-party libraries for vulnerability management
try:
    import nvdlib
    import cvss
    import pyyaml
    import xmltodict
    import pandas as pd
    import numpy as np
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    ENHANCED_FEATURES = True
except ImportError as e:
    logging.warning(f"Enhanced features disabled due to missing dependencies: {e}")
    ENHANCED_FEATURES = False

# Vulnerability data structures
@dataclass
class Vulnerability:
    """Vulnerability information"""
    cve_id: str
    cvss_score: float
    cvss_vector: Optional[str] = None
    severity: str = "unknown"
    description: str = ""
    published_date: Optional[datetime] = None
    modified_date: Optional[datetime] = None
    affected_software: List[str] = None
    exploit_available: bool = False
    exploit_maturity: str = "unknown"
    references: List[str] = None
    cwe_ids: List[str] = None
    
    def __post_init__(self):
        if self.affected_software is None:
            self.affected_software = []
        if self.references is None:
            self.references = []
        if self.cwe_ids is None:
            self.cwe_ids = []

@dataclass 
class AssetVulnerability:
    """Asset-specific vulnerability information"""
    asset_ip: str
    cve_id: str
    scanner_source: str
    scan_date: datetime
    port: Optional[int] = None
    service: Optional[str] = None
    service_version: Optional[str] = None
    plugin_id: Optional[str] = None
    plugin_name: Optional[str] = None
    risk_score: float = 0.0
    threat_score: float = 0.0
    exploitability_score: float = 0.0
    asset_criticality: str = "medium"
    mitigation_status: str = "open"
    false_positive: bool = False
    
    def __post_init__(self):
        if isinstance(self.scan_date, str):
            self.scan_date = datetime.fromisoformat(self.scan_date)

@dataclass
class ThreatContext:
    """Threat context for vulnerability correlation"""
    asset_ip: str
    vulnerability_count: int
    critical_vulns: int
    high_vulns: int
    medium_vulns: int
    low_vulns: int
    exploitable_vulns: int
    risk_score: float
    threat_intelligence_matches: List[str] = None
    active_exploits: List[str] = None
    network_exposure: str = "unknown"
    
    def __post_init__(self):
        if self.threat_intelligence_matches is None:
            self.threat_intelligence_matches = []
        if self.active_exploits is None:
            self.active_exploits = []

@dataclass
class CorrelatedAlert:
    """Alert enriched with vulnerability context"""
    alert_id: str
    source_ip: str
    destination_ip: str
    alert_type: str
    severity: str
    timestamp: datetime
    vulnerability_context: Optional[ThreatContext] = None
    asset_risk_score: float = 0.0
    enhanced_severity: Optional[str] = None
    correlation_confidence: float = 0.0
    mitigation_recommendations: List[str] = None
    
    def __post_init__(self):
        if self.mitigation_recommendations is None:
            self.mitigation_recommendations = []
        if isinstance(self.timestamp, str):
            self.timestamp = datetime.fromisoformat(self.timestamp)

class VulnerabilityDataIngestion:
    """Vulnerability data ingestion from various sources"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.vulnerabilities: Dict[str, Vulnerability] = {}
        self.asset_vulnerabilities: Dict[str, List[AssetVulnerability]] = defaultdict(list)
        
    def ingest_nessus_data(self, file_path: str) -> List[AssetVulnerability]:
        """Ingest vulnerability data from Nessus .nessus files"""
        vulnerabilities = []
        
        try:
            tree = ET.parse(file_path)
            root = tree.getroot()
            
            for report_host in root.findall('.//ReportHost'):
                host_ip = report_host.get('name')
                
                for report_item in report_host.findall('ReportItem'):
                    try:
                        # Extract vulnerability information
                        plugin_id = report_item.get('pluginID')
                        plugin_name = report_item.get('pluginName')
                        severity = int(report_item.get('severity', 0))
                        port = report_item.get('port')
                        service = report_item.get('svc_name')
                        protocol = report_item.get('protocol')
                        
                        # Extract CVE IDs
                        cve_elements = report_item.findall('cve')
                        cve_ids = [cve.text for cve in cve_elements]
                        
                        # Extract CVSS score
                        cvss_score = 0.0
                        cvss_element = report_item.find('cvss_base_score')
                        if cvss_element is not None:
                            cvss_score = float(cvss_element.text)
                        
                        # Convert Nessus severity to string
                        severity_map = {0: "info", 1: "low", 2: "medium", 3: "high", 4: "critical"}
                        severity_str = severity_map.get(severity, "unknown")
                        
                        # Create asset vulnerability for each CVE
                        for cve_id in cve_ids:
                            if cve_id:
                                asset_vuln = AssetVulnerability(
                                    asset_ip=host_ip,
                                    cve_id=cve_id,
                                    scanner_source="nessus",
                                    scan_date=datetime.utcnow(),
                                    port=int(port) if port and port.isdigit() else None,
                                    service=service,
                                    plugin_id=plugin_id,
                                    plugin_name=plugin_name,
                                    risk_score=cvss_score
                                )
                                vulnerabilities.append(asset_vuln)
                                
                        # Handle non-CVE vulnerabilities
                        if not cve_ids and plugin_id:
                            asset_vuln = AssetVulnerability(
                                asset_ip=host_ip,
                                cve_id=f"NESSUS-{plugin_id}",
                                scanner_source="nessus",
                                scan_date=datetime.utcnow(),
                                port=int(port) if port and port.isdigit() else None,
                                service=service,
                                plugin_id=plugin_id,
                                plugin_name=plugin_name,
                                risk_score=cvss_score
                            )
                            vulnerabilities.append(asset_vuln)
                            
                    except Exception as e:
                        self.logger.error(f"Error processing Nessus report item: {e}")
                        continue
            
            self.logger.info(f"Ingested {len(vulnerabilities)} vulnerabilities from Nessus file {file_path}")
            
        except Exception as e:
            self.logger.error(f"Error ingesting Nessus data from {file_path}: {e}")
        
        return vulnerabilities
    
    def ingest_openvas_data(self, file_path: str) -> List[AssetVulnerability]:
        """Ingest vulnerability data from OpenVAS XML reports"""
        vulnerabilities = []
        
        try:
            tree = ET.parse(file_path)
            root = tree.getroot()
            
            # OpenVAS XML structure
            for result in root.findall('.//result'):
                try:
                    # Extract host information
                    host_element = result.find('host')
                    if host_element is None:
                        continue
                    host_ip = host_element.text
                    
                    # Extract port information
                    port_element = result.find('port')
                    port = None
                    service = None
                    if port_element is not None:
                        port_info = port_element.text
                        if port_info and '/' in port_info:
                            port_str, protocol = port_info.split('/', 1)
                            if port_str.isdigit():
                                port = int(port_str)
                    
                    # Extract NVT (vulnerability test) information
                    nvt_element = result.find('nvt')
                    if nvt_element is None:
                        continue
                    
                    nvt_oid = nvt_element.get('oid')
                    name_element = nvt_element.find('name')
                    name = name_element.text if name_element is not None else ""
                    
                    # Extract CVE references
                    cve_ids = []
                    refs = nvt_element.findall('refs/ref[@type="cve"]')
                    for ref in refs:
                        cve_id = ref.get('id')
                        if cve_id:
                            cve_ids.append(cve_id)
                    
                    # Extract severity
                    severity_element = result.find('severity')
                    severity_score = 0.0
                    if severity_element is not None:
                        try:
                            severity_score = float(severity_element.text)
                        except (ValueError, TypeError):
                            pass
                    
                    # Create asset vulnerabilities
                    for cve_id in cve_ids:
                        asset_vuln = AssetVulnerability(
                            asset_ip=host_ip,
                            cve_id=cve_id,
                            scanner_source="openvas",
                            scan_date=datetime.utcnow(),
                            port=port,
                            service=service,
                            plugin_id=nvt_oid,
                            plugin_name=name,
                            risk_score=severity_score
                        )
                        vulnerabilities.append(asset_vuln)
                    
                    # Handle non-CVE vulnerabilities
                    if not cve_ids and nvt_oid:
                        asset_vuln = AssetVulnerability(
                            asset_ip=host_ip,
                            cve_id=f"OPENVAS-{nvt_oid}",
                            scanner_source="openvas",
                            scan_date=datetime.utcnow(),
                            port=port,
                            service=service,
                            plugin_id=nvt_oid,
                            plugin_name=name,
                            risk_score=severity_score
                        )
                        vulnerabilities.append(asset_vuln)
                        
                except Exception as e:
                    self.logger.error(f"Error processing OpenVAS result: {e}")
                    continue
            
            self.logger.info(f"Ingested {len(vulnerabilities)} vulnerabilities from OpenVAS file {file_path}")
            
        except Exception as e:
            self.logger.error(f"Error ingesting OpenVAS data from {file_path}: {e}")
        
        return vulnerabilities
    
    def ingest_qualys_data(self, file_path: str) -> List[AssetVulnerability]:
        """Ingest vulnerability data from Qualys CSV reports"""
        vulnerabilities = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                
                for row in reader:
                    try:
                        # Extract basic information
                        host_ip = row.get('IP', '').strip()
                        if not host_ip:
                            continue
                        
                        # Extract vulnerability information
                        qid = row.get('QID', '')
                        title = row.get('Title', '')
                        severity = row.get('Severity', '').lower()
                        
                        # Extract CVE IDs
                        cve_field = row.get('CVE ID', '')
                        cve_ids = []
                        if cve_field:
                            # CVE IDs can be comma-separated
                            cve_ids = [cve.strip() for cve in cve_field.split(',') if cve.strip()]
                        
                        # Extract CVSS score
                        cvss_score = 0.0
                        cvss_field = row.get('CVSS Base', '') or row.get('CVSS', '')
                        if cvss_field:
                            try:
                                cvss_score = float(cvss_field)
                            except ValueError:
                                pass
                        
                        # Extract port information
                        port = None
                        port_field = row.get('Port', '')
                        if port_field and port_field.isdigit():
                            port = int(port_field)
                        
                        # Extract service information
                        service = row.get('Service', '')
                        
                        # Create asset vulnerabilities
                        for cve_id in cve_ids:
                            asset_vuln = AssetVulnerability(
                                asset_ip=host_ip,
                                cve_id=cve_id,
                                scanner_source="qualys",
                                scan_date=datetime.utcnow(),
                                port=port,
                                service=service if service else None,
                                plugin_id=qid,
                                plugin_name=title,
                                risk_score=cvss_score
                            )
                            vulnerabilities.append(asset_vuln)
                        
                        # Handle non-CVE vulnerabilities
                        if not cve_ids and qid:
                            asset_vuln = AssetVulnerability(
                                asset_ip=host_ip,
                                cve_id=f"QUALYS-{qid}",
                                scanner_source="qualys",
                                scan_date=datetime.utcnow(),
                                port=port,
                                service=service if service else None,
                                plugin_id=qid,
                                plugin_name=title,
                                risk_score=cvss_score
                            )
                            vulnerabilities.append(asset_vuln)
                            
                    except Exception as e:
                        self.logger.error(f"Error processing Qualys row: {e}")
                        continue
            
            self.logger.info(f"Ingested {len(vulnerabilities)} vulnerabilities from Qualys file {file_path}")
            
        except Exception as e:
            self.logger.error(f"Error ingesting Qualys data from {file_path}: {e}")
        
        return vulnerabilities
    
    def fetch_nvd_data(self, cve_ids: List[str]) -> Dict[str, Vulnerability]:
        """Fetch vulnerability data from NVD API"""
        vulnerabilities = {}
        
        if not ENHANCED_FEATURES:
            self.logger.warning("NVD API features not available")
            return vulnerabilities
        
        try:
            for cve_id in cve_ids:
                try:
                    # Fetch CVE data from NVD
                    cve_data = nvdlib.searchCVE(cveId=cve_id)
                    
                    if cve_data:
                        cve = cve_data[0]  # First result
                        
                        # Extract CVSS score
                        cvss_score = 0.0
                        cvss_vector = None
                        
                        if hasattr(cve, 'v3_1score') and cve.v3_1score:
                            cvss_score = cve.v3_1score
                            cvss_vector = getattr(cve, 'v3_1vector', None)
                        elif hasattr(cve, 'v2score') and cve.v2score:
                            cvss_score = cve.v2score
                            cvss_vector = getattr(cve, 'v2vector', None)
                        
                        # Determine severity
                        severity = "unknown"
                        if cvss_score >= 9.0:
                            severity = "critical"
                        elif cvss_score >= 7.0:
                            severity = "high"
                        elif cvss_score >= 4.0:
                            severity = "medium"
                        elif cvss_score > 0.0:
                            severity = "low"
                        
                        # Extract CWE IDs
                        cwe_ids = []
                        if hasattr(cve, 'cwe') and cve.cwe:
                            cwe_ids = [cwe for cwe in cve.cwe if cwe]
                        
                        # Create vulnerability object
                        vulnerability = Vulnerability(
                            cve_id=cve_id,
                            cvss_score=cvss_score,
                            cvss_vector=cvss_vector,
                            severity=severity,
                            description=getattr(cve, 'description', ''),
                            published_date=getattr(cve, 'published', None),
                            modified_date=getattr(cve, 'lastModified', None),
                            cwe_ids=cwe_ids,
                            references=getattr(cve, 'references', [])
                        )
                        
                        vulnerabilities[cve_id] = vulnerability
                        
                    # Rate limiting for NVD API
                    time.sleep(0.6)  # NVD API allows ~10 requests per minute
                    
                except Exception as e:
                    self.logger.error(f"Error fetching NVD data for {cve_id}: {e}")
                    continue
            
            self.logger.info(f"Fetched {len(vulnerabilities)} vulnerabilities from NVD")
            
        except Exception as e:
            self.logger.error(f"Error fetching NVD data: {e}")
        
        return vulnerabilities
    
    def ingest_custom_csv(self, file_path: str, mapping: Dict[str, str]) -> List[AssetVulnerability]:
        """Ingest vulnerability data from custom CSV format"""
        vulnerabilities = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                
                for row in reader:
                    try:
                        # Map fields based on configuration
                        asset_ip = row.get(mapping.get('ip_field', 'ip'), '').strip()
                        cve_id = row.get(mapping.get('cve_field', 'cve'), '').strip()
                        risk_score = row.get(mapping.get('score_field', 'score'), '0')
                        
                        if not asset_ip or not cve_id:
                            continue
                        
                        # Convert risk score
                        try:
                            risk_score = float(risk_score)
                        except ValueError:
                            risk_score = 0.0
                        
                        # Extract optional fields
                        port = row.get(mapping.get('port_field', 'port'), '')
                        service = row.get(mapping.get('service_field', 'service'), '')
                        
                        port_num = None
                        if port and port.isdigit():
                            port_num = int(port)
                        
                        asset_vuln = AssetVulnerability(
                            asset_ip=asset_ip,
                            cve_id=cve_id,
                            scanner_source="custom",
                            scan_date=datetime.utcnow(),
                            port=port_num,
                            service=service if service else None,
                            risk_score=risk_score
                        )
                        vulnerabilities.append(asset_vuln)
                        
                    except Exception as e:
                        self.logger.error(f"Error processing custom CSV row: {e}")
                        continue
            
            self.logger.info(f"Ingested {len(vulnerabilities)} vulnerabilities from custom CSV {file_path}")
            
        except Exception as e:
            self.logger.error(f"Error ingesting custom CSV data from {file_path}: {e}")
        
        return vulnerabilities
    
    def update_vulnerability_database(self, vulnerabilities: List[AssetVulnerability]):
        """Update asset vulnerabilities in memory storage"""
        for vuln in vulnerabilities:
            self.asset_vulnerabilities[vuln.asset_ip].append(vuln)
        
        self.logger.info(f"Updated vulnerability database with {len(vulnerabilities)} entries")

class ThreatIntelligenceCorrelation:
    """Threat intelligence correlation for vulnerability prioritization"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.exploit_data: Dict[str, Dict[str, Any]] = {}
        self.threat_feeds: Dict[str, List[str]] = defaultdict(list)
        
    def load_exploit_data(self, exploit_db_path: str):
        """Load exploit data from Exploit-DB or similar sources"""
        try:
            if not Path(exploit_db_path).exists():
                self.logger.warning(f"Exploit database not found at {exploit_db_path}")
                return
            
            with open(exploit_db_path, 'r') as f:
                if exploit_db_path.endswith('.json'):
                    exploit_data = json.load(f)
                    
                    for exploit in exploit_data:
                        cve_ids = exploit.get('cve_ids', [])
                        for cve_id in cve_ids:
                            if cve_id not in self.exploit_data:
                                self.exploit_data[cve_id] = []
                            
                            self.exploit_data[cve_id].append({
                                'exploit_id': exploit.get('id'),
                                'title': exploit.get('title', ''),
                                'type': exploit.get('type', 'unknown'),
                                'platform': exploit.get('platform', 'unknown'),
                                'date': exploit.get('date'),
                                'verified': exploit.get('verified', False)
                            })
                
                elif exploit_db_path.endswith('.csv'):
                    reader = csv.DictReader(f)
                    for row in reader:
                        cve_field = row.get('cve', '') or row.get('CVE', '')
                        if cve_field:
                            cve_ids = [cve.strip() for cve in cve_field.split(',') if cve.strip()]
                            
                            for cve_id in cve_ids:
                                if cve_id not in self.exploit_data:
                                    self.exploit_data[cve_id] = []
                                
                                self.exploit_data[cve_id].append({
                                    'exploit_id': row.get('id', ''),
                                    'title': row.get('title', ''),
                                    'type': row.get('type', 'unknown'),
                                    'platform': row.get('platform', 'unknown'),
                                    'date': row.get('date'),
                                    'verified': row.get('verified', 'false').lower() == 'true'
                                })
            
            self.logger.info(f"Loaded exploit data for {len(self.exploit_data)} CVEs")
            
        except Exception as e:
            self.logger.error(f"Error loading exploit data: {e}")
    
    def check_exploit_availability(self, cve_id: str) -> Dict[str, Any]:
        """Check if exploits are available for a CVE"""
        exploit_info = {
            'available': False,
            'count': 0,
            'verified_count': 0,
            'maturity': 'unknown',
            'exploits': []
        }
        
        if cve_id in self.exploit_data:
            exploits = self.exploit_data[cve_id]
            exploit_info['available'] = True
            exploit_info['count'] = len(exploits)
            exploit_info['verified_count'] = sum(1 for e in exploits if e.get('verified', False))
            exploit_info['exploits'] = exploits
            
            # Determine exploit maturity
            if exploit_info['verified_count'] > 0:
                exploit_info['maturity'] = 'functional'
            elif exploit_info['count'] > 2:
                exploit_info['maturity'] = 'proof_of_concept'
            else:
                exploit_info['maturity'] = 'unproven'
        
        return exploit_info
    
    def correlate_with_threat_feeds(self, cve_ids: List[str]) -> Dict[str, List[str]]:
        """Correlate CVEs with threat intelligence feeds"""
        correlations = {}
        
        for cve_id in cve_ids:
            matches = []
            
            # Check various threat feeds
            for feed_name, feed_data in self.threat_feeds.items():
                if cve_id in feed_data:
                    matches.append(feed_name)
            
            if matches:
                correlations[cve_id] = matches
        
        return correlations
    
    def load_threat_feeds(self, feed_configs: List[Dict[str, Any]]):
        """Load threat intelligence feeds"""
        for feed_config in feed_configs:
            try:
                feed_name = feed_config['name']
                feed_type = feed_config['type']
                feed_source = feed_config['source']
                
                if feed_type == 'file':
                    self._load_threat_feed_file(feed_name, feed_source)
                elif feed_type == 'api':
                    self._load_threat_feed_api(feed_name, feed_source, feed_config.get('api_key'))
                
            except Exception as e:
                self.logger.error(f"Error loading threat feed {feed_config.get('name', 'unknown')}: {e}")
    
    def _load_threat_feed_file(self, feed_name: str, file_path: str):
        """Load threat feed from file"""
        try:
            with open(file_path, 'r') as f:
                if file_path.endswith('.json'):
                    data = json.load(f)
                    if isinstance(data, list):
                        self.threat_feeds[feed_name].extend(data)
                    elif isinstance(data, dict) and 'cves' in data:
                        self.threat_feeds[feed_name].extend(data['cves'])
                        
                elif file_path.endswith('.txt'):
                    # Plain text list of CVEs
                    for line in f:
                        cve_id = line.strip()
                        if cve_id.startswith('CVE-'):
                            self.threat_feeds[feed_name].append(cve_id)
            
            self.logger.info(f"Loaded {len(self.threat_feeds[feed_name])} items from {feed_name}")
            
        except Exception as e:
            self.logger.error(f"Error loading threat feed file {file_path}: {e}")
    
    def _load_threat_feed_api(self, feed_name: str, api_url: str, api_key: str = None):
        """Load threat feed from API"""
        try:
            headers = {}
            if api_key:
                headers['Authorization'] = f"Bearer {api_key}"
            
            response = requests.get(api_url, headers=headers, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            
            # Extract CVE IDs based on common API formats
            cve_ids = []
            if isinstance(data, list):
                for item in data:
                    if isinstance(item, str) and item.startswith('CVE-'):
                        cve_ids.append(item)
                    elif isinstance(item, dict):
                        cve_id = item.get('cve_id') or item.get('cve') or item.get('id')
                        if cve_id and cve_id.startswith('CVE-'):
                            cve_ids.append(cve_id)
            elif isinstance(data, dict):
                if 'cves' in data:
                    cve_ids.extend(data['cves'])
                elif 'vulnerabilities' in data:
                    for vuln in data['vulnerabilities']:
                        cve_id = vuln.get('cve_id') or vuln.get('cve')
                        if cve_id:
                            cve_ids.append(cve_id)
            
            self.threat_feeds[feed_name].extend(cve_ids)
            self.logger.info(f"Loaded {len(cve_ids)} CVEs from {feed_name} API")
            
        except Exception as e:
            self.logger.error(f"Error loading threat feed API {api_url}: {e}")

class VulnerabilityRiskScoring:
    """Advanced vulnerability risk scoring and prioritization"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # Risk scoring weights
        self.weights = {
            'cvss_score': config.get('weights', {}).get('cvss_score', 0.4),
            'exploit_availability': config.get('weights', {}).get('exploit_availability', 0.3),
            'asset_criticality': config.get('weights', {}).get('asset_criticality', 0.2),
            'network_exposure': config.get('weights', {}).get('network_exposure', 0.1)
        }
    
    def calculate_vulnerability_risk_score(self, 
                                         asset_vuln: AssetVulnerability,
                                         exploit_info: Dict[str, Any],
                                         asset_criticality: str,
                                         network_exposure: str) -> float:
        """Calculate comprehensive risk score for a vulnerability"""
        
        # Base CVSS score (0-10) normalized to 0-1
        cvss_component = min(asset_vuln.risk_score / 10.0, 1.0)
        
        # Exploit availability score
        exploit_score = 0.0
        if exploit_info.get('available', False):
            if exploit_info.get('maturity') == 'functional':
                exploit_score = 1.0
            elif exploit_info.get('maturity') == 'proof_of_concept':
                exploit_score = 0.7
            else:
                exploit_score = 0.3
        
        # Asset criticality score
        criticality_scores = {
            'critical': 1.0,
            'high': 0.8,
            'medium': 0.5,
            'low': 0.2,
            'unknown': 0.3
        }
        criticality_score = criticality_scores.get(asset_criticality.lower(), 0.3)
        
        # Network exposure score
        exposure_scores = {
            'internet_facing': 1.0,
            'dmz': 0.8,
            'internal': 0.4,
            'isolated': 0.1,
            'unknown': 0.5
        }
        exposure_score = exposure_scores.get(network_exposure.lower(), 0.5)
        
        # Calculate weighted risk score
        risk_score = (
            cvss_component * self.weights['cvss_score'] +
            exploit_score * self.weights['exploit_availability'] +
            criticality_score * self.weights['asset_criticality'] +
            exposure_score * self.weights['network_exposure']
        )
        
        return min(risk_score, 1.0)  # Cap at 1.0
    
    def calculate_threat_score(self, 
                             asset_vulns: List[AssetVulnerability],
                             threat_intel_matches: List[str],
                             active_exploits: List[str]) -> float:
        """Calculate overall threat score for an asset"""
        
        if not asset_vulns:
            return 0.0
        
        # Base threat score from vulnerabilities
        vuln_scores = [vuln.risk_score / 10.0 for vuln in asset_vulns]
        base_score = max(vuln_scores)  # Highest vulnerability drives base score
        
        # Threat intelligence boost
        ti_boost = min(len(threat_intel_matches) * 0.1, 0.3)
        
        # Active exploit boost
        exploit_boost = min(len(active_exploits) * 0.2, 0.4)
        
        # Vulnerability count factor
        count_factor = min(len(asset_vulns) * 0.05, 0.2)
        
        threat_score = base_score + ti_boost + exploit_boost + count_factor
        
        return min(threat_score, 1.0)  # Cap at 1.0
    
    def prioritize_vulnerabilities(self, 
                                 vulnerabilities: List[AssetVulnerability],
                                 scoring_context: Dict[str, Any]) -> List[AssetVulnerability]:
        """Prioritize vulnerabilities based on risk scores"""
        
        # Calculate risk scores for each vulnerability
        for vuln in vulnerabilities:
            asset_context = scoring_context.get(vuln.asset_ip, {})
            
            exploit_info = asset_context.get('exploit_info', {})
            asset_criticality = asset_context.get('asset_criticality', 'medium')
            network_exposure = asset_context.get('network_exposure', 'internal')
            
            vuln.threat_score = self.calculate_vulnerability_risk_score(
                vuln, exploit_info, asset_criticality, network_exposure
            )
        
        # Sort by threat score (highest first)
        prioritized = sorted(vulnerabilities, key=lambda v: v.threat_score, reverse=True)
        
        return prioritized

class AlertEnrichment:
    """Alert enrichment with vulnerability context"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
    def enrich_alert_with_vulnerability_context(self,
                                              alert: Dict[str, Any],
                                              threat_context: ThreatContext) -> CorrelatedAlert:
        """Enrich security alert with vulnerability context"""
        
        # Create correlated alert
        correlated_alert = CorrelatedAlert(
            alert_id=alert.get('id', ''),
            source_ip=alert.get('source_ip', ''),
            destination_ip=alert.get('destination_ip', ''),
            alert_type=alert.get('type', ''),
            severity=alert.get('severity', 'medium'),
            timestamp=datetime.fromisoformat(alert.get('timestamp', datetime.utcnow().isoformat())),
            vulnerability_context=threat_context
        )
        
        # Calculate enhanced severity
        correlated_alert.enhanced_severity = self._calculate_enhanced_severity(
            alert.get('severity', 'medium'),
            threat_context
        )
        
        # Calculate asset risk score
        correlated_alert.asset_risk_score = threat_context.risk_score
        
        # Calculate correlation confidence
        correlated_alert.correlation_confidence = self._calculate_correlation_confidence(
            alert, threat_context
        )
        
        # Generate mitigation recommendations
        correlated_alert.mitigation_recommendations = self._generate_mitigation_recommendations(
            alert, threat_context
        )
        
        return correlated_alert
    
    def _calculate_enhanced_severity(self, 
                                   original_severity: str, 
                                   threat_context: ThreatContext) -> str:
        """Calculate enhanced severity based on vulnerability context"""
        
        severity_scores = {
            'low': 1,
            'medium': 2,
            'high': 3,
            'critical': 4
        }
        
        original_score = severity_scores.get(original_severity.lower(), 2)
        
        # Boost based on vulnerability context
        boost = 0
        
        if threat_context.critical_vulns > 0:
            boost += 2
        elif threat_context.high_vulns > 0:
            boost += 1
        
        if threat_context.exploitable_vulns > 0:
            boost += 1
        
        if threat_context.active_exploits:
            boost += 1
        
        if threat_context.threat_intelligence_matches:
            boost += 1
        
        # Calculate enhanced score
        enhanced_score = min(original_score + boost, 4)
        
        # Convert back to severity string
        score_to_severity = {1: 'low', 2: 'medium', 3: 'high', 4: 'critical'}
        return score_to_severity[enhanced_score]
    
    def _calculate_correlation_confidence(self,
                                        alert: Dict[str, Any],
                                        threat_context: ThreatContext) -> float:
        """Calculate confidence in vulnerability-alert correlation"""
        
        confidence = 0.0
        
        # Base confidence for having vulnerability data
        if threat_context.vulnerability_count > 0:
            confidence += 0.3
        
        # Port/service correlation
        alert_port = alert.get('destination_port')
        if alert_port:
            # Check if alert port matches vulnerable services
            # This would require more detailed vulnerability data
            confidence += 0.2
        
        # IP address exact match
        if alert.get('destination_ip') == threat_context.asset_ip:
            confidence += 0.3
        
        # Exploit availability
        if threat_context.exploitable_vulns > 0:
            confidence += 0.2
        
        return min(confidence, 1.0)
    
    def _generate_mitigation_recommendations(self,
                                           alert: Dict[str, Any],
                                           threat_context: ThreatContext) -> List[str]:
        """Generate mitigation recommendations based on context"""
        
        recommendations = []
        
        # General recommendations
        if threat_context.critical_vulns > 0:
            recommendations.append("Immediately patch critical vulnerabilities")
        
        if threat_context.exploitable_vulns > 0:
            recommendations.append("Prioritize patching of exploitable vulnerabilities")
        
        if threat_context.network_exposure == "internet_facing":
            recommendations.append("Consider temporary network isolation")
            recommendations.append("Implement additional access controls")
        
        if threat_context.active_exploits:
            recommendations.append("Deploy specific protections for active exploits")
            recommendations.append("Monitor for exploitation attempts")
        
        # Alert-specific recommendations
        alert_type = alert.get('type', '').lower()
        
        if 'brute_force' in alert_type or 'login' in alert_type:
            recommendations.append("Implement account lockout policies")
            recommendations.append("Enable multi-factor authentication")
        
        if 'malware' in alert_type or 'trojan' in alert_type:
            recommendations.append("Perform full malware scan")
            recommendations.append("Check for lateral movement indicators")
        
        if 'network_scan' in alert_type or 'reconnaissance' in alert_type:
            recommendations.append("Monitor for follow-up exploitation attempts")
            recommendations.append("Review firewall and access controls")
        
        return recommendations

class VulnerabilityCorrelationEngine:
    """Main vulnerability correlation and contextualization engine"""
    
    def __init__(self, config_path: str = "/etc/nsm/vulnerability-correlation.yaml"):
        self.config_path = config_path
        self.config = self._load_config()
        self.logger = self._setup_logging()
        
        # Initialize components
        self.data_ingestion = VulnerabilityDataIngestion(self.config.get('data_ingestion', {}))
        self.threat_intel = ThreatIntelligenceCorrelation(self.config.get('threat_intelligence', {}))
        self.risk_scoring = VulnerabilityRiskScoring(self.config.get('risk_scoring', {}))
        self.alert_enrichment = AlertEnrichment(self.config.get('alert_enrichment', {}))
        
        # Database setup
        self.db_path = self.config.get('database', {}).get('path', '/var/lib/nsm/vulnerability_correlation.db')
        self._initialize_database()
        
        # Redis connection
        self.redis_client = None
        if self.config.get('redis', {}).get('enabled', False):
            self._initialize_redis()
        
        # Processing state
        self.processing_active = False
        self.processing_thread = None
        
        # Metrics
        self.metrics = {
            'vulnerabilities_processed': 0,
            'alerts_enriched': 0,
            'correlations_made': 0,
            'last_update_time': None
        }
        
        # Load initial data
        self._load_initial_data()
    
    def _load_config(self) -> Dict[str, Any]:
        """Load configuration from YAML file"""
        try:
            with open(self.config_path, 'r') as f:
                return yaml.safe_load(f)
        except Exception as e:
            print(f"Error loading config: {e}")
            return {}
    
    def _setup_logging(self) -> logging.Logger:
        """Setup logging configuration"""
        logger = logging.getLogger(__name__)
        logger.setLevel(getattr(logging, self.config.get('log_level', 'INFO')))
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def _initialize_database(self):
        """Initialize SQLite database for vulnerability correlation"""
        try:
            Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)
            
            with sqlite3.connect(self.db_path) as conn:
                # Create tables
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS vulnerabilities (
                        cve_id TEXT PRIMARY KEY,
                        cvss_score REAL,
                        cvss_vector TEXT,
                        severity TEXT,
                        description TEXT,
                        published_date TIMESTAMP,
                        modified_date TIMESTAMP,
                        affected_software TEXT,
                        exploit_available BOOLEAN,
                        exploit_maturity TEXT,
                        references TEXT,
                        cwe_ids TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                ''')
                
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS asset_vulnerabilities (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        asset_ip TEXT,
                        cve_id TEXT,
                        scanner_source TEXT,
                        scan_date TIMESTAMP,
                        port INTEGER,
                        service TEXT,
                        service_version TEXT,
                        plugin_id TEXT,
                        plugin_name TEXT,
                        risk_score REAL,
                        threat_score REAL,
                        exploitability_score REAL,
                        asset_criticality TEXT,
                        mitigation_status TEXT,
                        false_positive BOOLEAN,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        UNIQUE(asset_ip, cve_id, scanner_source)
                    )
                ''')
                
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS threat_context (
                        asset_ip TEXT PRIMARY KEY,
                        vulnerability_count INTEGER,
                        critical_vulns INTEGER,
                        high_vulns INTEGER,
                        medium_vulns INTEGER,
                        low_vulns INTEGER,
                        exploitable_vulns INTEGER,
                        risk_score REAL,
                        threat_intelligence_matches TEXT,
                        active_exploits TEXT,
                        network_exposure TEXT,
                        last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                ''')
                
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS correlated_alerts (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        alert_id TEXT,
                        source_ip TEXT,
                        destination_ip TEXT,
                        alert_type TEXT,
                        severity TEXT,
                        enhanced_severity TEXT,
                        timestamp TIMESTAMP,
                        asset_risk_score REAL,
                        correlation_confidence REAL,
                        mitigation_recommendations TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                ''')
                
                # Create indexes
                conn.execute('CREATE INDEX IF NOT EXISTS idx_asset_vulns_ip ON asset_vulnerabilities(asset_ip)')
                conn.execute('CREATE INDEX IF NOT EXISTS idx_asset_vulns_cve ON asset_vulnerabilities(cve_id)')
                conn.execute('CREATE INDEX IF NOT EXISTS idx_correlated_alerts_dest ON correlated_alerts(destination_ip)')
                conn.execute('CREATE INDEX IF NOT EXISTS idx_correlated_alerts_time ON correlated_alerts(timestamp)')
                
                conn.commit()
                
            self.logger.info("Vulnerability correlation database initialized")
            
        except Exception as e:
            self.logger.error(f"Failed to initialize database: {e}")
    
    def _initialize_redis(self):
        """Initialize Redis connection"""
        try:
            redis_config = self.config['redis']
            self.redis_client = redis.Redis(
                host=redis_config.get('host', 'localhost'),
                port=redis_config.get('port', 6379),
                db=redis_config.get('db', 0),
                password=redis_config.get('password'),
                decode_responses=True
            )
            self.redis_client.ping()
            self.logger.info("Connected to Redis for vulnerability correlation")
        except Exception as e:
            self.logger.error(f"Failed to connect to Redis: {e}")
            self.redis_client = None
    
    def _load_initial_data(self):
        """Load initial threat intelligence and exploit data"""
        try:
            # Load threat intelligence feeds
            ti_config = self.config.get('threat_intelligence', {})
            feeds = ti_config.get('feeds', [])
            if feeds:
                self.threat_intel.load_threat_feeds(feeds)
            
            # Load exploit data
            exploit_db_path = ti_config.get('exploit_database_path')
            if exploit_db_path:
                self.threat_intel.load_exploit_data(exploit_db_path)
            
        except Exception as e:
            self.logger.error(f"Error loading initial data: {e}")
    
    def start_processing(self):
        """Start continuous vulnerability correlation processing"""
        if self.processing_active:
            self.logger.warning("Processing already active")
            return
        
        self.processing_active = True
        self.processing_thread = threading.Thread(target=self._processing_loop, daemon=True)
        self.processing_thread.start()
        
        self.logger.info("Vulnerability correlation processing started")
    
    def stop_processing(self):
        """Stop vulnerability correlation processing"""
        self.processing_active = False
        if self.processing_thread:
            self.processing_thread.join(timeout=30)
        
        self.logger.info("Vulnerability correlation processing stopped")
    
    def _processing_loop(self):
        """Main processing loop"""
        while self.processing_active:
            try:
                # Process new vulnerability data
                self._process_vulnerability_updates()
                
                # Process alerts for enrichment
                self._process_alert_enrichment()
                
                # Update threat context
                self._update_threat_context()
                
                # Update metrics
                self.metrics['last_update_time'] = datetime.utcnow()
                
                # Sleep until next cycle
                sleep_time = self.config.get('processing_interval', 300)  # Default 5 minutes
                time.sleep(sleep_time)
                
            except Exception as e:
                self.logger.error(f"Error in processing loop: {e}")
                time.sleep(60)  # Sleep 1 minute on error
    
    def _process_vulnerability_updates(self):
        """Process new vulnerability scan data"""
        try:
            # Check for new scan files
            scan_directories = self.config.get('data_ingestion', {}).get('scan_directories', [])
            
            for scan_dir in scan_directories:
                scan_path = Path(scan_dir)
                if not scan_path.exists():
                    continue
                
                # Process different file types
                for file_pattern in ['*.nessus', '*.xml', '*.csv']:
                    for scan_file in scan_path.glob(file_pattern):
                        if self._is_new_scan_file(scan_file):
                            self._process_scan_file(scan_file)
                            self._mark_scan_file_processed(scan_file)
            
        except Exception as e:
            self.logger.error(f"Error processing vulnerability updates: {e}")
    
    def _process_scan_file(self, file_path: Path):
        """Process individual scan file"""
        try:
            file_ext = file_path.suffix.lower()
            vulnerabilities = []
            
            if file_ext == '.nessus':
                vulnerabilities = self.data_ingestion.ingest_nessus_data(str(file_path))
            elif file_ext == '.xml':
                # Try OpenVAS format
                vulnerabilities = self.data_ingestion.ingest_openvas_data(str(file_path))
            elif file_ext == '.csv':
                # Try Qualys format first, then custom
                try:
                    vulnerabilities = self.data_ingestion.ingest_qualys_data(str(file_path))
                except:
                    # Fallback to custom format
                    custom_mapping = self.config.get('data_ingestion', {}).get('custom_csv_mapping', {})
                    vulnerabilities = self.data_ingestion.ingest_custom_csv(str(file_path), custom_mapping)
            
            if vulnerabilities:
                self._store_vulnerabilities(vulnerabilities)
                self.metrics['vulnerabilities_processed'] += len(vulnerabilities)
                self.logger.info(f"Processed {len(vulnerabilities)} vulnerabilities from {file_path}")
            
        except Exception as e:
            self.logger.error(f"Error processing scan file {file_path}: {e}")
    
    def _is_new_scan_file(self, file_path: Path) -> bool:
        """Check if scan file is new and needs processing"""
        # Simple implementation - check modification time
        # In production, you might want to track processed files in database
        try:
            mtime = file_path.stat().st_mtime
            current_time = time.time()
            
            # Process files modified in the last hour
            return (current_time - mtime) < 3600
            
        except:
            return False
    
    def _mark_scan_file_processed(self, file_path: Path):
        """Mark scan file as processed"""
        # Simple implementation - could be enhanced with database tracking
        pass
    
    def _store_vulnerabilities(self, vulnerabilities: List[AssetVulnerability]):
        """Store vulnerabilities in database"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                for vuln in vulnerabilities:
                    # Check for exploit information
                    exploit_info = self.threat_intel.check_exploit_availability(vuln.cve_id)
                    vuln.exploitability_score = 1.0 if exploit_info['available'] else 0.0
                    
                    conn.execute('''
                        INSERT OR REPLACE INTO asset_vulnerabilities (
                            asset_ip, cve_id, scanner_source, scan_date, port, service,
                            service_version, plugin_id, plugin_name, risk_score,
                            threat_score, exploitability_score, asset_criticality,
                            mitigation_status, false_positive
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        vuln.asset_ip, vuln.cve_id, vuln.scanner_source, vuln.scan_date,
                        vuln.port, vuln.service, vuln.service_version, vuln.plugin_id,
                        vuln.plugin_name, vuln.risk_score, vuln.threat_score,
                        vuln.exploitability_score, vuln.asset_criticality,
                        vuln.mitigation_status, vuln.false_positive
                    ))
                
                conn.commit()
                
        except Exception as e:
            self.logger.error(f"Error storing vulnerabilities: {e}")
    
    def _process_alert_enrichment(self):
        """Process alerts for vulnerability enrichment"""
        try:
            if not self.redis_client:
                return
            
            # Get pending alerts from Redis
            alert_keys = self.redis_client.keys("alert:*")
            
            for alert_key in alert_keys[:100]:  # Limit batch size
                try:
                    alert_data = self.redis_client.get(alert_key)
                    if not alert_data:
                        continue
                    
                    alert = json.loads(alert_data)
                    
                    # Enrich alert with vulnerability context
                    enriched_alert = self._enrich_alert(alert)
                    
                    if enriched_alert:
                        self._store_enriched_alert(enriched_alert)
                        self.metrics['alerts_enriched'] += 1
                        self.metrics['correlations_made'] += 1
                    
                    # Remove processed alert
                    self.redis_client.delete(alert_key)
                    
                except Exception as e:
                    self.logger.error(f"Error processing alert {alert_key}: {e}")
                    continue
                    
        except Exception as e:
            self.logger.error(f"Error in alert enrichment: {e}")
    
    def _enrich_alert(self, alert: Dict[str, Any]) -> Optional[CorrelatedAlert]:
        """Enrich single alert with vulnerability context"""
        try:
            # Get target IP from alert
            target_ip = alert.get('destination_ip') or alert.get('target_ip')
            if not target_ip:
                return None
            
            # Get threat context for target
            threat_context = self._get_threat_context(target_ip)
            
            if threat_context and threat_context.vulnerability_count > 0:
                # Enrich alert
                enriched_alert = self.alert_enrichment.enrich_alert_with_vulnerability_context(
                    alert, threat_context
                )
                return enriched_alert
            
        except Exception as e:
            self.logger.error(f"Error enriching alert: {e}")
        
        return None
    
    def _get_threat_context(self, asset_ip: str) -> Optional[ThreatContext]:
        """Get threat context for an asset"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                
                # Get vulnerability summary
                cursor = conn.execute('''
                    SELECT 
                        COUNT(*) as total_vulns,
                        SUM(CASE WHEN risk_score >= 9.0 THEN 1 ELSE 0 END) as critical_vulns,
                        SUM(CASE WHEN risk_score >= 7.0 AND risk_score < 9.0 THEN 1 ELSE 0 END) as high_vulns,
                        SUM(CASE WHEN risk_score >= 4.0 AND risk_score < 7.0 THEN 1 ELSE 0 END) as medium_vulns,
                        SUM(CASE WHEN risk_score < 4.0 THEN 1 ELSE 0 END) as low_vulns,
                        SUM(CASE WHEN exploitability_score > 0 THEN 1 ELSE 0 END) as exploitable_vulns,
                        AVG(threat_score) as avg_threat_score
                    FROM asset_vulnerabilities 
                    WHERE asset_ip = ? AND mitigation_status = 'open' AND false_positive = 0
                ''', (asset_ip,))
                
                row = cursor.fetchone()
                
                if row and row['total_vulns'] > 0:
                    # Get threat intelligence matches
                    cursor = conn.execute('''
                        SELECT DISTINCT cve_id FROM asset_vulnerabilities 
                        WHERE asset_ip = ? AND mitigation_status = 'open'
                    ''', (asset_ip,))
                    
                    cve_ids = [row[0] for row in cursor.fetchall()]
                    ti_matches = self.threat_intel.correlate_with_threat_feeds(cve_ids)
                    
                    # Get active exploits
                    active_exploits = []
                    for cve_id in cve_ids:
                        exploit_info = self.threat_intel.check_exploit_availability(cve_id)
                        if exploit_info['available'] and exploit_info['maturity'] == 'functional':
                            active_exploits.append(cve_id)
                    
                    threat_context = ThreatContext(
                        asset_ip=asset_ip,
                        vulnerability_count=row['total_vulns'],
                        critical_vulns=row['critical_vulns'] or 0,
                        high_vulns=row['high_vulns'] or 0,
                        medium_vulns=row['medium_vulns'] or 0,
                        low_vulns=row['low_vulns'] or 0,
                        exploitable_vulns=row['exploitable_vulns'] or 0,
                        risk_score=row['avg_threat_score'] or 0.0,
                        threat_intelligence_matches=list(ti_matches.keys()),
                        active_exploits=active_exploits
                    )
                    
                    return threat_context
                    
        except Exception as e:
            self.logger.error(f"Error getting threat context for {asset_ip}: {e}")
        
        return None
    
    def _store_enriched_alert(self, enriched_alert: CorrelatedAlert):
        """Store enriched alert in database"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute('''
                    INSERT INTO correlated_alerts (
                        alert_id, source_ip, destination_ip, alert_type, severity,
                        enhanced_severity, timestamp, asset_risk_score,
                        correlation_confidence, mitigation_recommendations
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    enriched_alert.alert_id,
                    enriched_alert.source_ip,
                    enriched_alert.destination_ip,
                    enriched_alert.alert_type,
                    enriched_alert.severity,
                    enriched_alert.enhanced_severity,
                    enriched_alert.timestamp,
                    enriched_alert.asset_risk_score,
                    enriched_alert.correlation_confidence,
                    json.dumps(enriched_alert.mitigation_recommendations)
                ))
                
                conn.commit()
                
        except Exception as e:
            self.logger.error(f"Error storing enriched alert: {e}")
    
    def _update_threat_context(self):
        """Update threat context cache for all assets"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # Get all assets with vulnerabilities
                cursor = conn.execute('''
                    SELECT DISTINCT asset_ip FROM asset_vulnerabilities
                    WHERE mitigation_status = 'open' AND false_positive = 0
                ''')
                
                asset_ips = [row[0] for row in cursor.fetchall()]
                
                for asset_ip in asset_ips:
                    threat_context = self._get_threat_context(asset_ip)
                    if threat_context:
                        # Store/update threat context
                        conn.execute('''
                            INSERT OR REPLACE INTO threat_context (
                                asset_ip, vulnerability_count, critical_vulns, high_vulns,
                                medium_vulns, low_vulns, exploitable_vulns, risk_score,
                                threat_intelligence_matches, active_exploits, network_exposure
                            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            threat_context.asset_ip,
                            threat_context.vulnerability_count,
                            threat_context.critical_vulns,
                            threat_context.high_vulns,
                            threat_context.medium_vulns,
                            threat_context.low_vulns,
                            threat_context.exploitable_vulns,
                            threat_context.risk_score,
                            json.dumps(threat_context.threat_intelligence_matches),
                            json.dumps(threat_context.active_exploits),
                            threat_context.network_exposure
                        ))
                
                conn.commit()
                
        except Exception as e:
            self.logger.error(f"Error updating threat context: {e}")
    
    def manual_scan_ingestion(self, file_path: str, scanner_type: str = "auto") -> bool:
        """Manually ingest vulnerability scan file"""
        try:
            scan_path = Path(file_path)
            if not scan_path.exists():
                self.logger.error(f"Scan file not found: {file_path}")
                return False
            
            vulnerabilities = []
            
            if scanner_type == "auto":
                # Auto-detect based on file extension and content
                if file_path.endswith('.nessus'):
                    scanner_type = "nessus"
                elif file_path.endswith('.xml'):
                    scanner_type = "openvas"
                elif file_path.endswith('.csv'):
                    scanner_type = "qualys"
            
            if scanner_type == "nessus":
                vulnerabilities = self.data_ingestion.ingest_nessus_data(file_path)
            elif scanner_type == "openvas":
                vulnerabilities = self.data_ingestion.ingest_openvas_data(file_path)
            elif scanner_type == "qualys":
                vulnerabilities = self.data_ingestion.ingest_qualys_data(file_path)
            elif scanner_type == "custom":
                custom_mapping = self.config.get('data_ingestion', {}).get('custom_csv_mapping', {})
                vulnerabilities = self.data_ingestion.ingest_custom_csv(file_path, custom_mapping)
            
            if vulnerabilities:
                self._store_vulnerabilities(vulnerabilities)
                self.metrics['vulnerabilities_processed'] += len(vulnerabilities)
                self.logger.info(f"Manually ingested {len(vulnerabilities)} vulnerabilities from {file_path}")
                return True
            else:
                self.logger.warning(f"No vulnerabilities found in {file_path}")
                return False
                
        except Exception as e:
            self.logger.error(f"Error in manual scan ingestion: {e}")
            return False
    
    def get_asset_vulnerability_summary(self, asset_ip: str) -> Dict[str, Any]:
        """Get vulnerability summary for an asset"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.row_factory = sqlite3.Row
                
                # Get vulnerability counts
                cursor = conn.execute('''
                    SELECT 
                        COUNT(*) as total_vulns,
                        SUM(CASE WHEN risk_score >= 9.0 THEN 1 ELSE 0 END) as critical_vulns,
                        SUM(CASE WHEN risk_score >= 7.0 AND risk_score < 9.0 THEN 1 ELSE 0 END) as high_vulns,
                        SUM(CASE WHEN risk_score >= 4.0 AND risk_score < 7.0 THEN 1 ELSE 0 END) as medium_vulns,
                        SUM(CASE WHEN risk_score < 4.0 THEN 1 ELSE 0 END) as low_vulns,
                        SUM(CASE WHEN exploitability_score > 0 THEN 1 ELSE 0 END) as exploitable_vulns,
                        AVG(risk_score) as avg_risk_score,
                        MAX(risk_score) as max_risk_score,
                        MIN(scan_date) as first_scan,
                        MAX(scan_date) as last_scan
                    FROM asset_vulnerabilities 
                    WHERE asset_ip = ? AND mitigation_status = 'open' AND false_positive = 0
                ''', (asset_ip,))
                
                summary = dict(cursor.fetchone())
                
                # Get top vulnerabilities
                cursor = conn.execute('''
                    SELECT cve_id, risk_score, service, port, plugin_name
                    FROM asset_vulnerabilities 
                    WHERE asset_ip = ? AND mitigation_status = 'open' AND false_positive = 0
                    ORDER BY risk_score DESC
                    LIMIT 10
                ''', (asset_ip,))
                
                summary['top_vulnerabilities'] = [dict(row) for row in cursor.fetchall()]
                
                return summary
                
        except Exception as e:
            self.logger.error(f"Error getting vulnerability summary for {asset_ip}: {e}")
            return {}
    
    def get_correlation_metrics(self) -> Dict[str, Any]:
        """Get correlation engine metrics"""
        return {
            'metrics': self.metrics,
            'processing_active': self.processing_active,
            'database_path': self.db_path,
            'threat_feeds_loaded': len(self.threat_intel.threat_feeds),
            'exploits_loaded': len(self.threat_intel.exploit_data)
        }

def main():
    """Main function for standalone execution"""
    import argparse
    
    parser = argparse.ArgumentParser(description='iSECTECH Vulnerability Correlation Engine')
    parser.add_argument('--config', default='/etc/nsm/vulnerability-correlation.yaml',
                       help='Configuration file path')
    parser.add_argument('--mode', choices=['daemon', 'ingest', 'summary'],
                       default='daemon', help='Operation mode')
    parser.add_argument('--scan-file', help='Scan file to ingest (ingest mode)')
    parser.add_argument('--scanner-type', choices=['auto', 'nessus', 'openvas', 'qualys', 'custom'],
                       default='auto', help='Scanner type for ingestion')
    parser.add_argument('--asset-ip', help='Asset IP for summary mode')
    
    args = parser.parse_args()
    
    # Initialize engine
    engine = VulnerabilityCorrelationEngine(args.config)
    
    if args.mode == 'daemon':
        try:
            engine.start_processing()
            
            # Keep running until interrupted
            while True:
                time.sleep(60)
                metrics = engine.get_correlation_metrics()
                engine.logger.info(f"Correlation metrics: {metrics}")
                
        except KeyboardInterrupt:
            engine.logger.info("Shutdown requested")
            engine.stop_processing()
            
    elif args.mode == 'ingest':
        if not args.scan_file:
            print("Scan file required for ingest mode")
            return
        
        success = engine.manual_scan_ingestion(args.scan_file, args.scanner_type)
        if success:
            print(f"Successfully ingested vulnerability data from {args.scan_file}")
        else:
            print(f"Failed to ingest vulnerability data from {args.scan_file}")
            
    elif args.mode == 'summary':
        if not args.asset_ip:
            print("Asset IP required for summary mode")
            return
        
        summary = engine.get_asset_vulnerability_summary(args.asset_ip)
        print(json.dumps(summary, indent=2, default=str))

if __name__ == "__main__":
    main()