# Logstash Enrichment Pipeline for iSECTECH SIEM
# Production-grade log enrichment with external data sources
# Integrates asset inventory, threat intelligence, and contextual data

input {
  # Input from normalized logs
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOSTS:localhost:9200}"]
    index => "isectech-security-logs-*"
    query => '{ "query": { "bool": { "must_not": { "exists": { "field": "enrichment.timestamp" } } } } }'
    schedule => "*/5 * * * *"  # Every 5 minutes
    scroll => "5m"
    size => 1000
    ssl => true
    ssl_certificate_verification => true
    cacert => "/opt/logstash/config/certs/ca.crt"
    user => "${ELASTICSEARCH_USERNAME}"
    password => "${ELASTICSEARCH_PASSWORD}"
    docinfo => true
    type => "enrichment_candidate"
  }
  
  # Real-time enrichment via Kafka
  kafka {
    bootstrap_servers => "${KAFKA_BROKERS:localhost:9092}"
    topics => ["logs-for-enrichment"]
    group_id => "logstash-enrichment"
    consumer_threads => 2
    decorate_events => true
    security_protocol => "SSL"
    ssl_truststore_location => "/opt/logstash/config/certs/kafka.truststore.jks"
    ssl_truststore_password => "${KAFKA_TRUSTSTORE_PASSWORD}"
    ssl_keystore_location => "/opt/logstash/config/certs/kafka.keystore.jks"
    ssl_keystore_password => "${KAFKA_KEYSTORE_PASSWORD}"
    codec => json
    type => "realtime_enrichment"
  }
}

filter {
  # Add enrichment processing metadata
  mutate {
    add_field => {
      "[@metadata][enrichment_start_time]" => "%{+yyyy-MM-dd'T'HH:mm:ss.SSSZ}"
      "[@metadata][enrichment_pipeline]" => "logstash-enrichment"
    }
  }
  
  # Asset inventory enrichment
  if [host][name] or [source][ip] or [destination][ip] {
    # Check asset inventory database
    jdbc_streaming {
      jdbc_driver_library => "/opt/logstash/vendor/jar/postgresql-42.6.0.jar"
      jdbc_driver_class => "org.postgresql.Driver"
      jdbc_connection_string => "${ASSET_DB_URL:jdbc:postgresql://localhost:5432/asset_inventory}"
      jdbc_user => "${ASSET_DB_USER:asset_reader}"
      jdbc_password => "${ASSET_DB_PASSWORD}"
      statement => "
        SELECT 
          asset_id, asset_type, operating_system, owner, business_unit, 
          criticality, location, compliance_tags
        FROM assets 
        WHERE hostname = :hostname OR :source_ip = ANY(ip_addresses) OR :dest_ip = ANY(ip_addresses)
        LIMIT 1
      "
      parameters => {
        "hostname" => "%{[host][name]}"
        "source_ip" => "%{[source][ip]}"
        "dest_ip" => "%{[destination][ip]}"
      }
      target => "[@metadata][asset_info]"
      tag_on_failure => ["_asset_lookup_failed"]
    }
    
    # Add asset enrichment fields if found
    if [@metadata][asset_info] and [@metadata][asset_info][0] {
      ruby {
        code => "
          asset = event.get('[@metadata][asset_info]')[0]
          if asset
            event.set('[asset][id]', asset['asset_id'])
            event.set('[asset][type]', asset['asset_type'])
            event.set('[asset][operating_system]', asset['operating_system'])
            event.set('[asset][owner]', asset['owner'])
            event.set('[asset][business_unit]', asset['business_unit'])
            event.set('[asset][criticality]', asset['criticality'])
            event.set('[asset][location]', asset['location'])
            event.set('[asset][compliance_tags]', asset['compliance_tags'].split(',') if asset['compliance_tags'])
            
            # Add enrichment source tracking
            sources = event.get('[enrichment][sources]') || []
            sources << 'asset_inventory'
            event.set('[enrichment][sources]', sources)
          end
        "
      }
    }
  }
  
  # Threat intelligence enrichment
  if [source][ip] or [destination][ip] or [url][domain] or [file][hash][md5] or [file][hash][sha256] {
    # Extract potential IOCs
    ruby {
      code => "
        iocs = []
        
        # Collect IOCs from various fields
        ['[source][ip]', '[destination][ip]', '[client][ip]'].each do |field|
          value = event.get(field)
          iocs << { 'value' => value, 'type' => 'ip' } if value
        end
        
        ['[url][domain]', '[destination][domain]', '[dns][question][name]'].each do |field|
          value = event.get(field)
          iocs << { 'value' => value, 'type' => 'domain' } if value
        end
        
        ['[file][hash][md5]', '[process][hash][md5]'].each do |field|
          value = event.get(field)
          iocs << { 'value' => value, 'type' => 'hash' } if value
        end
        
        ['[file][hash][sha256]', '[process][hash][sha256]'].each do |field|
          value = event.get(field)
          iocs << { 'value' => value, 'type' => 'hash' } if value
        end
        
        if event.get('[url][original]')
          iocs << { 'value' => event.get('[url][original]'), 'type' => 'url' }
        end
        
        event.set('[@metadata][iocs_to_check]', iocs.uniq)
      "
    }
    
    # Check each IOC against threat intelligence database
    if [@metadata][iocs_to_check] {
      ruby {
        code => "
          require 'net/http'
          require 'json'
          require 'uri'
          
          iocs = event.get('[@metadata][iocs_to_check]')
          threat_matches = []
          
          # Threat intelligence API endpoint
          threat_api_url = ENV['THREAT_INTEL_API_URL'] || 'http://localhost:8080/api/threat-intel/lookup'
          threat_api_key = ENV['THREAT_INTEL_API_KEY'] || ''
          
          iocs.each do |ioc|
            begin
              uri = URI(threat_api_url)
              http = Net::HTTP.new(uri.host, uri.port)
              http.use_ssl = uri.scheme == 'https'
              http.read_timeout = 5
              
              request = Net::HTTP::Post.new(uri)
              request['Content-Type'] = 'application/json'
              request['Authorization'] = \"Bearer #{threat_api_key}\" if !threat_api_key.empty?
              request.body = { 'indicator' => ioc['value'], 'type' => ioc['type'] }.to_json
              
              response = http.request(request)
              
              if response.code == '200'
                result = JSON.parse(response.body)
                if result['found'] && result['confidence_score'] > 30
                  threat_matches << {
                    'indicator' => ioc['value'],
                    'indicator_type' => ioc['type'],
                    'threat_type' => result['threat_type'],
                    'confidence_score' => result['confidence_score'],
                    'source' => result['source'],
                    'description' => result['description'],
                    'tags' => result['tags']
                  }
                end
              end
            rescue => e
              # Log error but continue processing
              event.set('[@metadata][threat_lookup_error]', e.message)
            end
          end
          
          if !threat_matches.empty?
            event.set('[threat][indicators]', threat_matches)
            event.set('[threat][indicator][matched]', true)
            event.set('[threat][indicator][count]', threat_matches.length)
            
            # Calculate overall threat score
            max_confidence = threat_matches.map { |m| m['confidence_score'] }.max
            event.set('[threat][indicator][confidence]', max_confidence)
            
            # Extract unique threat types and sources
            threat_types = threat_matches.map { |m| m['threat_type'] }.uniq
            sources = threat_matches.map { |m| m['source'] }.uniq
            
            event.set('[threat][indicator][types]', threat_types)
            event.set('[threat][indicator][sources]', sources)
            
            # Add to enrichment sources
            enrichment_sources = event.get('[enrichment][sources]') || []
            enrichment_sources << 'threat_intelligence'
            event.set('[enrichment][sources]', enrichment_sources)
          end
        "
      }
    }
  }
  
  # User context enrichment
  if [user][name] or [user][email] or [user][id] {
    # LDAP/Active Directory lookup
    ldap {
      host => "${LDAP_HOST:ldap.isectech.com}"
      port => 636
      use_ssl => true
      ssl_version => "TLSv1_2"
      base => "${LDAP_BASE_DN:dc=isectech,dc=com}"
      search_dn => "${LDAP_BIND_DN:cn=ldap-reader,ou=service-accounts,dc=isectech,dc=com}"
      search_password => "${LDAP_BIND_PASSWORD}"
      search_scope => "subtree"
      search_filter => "(|(sAMAccountName=%{[user][name]})(mail=%{[user][email]})(objectSid=%{[user][id]}))"
      attributes => [
        "department", "title", "manager", "memberOf", "lastLogon", 
        "badPwdCount", "lockoutTime", "userAccountControl"
      ]
      target => "[@metadata][user_ldap]"
      tag_on_failure => ["_ldap_lookup_failed"]
    }
    
    # Process LDAP results
    if [@metadata][user_ldap] and [@metadata][user_ldap][0] {
      ruby {
        code => "
          ldap_user = event.get('[@metadata][user_ldap]')[0]
          if ldap_user
            event.set('[user][department]', ldap_user['department'][0]) if ldap_user['department']
            event.set('[user][job_title]', ldap_user['title'][0]) if ldap_user['title']
            event.set('[user][manager]', ldap_user['manager'][0]) if ldap_user['manager']
            
            # Process group memberships
            if ldap_user['memberOf']
              groups = ldap_user['memberOf'].map { |dn| dn.split(',')[0].sub('CN=', '') }
              event.set('[user][groups]', groups)
              
              # Determine privileges based on groups
              privileges = []
              privileges << 'admin' if groups.any? { |g| g.match(/admin/i) }
              privileges << 'security_operator' if groups.any? { |g| g.match(/security/i) }
              privileges << 'privileged_user' if groups.any? { |g| g.match(/privileged|power/i) }
              privileges << 'user' if privileges.empty?
              
              event.set('[user][privileges]', privileges.uniq)
              
              # Calculate user risk score
              risk_score = 5  # Base score
              risk_score += 15 if privileges.include?('admin')
              risk_score += 10 if privileges.include?('security_operator')
              risk_score += 5 if privileges.include?('privileged_user')
              
              # Check for concerning indicators
              if ldap_user['badPwdCount'] && ldap_user['badPwdCount'][0].to_i > 3
                risk_score += 10
              end
              
              if ldap_user['lockoutTime'] && ldap_user['lockoutTime'][0] != '0'
                risk_score += 15
              end
              
              event.set('[user][risk_score]', [risk_score, 100].min)
            end
            
            # Process last logon
            if ldap_user['lastLogon'] && ldap_user['lastLogon'][0] != '0'
              # Convert Windows FILETIME to Unix timestamp
              filetime = ldap_user['lastLogon'][0].to_i
              unix_time = (filetime - 116444736000000000) / 10000000
              last_login = Time.at(unix_time).utc.iso8601
              event.set('[user][last_login]', last_login)
            end
            
            # Add to enrichment sources
            enrichment_sources = event.get('[enrichment][sources]') || []
            enrichment_sources << 'user_directory'
            event.set('[enrichment][sources]', enrichment_sources)
          end
        "
      }
    }
  }
  
  # Network context enrichment
  if [source][ip] or [destination][ip] {
    # GeoIP enrichment (if not already done)
    if ![source][geo] and [source][ip] {
      geoip {
        source => "[source][ip]"
        target => "[source][geo]"
        database => "/opt/logstash/vendor/geoip/GeoLite2-City.mmdb"
        tag_on_failure => ["_geoip_lookup_failure"]
      }
    }
    
    if ![destination][geo] and [destination][ip] {
      geoip {
        source => "[destination][ip]"
        target => "[destination][geo]"
        database => "/opt/logstash/vendor/geoip/GeoLite2-City.mmdb"
        tag_on_failure => ["_geoip_lookup_failure"]
      }
    }
    
    # Network topology enrichment
    ruby {
      code => "
        require 'ipaddr'
        require 'json'
        
        # Load network topology (in production, this would be from Redis/database)
        network_segments = [
          {
            'subnet' => '192.168.1.0/24',
            'zone' => 'corporate_workstations',
            'security_level' => 'medium',
            'network_type' => 'internal'
          },
          {
            'subnet' => '192.168.2.0/24',
            'zone' => 'database_servers', 
            'security_level' => 'high',
            'network_type' => 'internal'
          },
          {
            'subnet' => '192.168.3.0/24',
            'zone' => 'web_servers',
            'security_level' => 'high',
            'network_type' => 'dmz'
          },
          {
            'subnet' => '192.168.100.0/24',
            'zone' => 'security_management',
            'security_level' => 'critical',
            'network_type' => 'internal'
          }
        ]
        
        ['source', 'destination'].each do |direction|
          ip_field = \"[#{direction}][ip]\"
          ip_value = event.get(ip_field)
          
          if ip_value
            begin
              ip = IPAddr.new(ip_value)
              
              network_segments.each do |segment|
                subnet = IPAddr.new(segment['subnet'])
                if subnet.include?(ip)
                  event.set(\"[#{direction}][network][zone]\", segment['zone'])
                  event.set(\"[#{direction}][network][security_level]\", segment['security_level'])
                  event.set(\"[#{direction}][network][type]\", segment['network_type'])
                  event.set(\"[#{direction}][network][subnet]\", segment['subnet'])
                  break
                end
              end
              
              # Determine if IP is internal/external
              if ip.private?
                event.set(\"[#{direction}][network][category]\", 'internal')
              else
                event.set(\"[#{direction}][network][category]\", 'external')
              end
              
            rescue => e
              event.set('[@metadata][network_enrichment_error]', e.message)
            end
          end
        end
        
        # Add to enrichment sources
        enrichment_sources = event.get('[enrichment][sources]') || []
        enrichment_sources << 'network_topology'
        event.set('[enrichment][sources]', enrichment_sources)
      "
    }
  }
  
  # Vulnerability data enrichment
  if [threat][technique][id] or [rule][name] {
    # Extract CVE references
    ruby {
      code => "
        log_text = event.to_json
        cve_pattern = /CVE-\\d{4}-\\d{4,7}/i
        cves = log_text.scan(cve_pattern).uniq
        
        if !cves.empty?
          event.set('[@metadata][cves_found]', cves)
        end
      "
    }
    
    # Look up CVE information
    if [@metadata][cves_found] {
      ruby {
        code => "
          require 'net/http'
          require 'json'
          require 'uri'
          
          cves = event.get('[@metadata][cves_found]')
          vuln_data = []
          
          # NVD API endpoint (simplified - in production use proper NVD API)
          nvd_api_url = ENV['NVD_API_URL'] || 'https://services.nvd.nist.gov/rest/json/cves/2.0'
          
          cves.each do |cve|
            begin
              uri = URI(\"#{nvd_api_url}?cveId=#{cve}\")
              http = Net::HTTP.new(uri.host, uri.port)
              http.use_ssl = true
              http.read_timeout = 10
              
              request = Net::HTTP::Get.new(uri)
              request['User-Agent'] = 'iSECTECH-SIEM/1.0'
              
              response = http.request(request)
              
              if response.code == '200'
                result = JSON.parse(response.body)
                if result['vulnerabilities'] && !result['vulnerabilities'].empty?
                  vuln = result['vulnerabilities'][0]['cve']
                  
                  # Extract CVSS score
                  cvss_score = 0
                  if vuln['metrics'] && vuln['metrics']['cvssMetricV31']
                    cvss_score = vuln['metrics']['cvssMetricV31'][0]['cvssData']['baseScore']
                  elsif vuln['metrics'] && vuln['metrics']['cvssMetricV2']
                    cvss_score = vuln['metrics']['cvssMetricV2'][0]['cvssData']['baseScore']
                  end
                  
                  vuln_data << {
                    'cve_id' => cve,
                    'cvss_score' => cvss_score,
                    'severity' => cvss_score >= 9.0 ? 'critical' : 
                                 cvss_score >= 7.0 ? 'high' :
                                 cvss_score >= 4.0 ? 'medium' : 'low',
                    'description' => vuln['descriptions'][0]['value'] if vuln['descriptions'],
                    'published_date' => vuln['published']
                  }
                end
              end
            rescue => e
              # Continue processing other CVEs
              event.set('[@metadata][nvd_lookup_error]', e.message)
            end
          end
          
          if !vuln_data.empty?
            event.set('[vulnerability][cves]', vuln_data)
            event.set('[vulnerability][max_cvss_score]', vuln_data.map { |v| v['cvss_score'] }.max)
            event.set('[vulnerability][count]', vuln_data.length)
            
            # Add to enrichment sources
            enrichment_sources = event.get('[enrichment][sources]') || []
            enrichment_sources << 'vulnerability_database'
            event.set('[enrichment][sources]', enrichment_sources)
          end
        "
      }
    }
  }
  
  # Calculate enrichment score and risk assessment
  ruby {
    code => "
      enrichment_score = 0
      risk_factors = []
      
      # Asset criticality factor
      if event.get('[asset][criticality]')
        case event.get('[asset][criticality]')
        when 'critical'
          enrichment_score += 20
          risk_factors << 'critical_asset'
        when 'high'
          enrichment_score += 15
          risk_factors << 'high_value_asset'
        when 'medium'
          enrichment_score += 10
        end
      end
      
      # Threat intelligence factor
      if event.get('[threat][indicator][matched]')
        confidence = event.get('[threat][indicator][confidence]') || 0
        enrichment_score += (confidence * 0.3).to_i
        risk_factors << 'threat_intel_match'
      end
      
      # User risk factor
      if event.get('[user][risk_score]')
        user_risk = event.get('[user][risk_score]')
        enrichment_score += (user_risk * 0.2).to_i
        risk_factors << 'high_risk_user' if user_risk > 50
      end
      
      # Network security level factor
      ['source', 'destination'].each do |direction|
        security_level = event.get(\"[#{direction}][network][security_level]\")
        if security_level == 'critical'
          enrichment_score += 10
          risk_factors << \"#{direction}_critical_network\"
        elsif security_level == 'high'
          enrichment_score += 5
        end
      end
      
      # Vulnerability factor
      if event.get('[vulnerability][max_cvss_score]')
        cvss = event.get('[vulnerability][max_cvss_score]')
        enrichment_score += (cvss * 2).to_i
        risk_factors << 'vulnerability_present'
      end
      
      # External connectivity factor
      if event.get('[source][network][category]') == 'external' || 
         event.get('[destination][network][category]') == 'external'
        enrichment_score += 10
        risk_factors << 'external_communication'
      end
      
      event.set('[enrichment][score]', [enrichment_score, 100].min)
      event.set('[enrichment][risk_factors]', risk_factors.uniq)
      
      # Calculate overall risk level
      if enrichment_score >= 80
        event.set('[enrichment][risk_level]', 'critical')
      elsif enrichment_score >= 60
        event.set('[enrichment][risk_level]', 'high')
      elsif enrichment_score >= 40
        event.set('[enrichment][risk_level]', 'medium')
      else
        event.set('[enrichment][risk_level]', 'low')
      end
    "
  }
  
  # Add final enrichment metadata
  mutate {
    add_field => {
      "[enrichment][timestamp]" => "%{+yyyy-MM-dd'T'HH:mm:ss.SSSZ}"
      "[enrichment][version]" => "1.0.0"
      "[enrichment][pipeline]" => "logstash-enrichment"
    }
  }
  
  # Calculate enrichment processing time
  ruby {
    code => "
      start_time = event.get('[@metadata][enrichment_start_time]')
      if start_time
        require 'time'
        start_parsed = Time.parse(start_time)
        processing_time_ms = ((Time.now - start_parsed) * 1000).to_i
        event.set('[enrichment][processing_time_ms]', processing_time_ms)
      end
    "
  }
  
  # Clean up metadata fields
  mutate {
    remove_field => [
      "[@metadata][enrichment_start_time]",
      "[@metadata][asset_info]",
      "[@metadata][user_ldap]",
      "[@metadata][iocs_to_check]",
      "[@metadata][cves_found]"
    ]
  }
}

output {
  # Send enriched logs back to Elasticsearch
  if [type] == "enrichment_candidate" {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOSTS:localhost:9200}"]
      index => "%{[@metadata][_index]}"
      document_id => "%{[@metadata][_id]}"
      action => "update"
      doc_as_upsert => true
      
      # Security configuration
      ssl => true
      ssl_certificate_verification => true
      cacert => "/opt/logstash/config/certs/ca.crt"
      user => "${ELASTICSEARCH_USERNAME}"
      password => "${ELASTICSEARCH_PASSWORD}"
      
      # Performance tuning
      workers => 2
      flush_size => 500
      idle_flush_time => 5
    }
  }
  
  # Send real-time enriched logs to new index
  if [type] == "realtime_enrichment" {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOSTS:localhost:9200}"]
      index => "isectech-enriched-logs-%{+yyyy.MM.dd}"
      template_name => "isectech-enriched-logs"
      template => "/opt/logstash/templates/isectech-enriched-logs.json"
      template_overwrite => true
      
      # Security configuration
      ssl => true
      ssl_certificate_verification => true
      cacert => "/opt/logstash/config/certs/ca.crt"
      user => "${ELASTICSEARCH_USERNAME}"
      password => "${ELASTICSEARCH_PASSWORD}"
      
      # ILM policy
      ilm_enabled => true
      ilm_rollover_alias => "isectech-enriched-logs"
      ilm_pattern => "{now/d}-000001"
      ilm_policy => "isectech-enriched-logs-policy"
    }
  }
  
  # Send high-risk enriched events to alerts queue
  if [enrichment][risk_level] == "critical" or [enrichment][risk_level] == "high" {
    kafka {
      bootstrap_servers => "${KAFKA_BROKERS:localhost:9092}"
      topic_id => "enriched-high-risk-events"
      compression_type => "snappy"
      security_protocol => "SSL"
      ssl_truststore_location => "/opt/logstash/config/certs/kafka.truststore.jks"
      ssl_truststore_password => "${KAFKA_TRUSTSTORE_PASSWORD}"
      ssl_keystore_location => "/opt/logstash/config/certs/kafka.keystore.jks"
      ssl_keystore_password => "${KAFKA_KEYSTORE_PASSWORD}"
    }
  }
  
  # Metrics output
  statsd {
    host => "${STATSD_HOST:localhost}"
    port => 8125
    namespace => "isectech.siem.enrichment"
    increment => [
      "events.processed",
      "events.enriched.%{[enrichment][risk_level]}",
      "enrichment.sources.%{[enrichment][sources][0]}"
    ]
    timing => [
      "processing_time_ms" => "%{[enrichment][processing_time_ms]}"
    ]
  }
  
  # Debug output for development
  if "${LOGSTASH_DEBUG:false}" == "true" {
    stdout {
      codec => rubydebug {
        metadata => true
      }
    }
  }
}