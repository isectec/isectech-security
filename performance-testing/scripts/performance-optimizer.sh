#!/bin/bash

# iSECTECH Performance Optimization Implementation Script
# Automated performance optimization based on bottleneck analysis results

set -euo pipefail

# Script configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/../.." && pwd)"
PERFORMANCE_DIR="$PROJECT_ROOT/performance-testing"

# Color output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Logging functions
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

log_optimization() {
    echo -e "${PURPLE}[OPTIMIZE]${NC} $1"
}

log_progress() {
    echo -e "${CYAN}[PROGRESS]${NC} $1"
}

# Usage function
usage() {
    cat << EOF
Usage: $0 [OPTIONS] COMMAND

iSECTECH Performance Optimization Implementation Tool

COMMANDS:
    analyze-and-optimize    Run bottleneck analysis and apply optimizations
    database               Apply database performance optimizations
    api                    Apply API performance optimizations
    cache                  Implement caching strategies
    system                 Apply system-level optimizations
    monitoring             Implement performance monitoring optimizations
    validate               Validate optimization effectiveness
    rollback               Rollback applied optimizations
    
OPTIONS:
    -a, --analysis-file FILE    Bottleneck analysis file to base optimizations on
    -s, --strategy STRATEGY     Optimization strategy (conservative|balanced|aggressive) [default: balanced]
    -t, --test-run             Dry run - show what would be optimized without applying
    -v, --validate             Validate optimizations after applying
    -b, --backup               Create backup before applying optimizations
    -r, --rollback-id ID       Rollback optimization by ID
    -o, --output DIR           Output directory for optimization reports
    -h, --help                 Show this help message

EXAMPLES:
    # Run comprehensive optimization based on analysis
    $0 analyze-and-optimize -a ./analysis/bottlenecks.json -s balanced -v

    # Apply database optimizations only
    $0 database -s conservative -b -t

    # Implement Redis caching
    $0 cache -s aggressive -v

    # Rollback specific optimization
    $0 rollback -r opt_20240106_143022

EOF
}

# Backup and rollback functions
create_optimization_backup() {
    local optimization_id="$1"
    local backup_dir="$PERFORMANCE_DIR/backups/optimization_$optimization_id"
    
    log_info "Creating optimization backup: $optimization_id"
    mkdir -p "$backup_dir"
    
    # Backup database configurations
    if [[ -f "$PROJECT_ROOT/backend/config/postgres/production.yaml" ]]; then
        cp "$PROJECT_ROOT/backend/config/postgres/production.yaml" "$backup_dir/postgres_config.yaml.bak"
    fi
    
    # Backup API configurations  
    if [[ -f "$PROJECT_ROOT/app/config/app.ts" ]]; then
        cp "$PROJECT_ROOT/app/config/app.ts" "$backup_dir/app_config.ts.bak"
    fi
    
    # Backup Docker configurations
    if [[ -f "$PROJECT_ROOT/docker-compose.override.yml" ]]; then
        cp "$PROJECT_ROOT/docker-compose.override.yml" "$backup_dir/docker_compose.yml.bak"
    fi
    
    # Create backup manifest
    cat > "$backup_dir/manifest.json" << EOF
{
    "backup_id": "$optimization_id",
    "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%S.%3NZ)",
    "files_backed_up": [
        "postgres_config.yaml.bak",
        "app_config.ts.bak", 
        "docker_compose.yml.bak"
    ],
    "optimization_strategy": "${STRATEGY:-balanced}",
    "created_by": "performance-optimizer"
}
EOF
    
    log_success "Backup created: $backup_dir"
}

# Database optimization implementation
implement_database_optimizations() {
    local strategy="$1"
    local test_run="$2"
    local optimization_id="$3"
    
    log_optimization "Implementing database performance optimizations (strategy: $strategy)"
    
    # PostgreSQL optimization configurations
    local postgres_config_file="$PROJECT_ROOT/backend/config/postgres/optimized-production.yaml"
    
    if [[ "$test_run" == "false" ]]; then
        log_progress "Creating optimized PostgreSQL configuration..."
        
        cat > "$postgres_config_file" << EOF
# Optimized PostgreSQL Configuration for iSECTECH
# Generated by performance-optimizer on $(date)

# Connection settings optimized for high-load scenarios
max_connections: $(if [[ "$strategy" == "aggressive" ]]; then echo "300"; elif [[ "$strategy" == "balanced" ]]; then echo "200"; else echo "150"; fi)
shared_buffers: '$(if [[ "$strategy" == "aggressive" ]]; then echo "2GB"; elif [[ "$strategy" == "balanced" ]]; then echo "1GB"; else echo "512MB"; fi)'
effective_cache_size: '$(if [[ "$strategy" == "aggressive" ]]; then echo "6GB"; elif [[ "$strategy" == "balanced" ]]; then echo "4GB"; else echo "2GB"; fi)'

# Memory configuration
work_mem: '$(if [[ "$strategy" == "aggressive" ]]; then echo "32MB"; elif [[ "$strategy" == "balanced" ]]; then echo "16MB"; else echo "8MB"; fi)'
maintenance_work_mem: '$(if [[ "$strategy" == "aggressive" ]]; then echo "1GB"; elif [[ "$strategy" == "balanced" ]]; then echo "512MB"; else echo "256MB"; fi)'
temp_buffers: '$(if [[ "$strategy" == "aggressive" ]]; then echo "64MB"; elif [[ "$strategy" == "balanced" ]]; then echo "32MB"; else echo "16MB"; fi)'

# Query planning and execution
random_page_cost: $(if [[ "$strategy" == "aggressive" ]]; then echo "1.0"; elif [[ "$strategy" == "balanced" ]]; then echo "1.1"; else echo "1.5"; fi)  # SSD optimized
effective_io_concurrency: $(if [[ "$strategy" == "aggressive" ]]; then echo "200"; elif [[ "$strategy" == "balanced" ]]; then echo "100"; else echo "50"; fi)
max_worker_processes: $(if [[ "$strategy" == "aggressive" ]]; then echo "16"; elif [[ "$strategy" == "balanced" ]]; then echo "8"; else echo "4"; fi)
max_parallel_workers_per_gather: $(if [[ "$strategy" == "aggressive" ]]; then echo "4"; elif [[ "$strategy" == "balanced" ]]; then echo "2"; else echo "1"; fi)

# Write-ahead logging (WAL) optimization
wal_buffers: '$(if [[ "$strategy" == "aggressive" ]]; then echo "32MB"; elif [[ "$strategy" == "balanced" ]]; then echo "16MB"; else echo "8MB"; fi)'
checkpoint_completion_target: 0.9
checkpoint_timeout: '$(if [[ "$strategy" == "aggressive" ]]; then echo "15min"; elif [[ "$strategy" == "balanced" ]]; then echo "10min"; else echo "5min"; fi)'
max_wal_size: '$(if [[ "$strategy" == "aggressive" ]]; then echo "4GB"; elif [[ "$strategy" == "balanced" ]]; then echo "2GB"; else echo "1GB"; fi)'

# Query optimization
default_statistics_target: $(if [[ "$strategy" == "aggressive" ]]; then echo "500"; elif [[ "$strategy" == "balanced" ]]; then echo "250"; else echo "100"; fi)
constraint_exclusion: partition
enable_partition_pruning: on
enable_partitionwise_join: on
enable_partitionwise_aggregate: on

# Connection pooling optimization
shared_preload_libraries: 'pg_stat_statements'
track_io_timing: on
track_functions: pl
log_temp_files: 0

# Security-specific optimizations for iSECTECH
# Optimized for frequent alert queries and threat intelligence lookups
checkpoint_segments: $(if [[ "$strategy" == "aggressive" ]]; then echo "64"; elif [[ "$strategy" == "balanced" ]]; then echo "32"; else echo "16"; fi)
autovacuum_max_workers: 4
autovacuum_vacuum_cost_limit: $(if [[ "$strategy" == "aggressive" ]]; then echo "2000"; elif [[ "$strategy" == "balanced" ]]; then echo "1000"; else echo "500"; fi)

# Logging configuration for performance monitoring
log_min_duration_statement: $(if [[ "$strategy" == "aggressive" ]]; then echo "50"; elif [[ "$strategy" == "balanced" ]]; then echo "100"; else echo "250"; fi)  # Log slow queries
log_checkpoints: on
log_connections: off  # Reduce log volume in production
log_disconnections: off
log_lock_waits: on
log_statement: 'none'  # Disable for performance unless debugging
EOF

        log_success "PostgreSQL configuration optimized: $postgres_config_file"
    else
        log_info "[DRY RUN] Would create optimized PostgreSQL configuration"
    fi
    
    # Connection pooling optimization
    local pgbouncer_config="$PROJECT_ROOT/backend/config/pgbouncer/pgbouncer.ini"
    
    if [[ "$test_run" == "false" ]]; then
        mkdir -p "$(dirname "$pgbouncer_config")"
        
        cat > "$pgbouncer_config" << EOF
# PgBouncer Configuration for iSECTECH
# Optimized for security platform high-frequency operations

[databases]
isectech = host=postgres port=5432 dbname=isectech
isectech_readonly = host=postgres-readonly port=5432 dbname=isectech

[pgbouncer]
pool_mode = transaction
listen_port = 6432
listen_addr = *
auth_type = md5
auth_file = /etc/pgbouncer/userlist.txt

# Connection pool sizing based on optimization strategy
max_client_conn = $(if [[ "$strategy" == "aggressive" ]]; then echo "1000"; elif [[ "$strategy" == "balanced" ]]; then echo "500"; else echo "200"; fi)
default_pool_size = $(if [[ "$strategy" == "aggressive" ]]; then echo "50"; elif [[ "$strategy" == "balanced" ]]; then echo "25"; else echo "15"; fi)
min_pool_size = 5
reserve_pool_size = 10
max_db_connections = $(if [[ "$strategy" == "aggressive" ]]; then echo "100"; elif [[ "$strategy" == "balanced" ]]; then echo "50"; else echo "25"; fi)

# Performance tuning
server_reset_query = DISCARD ALL
server_check_query = select 1
server_check_delay = 30
server_fast_close = 1

# Timeouts optimized for security operations
server_lifetime = 3600
server_idle_timeout = 600
query_timeout = $(if [[ "$strategy" == "aggressive" ]]; then echo "300"; elif [[ "$strategy" == "balanced" ]]; then echo "120"; else echo "60"; fi)
client_idle_timeout = 3600

# Logging for monitoring
log_connections = 1
log_disconnections = 1
log_pooler_errors = 1
stats_period = 60

# Admin interface
admin_users = pgbouncer_admin
stats_users = pgbouncer_stats
EOF

        log_success "PgBouncer configuration optimized: $pgbouncer_config"
    else
        log_info "[DRY RUN] Would create optimized PgBouncer configuration"
    fi
    
    # Database query optimization recommendations
    local query_optimization_sql="$PROJECT_ROOT/backend/sql/performance_optimizations.sql"
    
    if [[ "$test_run" == "false" ]]; then
        mkdir -p "$(dirname "$query_optimization_sql")"
        
        cat > "$query_optimization_sql" << 'EOF'
-- iSECTECH Database Performance Optimizations
-- Apply these optimizations based on bottleneck analysis

-- Create indexes for frequent security queries
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_alerts_status_severity_created 
ON alerts (status, severity, created_at DESC) 
WHERE status IN ('ACTIVE', 'INVESTIGATING');

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_events_timestamp_event_type 
ON security_events (timestamp DESC, event_type) 
WHERE timestamp >= (NOW() - INTERVAL '30 days');

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_threats_confidence_severity 
ON threat_intelligence (confidence DESC, severity) 
WHERE confidence > 0.7;

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_users_last_login 
ON users (last_login_at DESC) 
WHERE active = true;

-- Partial indexes for performance-critical queries
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_alerts_unassigned 
ON alerts (created_at DESC) 
WHERE status = 'ACTIVE' AND assigned_to IS NULL;

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_events_high_risk 
ON security_events (timestamp DESC, source_ip, user_id) 
WHERE risk_score > 7;

-- Optimize frequent aggregation queries
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_alerts_dashboard_summary 
ON alerts (status, severity, created_at) 
WHERE created_at >= (NOW() - INTERVAL '24 hours');

-- Composite indexes for complex security correlation queries
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_events_correlation_analysis 
ON security_events (user_id, source_ip, timestamp DESC, event_type);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_alerts_threat_correlation 
ON alerts (threat_intelligence_id, status, created_at DESC) 
WHERE threat_intelligence_id IS NOT NULL;

-- Performance monitoring views
CREATE OR REPLACE VIEW v_slow_queries AS
SELECT 
    query,
    calls,
    total_time,
    mean_time,
    rows,
    100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent
FROM pg_stat_statements
WHERE mean_time > 100  -- Queries slower than 100ms
ORDER BY mean_time DESC;

CREATE OR REPLACE VIEW v_index_usage AS
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_tup_read,
    idx_tup_fetch,
    pg_size_pretty(pg_relation_size(indexname::regclass)) AS index_size
FROM pg_stat_user_indexes
ORDER BY idx_tup_read DESC;

-- Update table statistics for better query planning
ANALYZE alerts;
ANALYZE security_events;
ANALYZE threat_intelligence;
ANALYZE users;

-- Enable parallel query processing for large tables
ALTER TABLE security_events SET (parallel_workers = 4);
ALTER TABLE alerts SET (parallel_workers = 2);

-- Set appropriate fill factors for frequently updated tables
ALTER TABLE alerts SET (fillfactor = 90);
ALTER TABLE security_events SET (fillfactor = 95);

-- Optimize autovacuum settings for high-traffic tables
ALTER TABLE security_events SET (
    autovacuum_vacuum_scale_factor = 0.1,
    autovacuum_analyze_scale_factor = 0.05,
    autovacuum_vacuum_cost_limit = 1000
);

ALTER TABLE alerts SET (
    autovacuum_vacuum_scale_factor = 0.2,
    autovacuum_analyze_scale_factor = 0.1,
    autovacuum_vacuum_cost_limit = 500
);
EOF

        log_success "Database query optimizations created: $query_optimization_sql"
    else
        log_info "[DRY RUN] Would create database query optimization scripts"
    fi
}

# API optimization implementation
implement_api_optimizations() {
    local strategy="$1"
    local test_run="$2"
    local optimization_id="$3"
    
    log_optimization "Implementing API performance optimizations (strategy: $strategy)"
    
    # API configuration optimizations
    local api_config_file="$PROJECT_ROOT/app/config/performance.ts"
    
    if [[ "$test_run" == "false" ]]; then
        log_progress "Creating optimized API configuration..."
        
        cat > "$api_config_file" << EOF
// iSECTECH API Performance Configuration
// Generated by performance-optimizer on $(date)

export const performanceConfig = {
  // Request handling optimization
  requestTimeout: $(if [[ "$strategy" == "aggressive" ]]; then echo "60000"; elif [[ "$strategy" == "balanced" ]]; then echo "45000"; else echo "30000"; fi), // milliseconds
  maxRequestSize: '$(if [[ "$strategy" == "aggressive" ]]; then echo "50mb"; elif [[ "$strategy" == "balanced" ]]; then echo "25mb"; else echo "10mb"; fi)',
  
  // Connection pooling
  database: {
    connectionPoolSize: $(if [[ "$strategy" == "aggressive" ]]; then echo "50"; elif [[ "$strategy" == "balanced" ]]; then echo "25"; else echo "15"; fi),
    connectionTimeout: $(if [[ "$strategy" == "aggressive" ]]; then echo "10000"; elif [[ "$strategy" == "balanced" ]]; then echo "5000"; else echo "3000"; fi),
    idleTimeout: $(if [[ "$strategy" == "aggressive" ]]; then echo "300000"; elif [[ "$strategy" == "balanced" ]]; then echo "180000"; else echo "120000"; fi),
    maxRetries: 3,
    retryDelay: 1000
  },
  
  // Caching configuration
  cache: {
    enabled: true,
    defaultTTL: $(if [[ "$strategy" == "aggressive" ]]; then echo "600"; elif [[ "$strategy" == "balanced" ]]; then echo "300"; else echo "180"; fi), // seconds
    
    // Endpoint-specific cache settings
    endpoints: {
      '/api/dashboard/summary': { ttl: 60, staleWhileRevalidate: true },
      '/api/alerts': { ttl: 30, compression: true },
      '/api/threats': { ttl: 300, compression: true },
      '/api/events/search': { ttl: 120, compression: true },
      '/api/auth/profile': { ttl: 900, private: true }
    }
  },
  
  // Response optimization  
  compression: {
    enabled: true,
    level: $(if [[ "$strategy" == "aggressive" ]]; then echo "6"; elif [[ "$strategy" == "balanced" ]]; then echo "4"; else echo "2"; fi),
    threshold: 1024, // bytes
    algorithms: ['gzip', 'deflate', 'br']
  },
  
  // Rate limiting configuration
  rateLimiting: {
    enabled: true,
    windowMs: $(if [[ "$strategy" == "aggressive" ]]; then echo "60000"; elif [[ "$strategy" == "balanced" ]]; then echo "60000"; else echo "60000"; fi), // 1 minute
    maxRequests: $(if [[ "$strategy" == "aggressive" ]]; then echo "1000"; elif [[ "$strategy" == "balanced" ]]; then echo "500"; else echo "200"; fi),
    
    // Security-specific rate limits
    security: {
      '/api/auth/login': { windowMs: 900000, maxRequests: 5 }, // 15 minutes, 5 attempts
      '/api/events/search': { windowMs: 60000, maxRequests: 100 },
      '/api/alerts': { windowMs: 60000, maxRequests: 200 },
      '/api/threats': { windowMs: 60000, maxRequests: 150 }
    }
  },
  
  // Performance monitoring
  monitoring: {
    enabled: true,
    sampleRate: $(if [[ "$strategy" == "aggressive" ]]; then echo "1.0"; elif [[ "$strategy" == "balanced" ]]; then echo "0.1"; else echo "0.05"; fi),
    slowQueryThreshold: $(if [[ "$strategy" == "aggressive" ]]; then echo "100"; elif [[ "$strategy" == "balanced" ]]; then echo "250"; else echo "500"; fi), // ms
    
    metrics: {
      responseTime: true,
      throughput: true,
      errorRate: true,
      memoryUsage: true,
      databaseQueries: true
    }
  },
  
  // Security platform specific optimizations
  security: {
    // Threat detection optimization
    threatDetection: {
      batchSize: $(if [[ "$strategy" == "aggressive" ]]; then echo "1000"; elif [[ "$strategy" == "balanced" ]]; then echo "500"; else echo "200"; fi),
      processingInterval: $(if [[ "$strategy" == "aggressive" ]]; then echo "1000"; elif [[ "$strategy" == "balanced" ]]; then echo "2000"; else echo "5000"; fi), // ms
      concurrency: $(if [[ "$strategy" == "aggressive" ]]; then echo "8"; elif [[ "$strategy" == "balanced" ]]; then echo "4"; else echo "2"; fi)
    },
    
    // Alert correlation optimization
    alertCorrelation: {
      maxCorrelationWindow: $(if [[ "$strategy" == "aggressive" ]]; then echo "3600"; elif [[ "$strategy" == "balanced" ]]; then echo "1800"; else echo "900"; fi), // seconds
      batchProcessing: true,
      parallelProcessing: $(if [[ "$strategy" == "aggressive" ]]; then echo "true"; else echo "false"; fi)
    },
    
    // Event processing optimization
    eventProcessing: {
      bufferSize: $(if [[ "$strategy" == "aggressive" ]]; then echo "10000"; elif [[ "$strategy" == "balanced" ]]; then echo "5000"; else echo "2000"; fi),
      flushInterval: $(if [[ "$strategy" == "aggressive" ]]; then echo "5000"; elif [[ "$strategy" == "balanced" ]]; then echo "10000"; else echo "15000"; fi), // ms
      compression: true
    }
  },
  
  // Circuit breaker configuration
  circuitBreaker: {
    enabled: true,
    threshold: $(if [[ "$strategy" == "aggressive" ]]; then echo "10"; elif [[ "$strategy" == "balanced" ]]; then echo "5"; else echo "3"; fi), // failures
    timeout: $(if [[ "$strategy" == "aggressive" ]]; then echo "60000"; elif [[ "$strategy" == "balanced" ]]; then echo "30000"; else echo "10000"; fi), // ms
    resetTimeout: $(if [[ "$strategy" == "aggressive" ]]; then echo "30000"; elif [[ "$strategy" == "balanced" ]]; then echo "60000"; else echo "120000"; fi) // ms
  }
};

export default performanceConfig;
EOF

        log_success "API performance configuration created: $api_config_file"
    else
        log_info "[DRY RUN] Would create optimized API configuration"
    fi
    
    # Create middleware optimization
    local middleware_file="$PROJECT_ROOT/app/lib/middleware/performance-middleware.ts"
    
    if [[ "$test_run" == "false" ]]; then
        mkdir -p "$(dirname "$middleware_file")"
        
        cat > "$middleware_file" << 'EOF'
// iSECTECH Performance Optimization Middleware
// Implements caching, compression, and performance monitoring

import { NextRequest, NextResponse } from 'next/server';
import { performanceConfig } from '../../config/performance';

interface PerformanceMetrics {
  startTime: number;
  endTime: number;
  duration: number;
  endpoint: string;
  method: string;
  statusCode: number;
  responseSize: number;
  cacheHit: boolean;
}

const performanceMetrics: PerformanceMetrics[] = [];

// Response caching middleware
export async function cacheMiddleware(
  request: NextRequest,
  response: NextResponse
): Promise<NextResponse> {
  const { pathname } = request.nextUrl;
  const method = request.method;
  
  // Skip caching for non-GET requests and uncacheable endpoints
  if (method !== 'GET' || !performanceConfig.cache.enabled) {
    return response;
  }
  
  const cacheConfig = performanceConfig.cache.endpoints[pathname];
  if (!cacheConfig) {
    return response;
  }
  
  const cacheKey = `api:${pathname}:${request.nextUrl.searchParams.toString()}`;
  
  try {
    // Check cache first
    const cachedResponse = await getCachedResponse(cacheKey);
    if (cachedResponse) {
      // Add cache headers
      const cachedRes = new NextResponse(cachedResponse.body, {
        status: cachedResponse.status,
        headers: {
          ...cachedResponse.headers,
          'X-Cache': 'HIT',
          'X-Cache-TTL': cacheConfig.ttl.toString(),
        },
      });
      
      recordMetric({
        startTime: Date.now(),
        endTime: Date.now(),
        duration: 0,
        endpoint: pathname,
        method,
        statusCode: cachedResponse.status,
        responseSize: cachedResponse.body?.length || 0,
        cacheHit: true,
      });
      
      return cachedRes;
    }
    
    // Cache miss - store response for future use
    const responseClone = response.clone();
    const body = await responseClone.text();
    
    await cacheResponse(cacheKey, {
      body,
      status: response.status,
      headers: Object.fromEntries(response.headers.entries()),
    }, cacheConfig.ttl);
    
    // Add cache headers to original response
    response.headers.set('X-Cache', 'MISS');
    response.headers.set('X-Cache-TTL', cacheConfig.ttl.toString());
    
  } catch (error) {
    console.error('Cache middleware error:', error);
  }
  
  return response;
}

// Performance monitoring middleware
export function performanceMonitoringMiddleware(
  request: NextRequest,
  response: NextResponse,
  startTime: number
): NextResponse {
  if (!performanceConfig.monitoring.enabled) {
    return response;
  }
  
  const endTime = Date.now();
  const duration = endTime - startTime;
  const { pathname } = request.nextUrl;
  
  const metric: PerformanceMetrics = {
    startTime,
    endTime,
    duration,
    endpoint: pathname,
    method: request.method,
    statusCode: response.status,
    responseSize: parseInt(response.headers.get('content-length') || '0'),
    cacheHit: response.headers.get('X-Cache') === 'HIT',
  };
  
  recordMetric(metric);
  
  // Add performance headers
  response.headers.set('X-Response-Time', `${duration}ms`);
  response.headers.set('X-Timestamp', endTime.toString());
  
  // Log slow requests
  if (duration > performanceConfig.monitoring.slowQueryThreshold) {
    console.warn(`Slow API request: ${request.method} ${pathname} took ${duration}ms`);
  }
  
  return response;
}

// Compression middleware
export async function compressionMiddleware(
  request: NextRequest,
  response: NextResponse
): Promise<NextResponse> {
  if (!performanceConfig.compression.enabled) {
    return response;
  }
  
  const acceptEncoding = request.headers.get('accept-encoding') || '';
  const contentLength = parseInt(response.headers.get('content-length') || '0');
  
  // Skip compression for small responses
  if (contentLength < performanceConfig.compression.threshold) {
    return response;
  }
  
  // Determine best compression algorithm
  let encoding: string | null = null;
  if (acceptEncoding.includes('br')) {
    encoding = 'br';
  } else if (acceptEncoding.includes('gzip')) {
    encoding = 'gzip';
  } else if (acceptEncoding.includes('deflate')) {
    encoding = 'deflate';
  }
  
  if (encoding) {
    response.headers.set('Content-Encoding', encoding);
    response.headers.set('Vary', 'Accept-Encoding');
  }
  
  return response;
}

// Circuit breaker middleware
const circuitBreakerStates = new Map<string, {
  failures: number;
  lastFailureTime: number;
  state: 'CLOSED' | 'OPEN' | 'HALF_OPEN';
}>();

export function circuitBreakerMiddleware(
  request: NextRequest,
  response: NextResponse
): NextResponse {
  if (!performanceConfig.circuitBreaker.enabled) {
    return response;
  }
  
  const { pathname } = request.nextUrl;
  const state = circuitBreakerStates.get(pathname) || {
    failures: 0,
    lastFailureTime: 0,
    state: 'CLOSED' as const,
  };
  
  const now = Date.now();
  
  // Check if circuit breaker should reset
  if (
    state.state === 'OPEN' &&
    now - state.lastFailureTime > performanceConfig.circuitBreaker.resetTimeout
  ) {
    state.state = 'HALF_OPEN';
    state.failures = 0;
  }
  
  // Handle circuit breaker states
  if (state.state === 'OPEN') {
    return new NextResponse('Service temporarily unavailable', { status: 503 });
  }
  
  // Record success/failure
  if (response.status >= 500) {
    state.failures++;
    state.lastFailureTime = now;
    
    if (state.failures >= performanceConfig.circuitBreaker.threshold) {
      state.state = 'OPEN';
      console.warn(`Circuit breaker opened for ${pathname}`);
    }
  } else if (state.state === 'HALF_OPEN') {
    state.state = 'CLOSED';
    state.failures = 0;
  }
  
  circuitBreakerStates.set(pathname, state);
  
  return response;
}

// Utility functions
async function getCachedResponse(key: string): Promise<any> {
  // Implement Redis or in-memory cache lookup
  // This is a placeholder - implement with your caching solution
  return null;
}

async function cacheResponse(key: string, data: any, ttl: number): Promise<void> {
  // Implement Redis or in-memory cache storage
  // This is a placeholder - implement with your caching solution
}

function recordMetric(metric: PerformanceMetrics): void {
  performanceMetrics.push(metric);
  
  // Keep only last 1000 metrics to prevent memory leaks
  if (performanceMetrics.length > 1000) {
    performanceMetrics.splice(0, performanceMetrics.length - 1000);
  }
  
  // Send metrics to monitoring system (Prometheus, etc.)
  if (Math.random() < performanceConfig.monitoring.sampleRate) {
    sendMetricsToMonitoring(metric);
  }
}

function sendMetricsToMonitoring(metric: PerformanceMetrics): void {
  // Implement metrics export to Prometheus/Grafana
  // This is a placeholder - implement with your monitoring solution
  console.log('Performance metric:', metric);
}

// Export performance metrics for monitoring
export function getPerformanceMetrics(): PerformanceMetrics[] {
  return performanceMetrics.slice();
}

export function getPerformanceSummary(): {
  averageResponseTime: number;
  totalRequests: number;
  errorRate: number;
  cacheHitRate: number;
} {
  if (performanceMetrics.length === 0) {
    return {
      averageResponseTime: 0,
      totalRequests: 0,
      errorRate: 0,
      cacheHitRate: 0,
    };
  }
  
  const totalRequests = performanceMetrics.length;
  const averageResponseTime =
    performanceMetrics.reduce((sum, m) => sum + m.duration, 0) / totalRequests;
  const errorCount = performanceMetrics.filter(m => m.statusCode >= 400).length;
  const errorRate = (errorCount / totalRequests) * 100;
  const cacheHits = performanceMetrics.filter(m => m.cacheHit).length;
  const cacheHitRate = (cacheHits / totalRequests) * 100;
  
  return {
    averageResponseTime,
    totalRequests,
    errorRate,
    cacheHitRate,
  };
}
EOF

        log_success "Performance middleware created: $middleware_file"
    else
        log_info "[DRY RUN] Would create performance optimization middleware"
    fi
}

# Cache implementation
implement_caching_strategies() {
    local strategy="$1"
    local test_run="$2"
    local optimization_id="$3"
    
    log_optimization "Implementing caching strategies (strategy: $strategy)"
    
    # Redis cache configuration
    local redis_config_file="$PROJECT_ROOT/backend/config/redis/redis.conf"
    
    if [[ "$test_run" == "false" ]]; then
        mkdir -p "$(dirname "$redis_config_file")"
        
        cat > "$redis_config_file" << EOF
# Redis Configuration for iSECTECH Caching
# Optimized for security platform workloads

# Memory management
maxmemory $(if [[ "$strategy" == "aggressive" ]]; then echo "2gb"; elif [[ "$strategy" == "balanced" ]]; then echo "1gb"; else echo "512mb"; fi)
maxmemory-policy allkeys-lru
maxmemory-samples 10

# Performance optimization
tcp-keepalive 300
timeout 300
tcp-backlog 511

# Persistence configuration (optimized for caching)
save $(if [[ "$strategy" == "aggressive" ]]; then echo "300 10"; elif [[ "$strategy" == "balanced" ]]; then echo "900 1"; else echo "1800 1"; fi)
stop-writes-on-bgsave-error yes
rdbcompression yes
rdbchecksum yes

# Network optimization
bind 0.0.0.0
port 6379
protected-mode yes
requirepass "$(openssl rand -base64 32)"

# Client connection optimization
maxclients $(if [[ "$strategy" == "aggressive" ]]; then echo "10000"; elif [[ "$strategy" == "balanced" ]]; then echo "5000"; else echo "1000"; fi)

# Logging
loglevel notice
logfile "/var/log/redis/redis-server.log"

# Performance tuning for security platform
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
list-max-ziplist-size -2
list-compress-depth 0
set-max-intset-entries 512
zset-max-ziplist-entries 128
zset-max-ziplist-value 64

# Security-specific cache patterns
# Optimized for alert caching, threat intelligence, and user sessions
databases 16
EOF

        log_success "Redis configuration created: $redis_config_file"
    else
        log_info "[DRY RUN] Would create Redis caching configuration"
    fi
    
    # Application-level cache implementation
    local cache_service_file="$PROJECT_ROOT/app/lib/cache/cache-service.ts"
    
    if [[ "$test_run" == "false" ]]; then
        mkdir -p "$(dirname "$cache_service_file")"
        
        cat > "$cache_service_file" << 'EOF'
// iSECTECH Cache Service Implementation
// Multi-layer caching for optimal performance

import Redis from 'ioredis';
import { performanceConfig } from '../../config/performance';

interface CacheOptions {
  ttl?: number;
  compress?: boolean;
  serialize?: boolean;
  tags?: string[];
}

interface CacheEntry {
  data: any;
  timestamp: number;
  ttl: number;
  compressed: boolean;
  tags?: string[];
}

class CacheService {
  private redis: Redis;
  private memoryCache: Map<string, CacheEntry>;
  private compressionEnabled: boolean;

  constructor() {
    // Initialize Redis connection
    this.redis = new Redis({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
      password: process.env.REDIS_PASSWORD,
      retryDelayOnFailover: 100,
      maxRetriesPerRequest: 3,
      lazyConnect: true,
    });

    // Initialize in-memory cache for frequently accessed items
    this.memoryCache = new Map();
    this.compressionEnabled = performanceConfig.compression.enabled;

    // Setup cache cleanup interval
    setInterval(() => this.cleanupMemoryCache(), 300000); // 5 minutes
  }

  // Multi-layer cache get (L1: memory, L2: Redis)
  async get<T>(key: string): Promise<T | null> {
    try {
      // Try L1 cache (memory) first
      const memoryCacheEntry = this.memoryCache.get(key);
      if (memoryCacheEntry && this.isValidCacheEntry(memoryCacheEntry)) {
        return this.deserializeData(memoryCacheEntry.data, memoryCacheEntry.compressed);
      }

      // Try L2 cache (Redis)
      const redisData = await this.redis.get(key);
      if (redisData) {
        const cacheEntry: CacheEntry = JSON.parse(redisData);
        
        if (this.isValidCacheEntry(cacheEntry)) {
          // Store in L1 cache for faster future access
          this.memoryCache.set(key, cacheEntry);
          return this.deserializeData(cacheEntry.data, cacheEntry.compressed);
        }
      }

      return null;
    } catch (error) {
      console.error('Cache get error:', error);
      return null;
    }
  }

  // Multi-layer cache set
  async set<T>(key: string, data: T, options: CacheOptions = {}): Promise<void> {
    try {
      const ttl = options.ttl || performanceConfig.cache.defaultTTL;
      const compress = options.compress || false;
      const serializedData = compress ? this.compressData(data) : data;
      
      const cacheEntry: CacheEntry = {
        data: serializedData,
        timestamp: Date.now(),
        ttl: ttl * 1000, // Convert to milliseconds
        compressed: compress,
        tags: options.tags,
      };

      // Store in Redis (L2)
      await this.redis.setex(key, ttl, JSON.stringify(cacheEntry));

      // Store in memory cache (L1) for frequently accessed items
      if (this.shouldCacheInMemory(key)) {
        this.memoryCache.set(key, cacheEntry);
      }
    } catch (error) {
      console.error('Cache set error:', error);
    }
  }

  // Security-specific cache operations
  async cacheAlerts(alerts: any[], ttl: number = 300): Promise<void> {
    const key = 'alerts:active';
    await this.set(key, alerts, { ttl, compress: true, tags: ['alerts'] });
  }

  async getCachedAlerts(): Promise<any[] | null> {
    return await this.get<any[]>('alerts:active');
  }

  async cacheThreatIntelligence(threats: any[], ttl: number = 1800): Promise<void> {
    const key = 'threats:intelligence';
    await this.set(key, threats, { ttl, compress: true, tags: ['threats'] });
  }

  async getCachedThreatIntelligence(): Promise<any[] | null> {
    return await this.get<any[]>('threats:intelligence');
  }

  async cacheDashboardSummary(summary: any, ttl: number = 60): Promise<void> {
    const key = 'dashboard:summary';
    await this.set(key, summary, { ttl, tags: ['dashboard'] });
  }

  async getCachedDashboardSummary(): Promise<any | null> {
    return await this.get<any>('dashboard:summary');
  }

  // User session caching
  async cacheUserSession(userId: string, sessionData: any, ttl: number = 3600): Promise<void> {
    const key = `session:${userId}`;
    await this.set(key, sessionData, { ttl, tags: ['sessions'] });
  }

  async getUserSession(userId: string): Promise<any | null> {
    const key = `session:${userId}`;
    return await this.get<any>(key);
  }

  // Cache invalidation
  async invalidateByKey(key: string): Promise<void> {
    try {
      await this.redis.del(key);
      this.memoryCache.delete(key);
    } catch (error) {
      console.error('Cache invalidation error:', error);
    }
  }

  async invalidateByTag(tag: string): Promise<void> {
    try {
      const keys = await this.redis.keys('*');
      const keysToDelete = [];

      for (const key of keys) {
        const data = await this.redis.get(key);
        if (data) {
          const cacheEntry: CacheEntry = JSON.parse(data);
          if (cacheEntry.tags?.includes(tag)) {
            keysToDelete.push(key);
          }
        }
      }

      if (keysToDelete.length > 0) {
        await this.redis.del(...keysToDelete);
      }

      // Clean memory cache
      for (const [key, entry] of this.memoryCache.entries()) {
        if (entry.tags?.includes(tag)) {
          this.memoryCache.delete(key);
        }
      }
    } catch (error) {
      console.error('Cache tag invalidation error:', error);
    }
  }

  // Cache statistics
  async getStats(): Promise<{
    redisKeys: number;
    memoryKeys: number;
    memoryUsage: number;
    hitRate: number;
  }> {
    try {
      const redisKeys = await this.redis.dbsize();
      const memoryKeys = this.memoryCache.size;
      const memoryUsage = this.calculateMemoryUsage();
      const hitRate = await this.calculateHitRate();

      return {
        redisKeys,
        memoryKeys,
        memoryUsage,
        hitRate,
      };
    } catch (error) {
      console.error('Cache stats error:', error);
      return { redisKeys: 0, memoryKeys: 0, memoryUsage: 0, hitRate: 0 };
    }
  }

  // Private helper methods
  private isValidCacheEntry(entry: CacheEntry): boolean {
    const now = Date.now();
    return now - entry.timestamp < entry.ttl;
  }

  private shouldCacheInMemory(key: string): boolean {
    // Cache frequently accessed items in memory
    const memoryPriorityPatterns = ['dashboard:', 'alerts:active', 'session:'];
    return memoryPriorityPatterns.some(pattern => key.includes(pattern));
  }

  private compressData(data: any): string {
    // Implement compression (gzip, etc.)
    return JSON.stringify(data);
  }

  private deserializeData<T>(data: any, compressed: boolean): T {
    if (compressed) {
      // Implement decompression
      return JSON.parse(data);
    }
    return data;
  }

  private cleanupMemoryCache(): void {
    const now = Date.now();
    for (const [key, entry] of this.memoryCache.entries()) {
      if (now - entry.timestamp >= entry.ttl) {
        this.memoryCache.delete(key);
      }
    }
  }

  private calculateMemoryUsage(): number {
    // Rough estimation of memory usage
    return JSON.stringify([...this.memoryCache.entries()]).length;
  }

  private async calculateHitRate(): Promise<number> {
    // Implement hit rate calculation based on your metrics
    return 0.85; // Placeholder
  }
}

// Export singleton instance
export const cacheService = new CacheService();
export default cacheService;
EOF

        log_success "Cache service implementation created: $cache_service_file"
    else
        log_info "[DRY RUN] Would create cache service implementation"
    fi
}

# System optimization implementation
implement_system_optimizations() {
    local strategy="$1"
    local test_run="$2"
    local optimization_id="$3"
    
    log_optimization "Implementing system-level optimizations (strategy: $strategy)"
    
    # Docker Compose optimizations
    local docker_override_file="$PROJECT_ROOT/docker-compose.performance.yml"
    
    if [[ "$test_run" == "false" ]]; then
        cat > "$docker_override_file" << EOF
# Docker Compose Performance Optimizations for iSECTECH
# Generated by performance-optimizer

version: '3.8'

services:
  # Database optimizations
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_SHARED_PRELOAD_LIBRARIES=pg_stat_statements
    command: >
      postgres
      -c max_connections=$(if [[ "$strategy" == "aggressive" ]]; then echo "300"; elif [[ "$strategy" == "balanced" ]]; then echo "200"; else echo "150"; fi)
      -c shared_buffers=$(if [[ "$strategy" == "aggressive" ]]; then echo "2GB"; elif [[ "$strategy" == "balanced" ]]; then echo "1GB"; else echo "512MB"; fi)
      -c effective_cache_size=$(if [[ "$strategy" == "aggressive" ]]; then echo "6GB"; elif [[ "$strategy" == "balanced" ]]; then echo "4GB"; else echo "2GB"; fi)
      -c work_mem=$(if [[ "$strategy" == "aggressive" ]]; then echo "32MB"; elif [[ "$strategy" == "balanced" ]]; then echo "16MB"; else echo "8MB"; fi)
      -c maintenance_work_mem=$(if [[ "$strategy" == "aggressive" ]]; then echo "1GB"; elif [[ "$strategy" == "balanced" ]]; then echo "512MB"; else echo "256MB"; fi)
      -c checkpoint_completion_target=0.9
      -c wal_buffers=$(if [[ "$strategy" == "aggressive" ]]; then echo "32MB"; elif [[ "$strategy" == "balanced" ]]; then echo "16MB"; else echo "8MB"; fi)
      -c default_statistics_target=$(if [[ "$strategy" == "aggressive" ]]; then echo "500"; elif [[ "$strategy" == "balanced" ]]; then echo "250"; else echo "100"; fi)
    deploy:
      resources:
        limits:
          cpus: '$(if [[ "$strategy" == "aggressive" ]]; then echo "4.0"; elif [[ "$strategy" == "balanced" ]]; then echo "2.0"; else echo "1.0"; fi)'
          memory: $(if [[ "$strategy" == "aggressive" ]]; then echo "8G"; elif [[ "$strategy" == "balanced" ]]; then echo "4G"; else echo "2G"; fi)
        reservations:
          cpus: '$(if [[ "$strategy" == "aggressive" ]]; then echo "2.0"; elif [[ "$strategy" == "balanced" ]]; then echo "1.0"; else echo "0.5"; fi)'
          memory: $(if [[ "$strategy" == "aggressive" ]]; then echo "4G"; elif [[ "$strategy" == "balanced" ]]; then echo "2G"; else echo "1G"; fi)

  # Redis cache optimizations
  redis:
    image: redis:7-alpine
    command: >
      redis-server
      --maxmemory $(if [[ "$strategy" == "aggressive" ]]; then echo "2gb"; elif [[ "$strategy" == "balanced" ]]; then echo "1gb"; else echo "512mb"; fi)
      --maxmemory-policy allkeys-lru
      --tcp-keepalive 300
      --timeout 300
      --save $(if [[ "$strategy" == "aggressive" ]]; then echo "300 10"; elif [[ "$strategy" == "balanced" ]]; then echo "900 1"; else echo "1800 1"; fi)
    deploy:
      resources:
        limits:
          cpus: '$(if [[ "$strategy" == "aggressive" ]]; then echo "2.0"; elif [[ "$strategy" == "balanced" ]]; then echo "1.0"; else echo "0.5"; fi)'
          memory: $(if [[ "$strategy" == "aggressive" ]]; then echo "3G"; elif [[ "$strategy" == "balanced" ]]; then echo "2G"; else echo "1G"; fi)
        reservations:
          cpus: '$(if [[ "$strategy" == "aggressive" ]]; then echo "1.0"; elif [[ "$strategy" == "balanced" ]]; then echo "0.5"; else echo "0.25"; fi)'
          memory: $(if [[ "$strategy" == "aggressive" ]]; then echo "2G"; elif [[ "$strategy" == "balanced" ]]; then echo "1G"; else echo "512M"; fi)

  # Application optimizations
  app:
    environment:
      - NODE_ENV=production
      - NODE_OPTIONS=--max-old-space-size=$(if [[ "$strategy" == "aggressive" ]]; then echo "4096"; elif [[ "$strategy" == "balanced" ]]; then echo "2048"; else echo "1024"; fi)
      - UV_THREADPOOL_SIZE=$(if [[ "$strategy" == "aggressive" ]]; then echo "16"; elif [[ "$strategy" == "balanced" ]]; then echo "8"; else echo "4"; fi)
    deploy:
      replicas: $(if [[ "$strategy" == "aggressive" ]]; then echo "4"; elif [[ "$strategy" == "balanced" ]]; then echo "2"; else echo "1"; fi)
      resources:
        limits:
          cpus: '$(if [[ "$strategy" == "aggressive" ]]; then echo "2.0"; elif [[ "$strategy" == "balanced" ]]; then echo "1.0"; else echo "0.5"; fi)'
          memory: $(if [[ "$strategy" == "aggressive" ]]; then echo "4G"; elif [[ "$strategy" == "balanced" ]]; then echo "2G"; else echo "1G"; fi)
        reservations:
          cpus: '$(if [[ "$strategy" == "aggressive" ]]; then echo "1.0"; elif [[ "$strategy" == "balanced" ]]; then echo "0.5"; else echo "0.25"; fi)'
          memory: $(if [[ "$strategy" == "aggressive" ]]; then echo "2G"; elif [[ "$strategy" == "balanced" ]]; then echo "1G"; else echo "512M"; fi)
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback

  # Nginx reverse proxy optimizations
  nginx:
    image: nginx:alpine
    volumes:
      - ./nginx/nginx-optimized.conf:/etc/nginx/nginx.conf:ro
    deploy:
      resources:
        limits:
          cpus: '$(if [[ "$strategy" == "aggressive" ]]; then echo "1.0"; elif [[ "$strategy" == "balanced" ]]; then echo "0.5"; else echo "0.25"; fi)'
          memory: $(if [[ "$strategy" == "aggressive" ]]; then echo "512M"; elif [[ "$strategy" == "balanced" ]]; then echo "256M"; else echo "128M"; fi)

networks:
  default:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.name: isectech-optimized

volumes:
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/isectech/data/postgres
  
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/isectech/data/redis
EOF

        log_success "Docker Compose optimizations created: $docker_override_file"
    else
        log_info "[DRY RUN] Would create Docker Compose optimizations"
    fi
    
    # Nginx optimization configuration
    local nginx_config_file="$PROJECT_ROOT/nginx/nginx-optimized.conf"
    
    if [[ "$test_run" == "false" ]]; then
        mkdir -p "$(dirname "$nginx_config_file")"
        
        cat > "$nginx_config_file" << EOF
# Optimized Nginx Configuration for iSECTECH
# High-performance reverse proxy and static file serving

worker_processes auto;
worker_rlimit_nofile $(if [[ "$strategy" == "aggressive" ]]; then echo "65535"; elif [[ "$strategy" == "balanced" ]]; then echo "32768"; else echo "16384"; fi);

error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections $(if [[ "$strategy" == "aggressive" ]]; then echo "4096"; elif [[ "$strategy" == "balanced" ]]; then echo "2048"; else echo "1024"; fi);
    use epoll;
    multi_accept on;
    accept_mutex off;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Performance optimizations
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout $(if [[ "$strategy" == "aggressive" ]]; then echo "300"; elif [[ "$strategy" == "balanced" ]]; then echo "180"; else echo "65"; fi);
    keepalive_requests $(if [[ "$strategy" == "aggressive" ]]; then echo "10000"; elif [[ "$strategy" == "balanced" ]]; then echo "1000"; else echo "100"; fi);

    # Buffer optimizations
    client_body_buffer_size $(if [[ "$strategy" == "aggressive" ]]; then echo "128k"; elif [[ "$strategy" == "balanced" ]]; then echo "64k"; else echo "32k"; fi);
    client_header_buffer_size $(if [[ "$strategy" == "aggressive" ]]; then echo "16k"; elif [[ "$strategy" == "balanced" ]]; then echo "8k"; else echo "4k"; fi);
    client_max_body_size $(if [[ "$strategy" == "aggressive" ]]; then echo "50m"; elif [[ "$strategy" == "balanced" ]]; then echo "25m"; else echo "10m"; fi);
    large_client_header_buffers $(if [[ "$strategy" == "aggressive" ]]; then echo "8 32k"; elif [[ "$strategy" == "balanced" ]]; then echo "4 16k"; else echo "2 8k"; fi);

    # Compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_comp_level $(if [[ "$strategy" == "aggressive" ]]; then echo "6"; elif [[ "$strategy" == "balanced" ]]; then echo "4"; else echo "2"; fi);
    gzip_types
        application/atom+xml
        application/geo+json
        application/javascript
        application/x-javascript
        application/json
        application/ld+json
        application/manifest+json
        application/rdf+xml
        application/rss+xml
        application/xhtml+xml
        application/xml
        font/eot
        font/otf
        font/ttf
        image/svg+xml
        text/css
        text/javascript
        text/plain
        text/xml;

    # Security headers
    add_header X-Frame-Options DENY always;
    add_header X-Content-Type-Options nosniff always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

    # Rate limiting
    limit_req_zone \$binary_remote_addr zone=api:$(if [[ "$strategy" == "aggressive" ]]; then echo "100m"; elif [[ "$strategy" == "balanced" ]]; then echo "50m"; else echo "10m"; fi) rate=$(if [[ "$strategy" == "aggressive" ]]; then echo "1000r/m"; elif [[ "$strategy" == "balanced" ]]; then echo "500r/m"; else echo "200r/m"; fi);
    limit_req_zone \$binary_remote_addr zone=login:10m rate=5r/m;

    # Upstream configuration
    upstream isectech_backend {
        least_conn;
        server app:3000 max_fails=3 fail_timeout=30s;
        $(if [[ "$strategy" == "aggressive" ]] || [[ "$strategy" == "balanced" ]]; then echo "server app_2:3000 max_fails=3 fail_timeout=30s;"; fi)
        $(if [[ "$strategy" == "aggressive" ]]; then echo "server app_3:3000 max_fails=3 fail_timeout=30s;"; fi)
        $(if [[ "$strategy" == "aggressive" ]]; then echo "server app_4:3000 max_fails=3 fail_timeout=30s;"; fi)
    }

    # Main server configuration
    server {
        listen 80;
        server_name isectech.local;

        # Security and performance settings
        client_body_timeout 60;
        client_header_timeout 60;
        send_timeout 60;

        # API endpoints
        location /api/ {
            limit_req zone=api burst=$(if [[ "$strategy" == "aggressive" ]]; then echo "100"; elif [[ "$strategy" == "balanced" ]]; then echo "50"; else echo "20"; fi) nodelay;
            
            proxy_pass http://isectech_backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade \$http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host \$host;
            proxy_set_header X-Real-IP \$remote_addr;
            proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto \$scheme;
            proxy_cache_bypass \$http_upgrade;
            
            # Timeouts
            proxy_connect_timeout $(if [[ "$strategy" == "aggressive" ]]; then echo "10s"; elif [[ "$strategy" == "balanced" ]]; then echo "5s"; else echo "3s"; fi);
            proxy_send_timeout $(if [[ "$strategy" == "aggressive" ]]; then echo "60s"; elif [[ "$strategy" == "balanced" ]]; then echo "30s"; else echo "15s"; fi);
            proxy_read_timeout $(if [[ "$strategy" == "aggressive" ]]; then echo "60s"; elif [[ "$strategy" == "balanced" ]]; then echo "30s"; else echo "15s"; fi);
            
            # Buffer settings
            proxy_buffer_size $(if [[ "$strategy" == "aggressive" ]]; then echo "128k"; elif [[ "$strategy" == "balanced" ]]; then echo "64k"; else echo "32k"; fi);
            proxy_buffers $(if [[ "$strategy" == "aggressive" ]]; then echo "8 128k"; elif [[ "$strategy" == "balanced" ]]; then echo "4 64k"; else echo "2 32k"; fi);
            proxy_busy_buffers_size $(if [[ "$strategy" == "aggressive" ]]; then echo "256k"; elif [[ "$strategy" == "balanced" ]]; then echo "128k"; else echo "64k"; fi);
        }

        # Login endpoint with stricter rate limiting
        location /api/auth/login {
            limit_req zone=login burst=5 nodelay;
            proxy_pass http://isectech_backend;
            proxy_set_header Host \$host;
            proxy_set_header X-Real-IP \$remote_addr;
            proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
        }

        # Static file serving with caching
        location /static/ {
            root /var/www;
            expires $(if [[ "$strategy" == "aggressive" ]]; then echo "1y"; elif [[ "$strategy" == "balanced" ]]; then echo "1M"; else echo "1w"; fi);
            add_header Cache-Control "public, immutable";
            add_header X-Cache-Status "STATIC";
        }

        # Health check endpoint
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }

        # Default location
        location / {
            proxy_pass http://isectech_backend;
            proxy_set_header Host \$host;
            proxy_set_header X-Real-IP \$remote_addr;
            proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
        }
    }
}
EOF

        log_success "Nginx optimization configuration created: $nginx_config_file"
    else
        log_info "[DRY RUN] Would create Nginx optimization configuration"
    fi
}

# Validation of optimizations
validate_optimizations() {
    local optimization_id="$1"
    local validation_results_file="$PERFORMANCE_DIR/validation/validation_results_$optimization_id.json"
    
    log_info "Validating optimization effectiveness..."
    
    mkdir -p "$(dirname "$validation_results_file")"
    
    # Initialize validation results
    cat > "$validation_results_file" << EOF
{
    "optimization_id": "$optimization_id",
    "validation_timestamp": "$(date -u +%Y-%m-%dT%H:%M:%S.%3NZ)",
    "validation_results": {
EOF

    local validation_passed=true
    
    # Validate database configuration
    if [[ -f "$PROJECT_ROOT/backend/config/postgres/optimized-production.yaml" ]]; then
        log_info "✓ Database optimization configuration found"
        echo '        "database_config": { "status": "validated", "message": "Configuration file created successfully" },' >> "$validation_results_file"
    else
        log_warning "✗ Database optimization configuration not found"
        echo '        "database_config": { "status": "failed", "message": "Configuration file not found" },' >> "$validation_results_file"
        validation_passed=false
    fi
    
    # Validate API configuration
    if [[ -f "$PROJECT_ROOT/app/config/performance.ts" ]]; then
        log_info "✓ API performance configuration found"
        echo '        "api_config": { "status": "validated", "message": "Performance configuration created" },' >> "$validation_results_file"
    else
        log_warning "✗ API performance configuration not found"
        echo '        "api_config": { "status": "failed", "message": "Performance configuration not found" },' >> "$validation_results_file"
        validation_passed=false
    fi
    
    # Validate cache configuration
    if [[ -f "$PROJECT_ROOT/backend/config/redis/redis.conf" ]]; then
        log_info "✓ Redis cache configuration found"
        echo '        "cache_config": { "status": "validated", "message": "Redis configuration created" },' >> "$validation_results_file"
    else
        log_warning "✗ Redis cache configuration not found"  
        echo '        "cache_config": { "status": "failed", "message": "Redis configuration not found" },' >> "$validation_results_file"
        validation_passed=false
    fi
    
    # Validate system optimizations
    if [[ -f "$PROJECT_ROOT/docker-compose.performance.yml" ]]; then
        log_info "✓ Docker performance optimizations found"
        echo '        "system_config": { "status": "validated", "message": "Docker optimizations created" },' >> "$validation_results_file"
    else
        log_warning "✗ Docker performance optimizations not found"
        echo '        "system_config": { "status": "failed", "message": "Docker optimizations not found" },' >> "$validation_results_file"
        validation_passed=false
    fi
    
    # Remove trailing comma and close JSON
    sed -i '$ s/,$//' "$validation_results_file"
    cat >> "$validation_results_file" << EOF
    },
    "overall_status": "$(if [[ "$validation_passed" == "true" ]]; then echo "passed"; else echo "failed"; fi)",
    "recommendations": [
        "Monitor system performance after optimization deployment",
        "Run load tests to validate performance improvements",
        "Check application logs for any optimization-related issues",
        "Gradually roll out optimizations in staging before production"
    ]
}
EOF

    if [[ "$validation_passed" == "true" ]]; then
        log_success "Optimization validation passed: $validation_results_file"
    else
        log_error "Optimization validation failed. Check: $validation_results_file"
    fi
}

# Main execution logic
main() {
    # Default values
    ANALYSIS_FILE=""
    STRATEGY="balanced"
    TEST_RUN=false
    VALIDATE=false
    BACKUP=false
    ROLLBACK_ID=""
    OUTPUT_DIR="$PERFORMANCE_DIR/optimization"
    
    # Create output directory
    mkdir -p "$OUTPUT_DIR"
    
    # Generate optimization ID
    OPTIMIZATION_ID="opt_$(date +%Y%m%d_%H%M%S)"
    
    # Parse command line arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            -a|--analysis-file)
                ANALYSIS_FILE="$2"
                shift 2
                ;;
            -s|--strategy)
                STRATEGY="$2"
                shift 2
                ;;
            -t|--test-run)
                TEST_RUN=true
                shift
                ;;
            -v|--validate)
                VALIDATE=true
                shift
                ;;
            -b|--backup)
                BACKUP=true
                shift
                ;;
            -r|--rollback-id)
                ROLLBACK_ID="$2"
                shift 2
                ;;
            -o|--output)
                OUTPUT_DIR="$2"
                shift 2
                ;;
            -h|--help)
                usage
                exit 0
                ;;
            analyze-and-optimize|database|api|cache|system|monitoring|validate|rollback)
                COMMAND="$1"
                shift
                ;;
            *)
                log_error "Unknown option: $1"
                usage
                exit 1
                ;;
        esac
    done
    
    # Create backup if requested
    if [[ "$BACKUP" == "true" && "$COMMAND" != "rollback" ]]; then
        create_optimization_backup "$OPTIMIZATION_ID"
    fi
    
    # Execute command
    case "${COMMAND:-}" in
        analyze-and-optimize)
            log_info "Running comprehensive performance optimization (ID: $OPTIMIZATION_ID)"
            implement_database_optimizations "$STRATEGY" "$TEST_RUN" "$OPTIMIZATION_ID"
            implement_api_optimizations "$STRATEGY" "$TEST_RUN" "$OPTIMIZATION_ID"
            implement_caching_strategies "$STRATEGY" "$TEST_RUN" "$OPTIMIZATION_ID"
            implement_system_optimizations "$STRATEGY" "$TEST_RUN" "$OPTIMIZATION_ID"
            if [[ "$VALIDATE" == "true" ]]; then
                validate_optimizations "$OPTIMIZATION_ID"
            fi
            ;;
        database)
            implement_database_optimizations "$STRATEGY" "$TEST_RUN" "$OPTIMIZATION_ID"
            ;;
        api)
            implement_api_optimizations "$STRATEGY" "$TEST_RUN" "$OPTIMIZATION_ID"
            ;;
        cache)
            implement_caching_strategies "$STRATEGY" "$TEST_RUN" "$OPTIMIZATION_ID"
            ;;
        system)
            implement_system_optimizations "$STRATEGY" "$TEST_RUN" "$OPTIMIZATION_ID"
            ;;
        validate)
            validate_optimizations "$OPTIMIZATION_ID"
            ;;
        rollback)
            if [[ -z "$ROLLBACK_ID" ]]; then
                log_error "Rollback ID required. Use -r option."
                exit 1
            fi
            log_info "Rolling back optimization: $ROLLBACK_ID"
            # Implement rollback logic here
            ;;
        *)
            log_error "Command required. Use -h for help."
            usage
            exit 1
            ;;
    esac
    
    log_success "Performance optimization completed successfully!"
    if [[ "$TEST_RUN" == "false" ]]; then
        log_info "Optimization ID: $OPTIMIZATION_ID"
        log_info "To rollback these changes: $0 rollback -r $OPTIMIZATION_ID"
    fi
}

# Execute main function with all arguments
main "$@"