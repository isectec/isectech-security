package integrations

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"sync"
	"time"

	"github.com/isectech/platform/services/event-processor/domain/entity"
	"github.com/isectech/platform/shared/types"
	"github.com/prometheus/client_golang/prometheus"
)

// ValidationMonitorIntegration provides Go-based integration between
// validation service and monitoring infrastructure
// Task 83.4: Set Up Monitoring and Logging for Validation Failures
type ValidationMonitorIntegration struct {
	// Prometheus metrics
	validationFailuresTotal  *prometheus.CounterVec
	validationSuccessTotal   *prometheus.CounterVec
	validationDuration       *prometheus.HistogramVec
	schemaValidationErrors   *prometheus.CounterVec
	businessRuleViolations   *prometheus.CounterVec
	complianceViolations     *prometheus.CounterVec
	dataIntegrityErrors      *prometheus.CounterVec
	validationQueueDepth     *prometheus.GaugeVec
	validationThroughput     *prometheus.CounterVec

	// Configuration
	config *MonitoringConfig

	// Internal state
	errorRateTracking map[string][]time.Time
	mu                sync.RWMutex
	alertBuffer       []ValidationAlert
	lastFlush         time.Time
}

// MonitoringConfig defines configuration for validation monitoring
type MonitoringConfig struct {
	// Metrics configuration
	MetricsEnabled   bool
	MetricsNamespace string
	DefaultLabels    map[string]string

	// Alerting thresholds
	ErrorRateWarningThreshold  float64
	ErrorRateCriticalThreshold float64
	SpikeDetectionEnabled      bool
	SpikeMultiplier            float64
	WindowDuration             time.Duration

	// Performance settings
	BufferSize         int
	FlushInterval      time.Duration
	EnableSampling     bool
	SamplingRate       float64
	MaxErrorTracking   int
	CleanupInterval    time.Duration

	// Alert destinations
	WebhookURL         string
	SlackWebhookURL    string
	PagerDutyAPIKey    string
	EmailRecipients    []string
}

// ValidationAlert represents an alert generated by validation monitoring
type ValidationAlert struct {
	ID          string                 `json:"id"`
	Type        string                 `json:"type"`
	Severity    string                 `json:"severity"`
	Message     string                 `json:"message"`
	TenantID    string                 `json:"tenant_id,omitempty"`
	Metadata    map[string]interface{} `json:"metadata"`
	Timestamp   time.Time              `json:"timestamp"`
}

// ValidationError represents a structured validation error for monitoring
type ValidationError struct {
	Field     string      `json:"field"`
	Value     interface{} `json:"value,omitempty"`
	Rule      string      `json:"rule"`
	Message   string      `json:"message"`
	Severity  string      `json:"severity"`
	Code      string      `json:"code"`
	TenantID  string      `json:"tenant_id"`
	EventID   string      `json:"event_id,omitempty"`
	EventType string      `json:"event_type,omitempty"`
	Source    string      `json:"source,omitempty"`
	Timestamp time.Time   `json:"timestamp"`
}

// NewValidationMonitorIntegration creates a new validation monitoring integration
func NewValidationMonitorIntegration(config *MonitoringConfig) *ValidationMonitorIntegration {
	if config == nil {
		config = &MonitoringConfig{
			MetricsEnabled:             true,
			MetricsNamespace:           "api_validation",
			ErrorRateWarningThreshold:  5.0,
			ErrorRateCriticalThreshold: 15.0,
			SpikeDetectionEnabled:      true,
			SpikeMultiplier:           3.0,
			WindowDuration:            5 * time.Minute,
			BufferSize:                1000,
			FlushInterval:             30 * time.Second,
			EnableSampling:            false,
			SamplingRate:              1.0,
			MaxErrorTracking:          10000,
			CleanupInterval:           1 * time.Hour,
		}
	}

	vmi := &ValidationMonitorIntegration{
		config:            config,
		errorRateTracking: make(map[string][]time.Time),
		alertBuffer:       make([]ValidationAlert, 0, config.BufferSize),
		lastFlush:         time.Now(),
	}

	if config.MetricsEnabled {
		vmi.initializeMetrics()
	}

	// Start background goroutines
	go vmi.periodicFlush()
	go vmi.periodicCleanup()

	return vmi
}

// initializeMetrics sets up Prometheus metrics
func (vmi *ValidationMonitorIntegration) initializeMetrics() {
	namespace := vmi.config.MetricsNamespace

	vmi.validationFailuresTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Namespace: namespace,
			Name:      "failures_total",
			Help:      "Total number of API validation failures",
		},
		[]string{"tenant_id", "validation_type", "error_code", "severity", "event_type"},
	)

	vmi.validationSuccessTotal = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Namespace: namespace,
			Name:      "success_total",
			Help:      "Total number of successful API validations",
		},
		[]string{"tenant_id", "validation_type", "event_type"},
	)

	vmi.validationDuration = prometheus.NewHistogramVec(
		prometheus.HistogramOpts{
			Namespace: namespace,
			Name:      "duration_seconds",
			Help:      "Duration of API validation operations",
			Buckets:   []float64{0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 5},
		},
		[]string{"tenant_id", "validation_type", "event_type"},
	)

	vmi.schemaValidationErrors = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Namespace: namespace,
			Name:      "schema_errors_total",
			Help:      "Total number of schema validation errors",
		},
		[]string{"tenant_id", "event_type", "field", "error_code"},
	)

	vmi.businessRuleViolations = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Namespace: namespace,
			Name:      "business_rule_violations_total",
			Help:      "Total number of business rule violations",
		},
		[]string{"tenant_id", "rule_name", "event_type"},
	)

	vmi.complianceViolations = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Namespace: namespace,
			Name:      "compliance_violations_total",
			Help:      "Total number of compliance violations",
		},
		[]string{"tenant_id", "framework", "rule_id", "severity"},
	)

	vmi.dataIntegrityErrors = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Namespace: namespace,
			Name:      "data_integrity_errors_total",
			Help:      "Total number of data integrity errors",
		},
		[]string{"tenant_id", "error_type", "field"},
	)

	vmi.validationQueueDepth = prometheus.NewGaugeVec(
		prometheus.GaugeOpts{
			Namespace: namespace,
			Name:      "queue_depth",
			Help:      "Current depth of validation processing queue",
		},
		[]string{"tenant_id"},
	)

	vmi.validationThroughput = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Namespace: namespace,
			Name:      "throughput_total",
			Help:      "Total number of validations processed",
		},
		[]string{"tenant_id", "status"},
	)

	// Register metrics with Prometheus
	prometheus.MustRegister(
		vmi.validationFailuresTotal,
		vmi.validationSuccessTotal,
		vmi.validationDuration,
		vmi.schemaValidationErrors,
		vmi.businessRuleViolations,
		vmi.complianceViolations,
		vmi.dataIntegrityErrors,
		vmi.validationQueueDepth,
		vmi.validationThroughput,
	)
}

// RecordValidationFailure records a validation failure with comprehensive metrics and alerting
func (vmi *ValidationMonitorIntegration) RecordValidationFailure(
	ctx context.Context,
	validationType string,
	event *entity.Event,
	validationErr error,
	duration time.Duration,
) {
	if !vmi.config.MetricsEnabled {
		return
	}

	// Apply sampling if enabled
	if vmi.config.EnableSampling && vmi.shouldSample() {
		return
	}

	tenantID := event.TenantID.String()
	eventType := string(event.Type)

	// Extract error details
	errorCode, severity := vmi.extractErrorDetails(validationErr)

	// Record basic metrics
	vmi.validationFailuresTotal.WithLabelValues(
		tenantID, validationType, errorCode, severity, eventType,
	).Inc()

	vmi.validationDuration.WithLabelValues(
		tenantID, validationType, eventType,
	).Observe(duration.Seconds())

	vmi.validationThroughput.WithLabelValues(
		tenantID, "failure",
	).Inc()

	// Record validation-type-specific metrics
	switch validationType {
	case "schema":
		field, _ := vmi.extractFieldFromError(validationErr)
		vmi.schemaValidationErrors.WithLabelValues(
			tenantID, eventType, field, errorCode,
		).Inc()

	case "business_rule":
		ruleName, _ := vmi.extractRuleNameFromError(validationErr)
		vmi.businessRuleViolations.WithLabelValues(
			tenantID, ruleName, eventType,
		).Inc()

	case "compliance":
		framework, ruleID := vmi.extractComplianceInfo(validationErr)
		vmi.complianceViolations.WithLabelValues(
			tenantID, framework, ruleID, severity,
		).Inc()

	case "data_integrity":
		errorType, field := vmi.extractDataIntegrityInfo(validationErr)
		vmi.dataIntegrityErrors.WithLabelValues(
			tenantID, errorType, field,
		).Inc()
	}

	// Update error rate tracking for alerting
	vmi.updateErrorRateTracking(tenantID, validationType)

	// Check alerting conditions
	vmi.checkAlertingConditions(ctx, validationType, tenantID, validationErr)

	// Log structured error (if logger is available)
	log.Printf("Validation failure recorded: type=%s, tenant=%s, error=%s, duration=%v",
		validationType, tenantID, errorCode, duration)
}

// RecordValidationSuccess records a successful validation
func (vmi *ValidationMonitorIntegration) RecordValidationSuccess(
	ctx context.Context,
	validationType string,
	event *entity.Event,
	duration time.Duration,
) {
	if !vmi.config.MetricsEnabled {
		return
	}

	// Apply sampling if enabled
	if vmi.config.EnableSampling && vmi.shouldSample() {
		return
	}

	tenantID := event.TenantID.String()
	eventType := string(event.Type)

	vmi.validationSuccessTotal.WithLabelValues(
		tenantID, validationType, eventType,
	).Inc()

	vmi.validationDuration.WithLabelValues(
		tenantID, validationType, eventType,
	).Observe(duration.Seconds())

	vmi.validationThroughput.WithLabelValues(
		tenantID, "success",
	).Inc()
}

// UpdateQueueDepth updates the validation queue depth metric
func (vmi *ValidationMonitorIntegration) UpdateQueueDepth(tenantID string, depth int) {
	if !vmi.config.MetricsEnabled {
		return
	}

	vmi.validationQueueDepth.WithLabelValues(tenantID).Set(float64(depth))
}

// updateErrorRateTracking tracks error rates for alerting
func (vmi *ValidationMonitorIntegration) updateErrorRateTracking(tenantID, validationType string) {
	vmi.mu.Lock()
	defer vmi.mu.Unlock()

	key := fmt.Sprintf("%s:%s", tenantID, validationType)
	now := time.Now()

	if _, exists := vmi.errorRateTracking[key]; !exists {
		vmi.errorRateTracking[key] = make([]time.Time, 0)
	}

	// Add current timestamp
	vmi.errorRateTracking[key] = append(vmi.errorRateTracking[key], now)

	// Remove timestamps outside the window
	cutoff := now.Add(-vmi.config.WindowDuration)
	filtered := make([]time.Time, 0)
	for _, ts := range vmi.errorRateTracking[key] {
		if ts.After(cutoff) {
			filtered = append(filtered, ts)
		}
	}
	vmi.errorRateTracking[key] = filtered

	// Limit tracking size to prevent memory leaks
	if len(vmi.errorRateTracking[key]) > vmi.config.MaxErrorTracking {
		vmi.errorRateTracking[key] = vmi.errorRateTracking[key][len(vmi.errorRateTracking[key])-vmi.config.MaxErrorTracking:]
	}
}

// checkAlertingConditions evaluates alerting conditions and generates alerts
func (vmi *ValidationMonitorIntegration) checkAlertingConditions(
	ctx context.Context,
	validationType, tenantID string,
	validationErr error,
) {
	// Rate-based alerting
	errorRate := vmi.getCurrentErrorRate(tenantID, validationType)

	if errorRate >= vmi.config.ErrorRateCriticalThreshold {
		vmi.createAlert(ValidationAlert{
			ID:       fmt.Sprintf("rate_critical_%s_%s_%d", tenantID, validationType, time.Now().UnixNano()),
			Type:     "rate_threshold",
			Severity: "critical",
			Message:  fmt.Sprintf("Critical error rate: %.2f errors/min in %s validation", errorRate, validationType),
			TenantID: tenantID,
			Metadata: map[string]interface{}{
				"validation_type": validationType,
				"error_rate":      errorRate,
				"threshold":       vmi.config.ErrorRateCriticalThreshold,
			},
			Timestamp: time.Now(),
		})
	} else if errorRate >= vmi.config.ErrorRateWarningThreshold {
		vmi.createAlert(ValidationAlert{
			ID:       fmt.Sprintf("rate_warning_%s_%s_%d", tenantID, validationType, time.Now().UnixNano()),
			Type:     "rate_threshold",
			Severity: "warning",
			Message:  fmt.Sprintf("Warning error rate: %.2f errors/min in %s validation", errorRate, validationType),
			TenantID: tenantID,
			Metadata: map[string]interface{}{
				"validation_type": validationType,
				"error_rate":      errorRate,
				"threshold":       vmi.config.ErrorRateWarningThreshold,
			},
			Timestamp: time.Now(),
		})
	}

	// Spike detection
	if vmi.config.SpikeDetectionEnabled {
		vmi.checkSpikeDetection(tenantID, validationType)
	}

	// Compliance-specific immediate alerts
	if validationType == "compliance" {
		errorCode, _ := vmi.extractErrorDetails(validationErr)
		if vmi.isImmediateComplianceAlert(errorCode) {
			vmi.createAlert(ValidationAlert{
				ID:       fmt.Sprintf("compliance_%s_%s_%d", errorCode, tenantID, time.Now().UnixNano()),
				Type:     "compliance_violation",
				Severity: "high",
				Message:  fmt.Sprintf("Immediate compliance violation: %s", validationErr.Error()),
				TenantID: tenantID,
				Metadata: map[string]interface{}{
					"error_code": errorCode,
					"rule":       vmi.extractRuleFromError(validationErr),
				},
				Timestamp: time.Now(),
			})
		}
	}
}

// getCurrentErrorRate calculates current error rate for a tenant/validation type
func (vmi *ValidationMonitorIntegration) getCurrentErrorRate(tenantID, validationType string) float64 {
	vmi.mu.RLock()
	defer vmi.mu.RUnlock()

	key := fmt.Sprintf("%s:%s", tenantID, validationType)
	timestamps, exists := vmi.errorRateTracking[key]
	if !exists {
		return 0
	}

	// Calculate errors per minute over the window
	windowMinutes := vmi.config.WindowDuration.Minutes()
	return float64(len(timestamps)) / windowMinutes
}

// checkSpikeDetection detects error spikes
func (vmi *ValidationMonitorIntegration) checkSpikeDetection(tenantID, validationType string) {
	vmi.mu.RLock()
	defer vmi.mu.RUnlock()

	key := fmt.Sprintf("%s:%s", tenantID, validationType)
	timestamps, exists := vmi.errorRateTracking[key]
	if !exists || len(timestamps) < 10 { // Minimum events threshold
		return
	}

	now := time.Now()
	recentWindow := now.Add(-vmi.config.WindowDuration)
	historicalWindow := now.Add(-vmi.config.WindowDuration * 6)

	// Count recent vs historical errors
	recentErrors := 0
	historicalErrors := 0

	for _, ts := range timestamps {
		if ts.After(recentWindow) {
			recentErrors++
		} else if ts.After(historicalWindow) {
			historicalErrors++
		}
	}

	if historicalErrors == 0 {
		return // No baseline for comparison
	}

	recentRate := float64(recentErrors) / vmi.config.WindowDuration.Minutes()
	historicalRate := float64(historicalErrors) / (vmi.config.WindowDuration.Minutes() * 5)

	if recentRate >= historicalRate*vmi.config.SpikeMultiplier {
		vmi.createAlert(ValidationAlert{
			ID:       fmt.Sprintf("spike_%s_%s_%d", tenantID, validationType, now.UnixNano()),
			Type:     "error_spike",
			Severity: "warning",
			Message:  fmt.Sprintf("Error spike detected: %.2f errors/min (%.1fx normal)", recentRate, vmi.config.SpikeMultiplier),
			TenantID: tenantID,
			Metadata: map[string]interface{}{
				"validation_type":   validationType,
				"recent_rate":       recentRate,
				"historical_rate":   historicalRate,
				"spike_multiplier":  vmi.config.SpikeMultiplier,
			},
			Timestamp: now,
		})
	}
}

// createAlert adds an alert to the buffer
func (vmi *ValidationMonitorIntegration) createAlert(alert ValidationAlert) {
	vmi.mu.Lock()
	defer vmi.mu.Unlock()

	// Add to buffer
	if len(vmi.alertBuffer) < vmi.config.BufferSize {
		vmi.alertBuffer = append(vmi.alertBuffer, alert)
	}

	// Immediate delivery for critical alerts
	if alert.Severity == "critical" {
		go vmi.sendAlert(alert)
	}

	log.Printf("Alert created: ID=%s, Type=%s, Severity=%s, Message=%s",
		alert.ID, alert.Type, alert.Severity, alert.Message)
}

// sendAlert sends an alert to configured destinations
func (vmi *ValidationMonitorIntegration) sendAlert(alert ValidationAlert) {
	// Implementation would send to webhook, Slack, PagerDuty, email, etc.
	// For now, just log
	alertJSON, _ := json.Marshal(alert)
	log.Printf("Sending alert: %s", string(alertJSON))

	// TODO: Implement actual alert delivery based on configuration
	// - Webhook POST
	// - Slack webhook
	// - PagerDuty Events API
	// - Email via SMTP
}

// periodicFlush periodically flushes buffered alerts
func (vmi *ValidationMonitorIntegration) periodicFlush() {
	ticker := time.NewTicker(vmi.config.FlushInterval)
	defer ticker.Stop()

	for range ticker.C {
		vmi.flushAlerts()
	}
}

// flushAlerts sends all buffered alerts
func (vmi *ValidationMonitorIntegration) flushAlerts() {
	vmi.mu.Lock()
	alertsToFlush := make([]ValidationAlert, len(vmi.alertBuffer))
	copy(alertsToFlush, vmi.alertBuffer)
	vmi.alertBuffer = vmi.alertBuffer[:0] // Clear buffer
	vmi.lastFlush = time.Now()
	vmi.mu.Unlock()

	if len(alertsToFlush) == 0 {
		return
	}

	log.Printf("Flushing %d buffered alerts", len(alertsToFlush))

	// Send alerts in batches
	for _, alert := range alertsToFlush {
		if alert.Severity != "critical" { // Critical alerts already sent immediately
			go vmi.sendAlert(alert)
		}
	}
}

// periodicCleanup cleans up old tracking data
func (vmi *ValidationMonitorIntegration) periodicCleanup() {
	ticker := time.NewTicker(vmi.config.CleanupInterval)
	defer ticker.Stop()

	for range ticker.C {
		vmi.cleanupOldData()
	}
}

// cleanupOldData removes old error tracking data
func (vmi *ValidationMonitorIntegration) cleanupOldData() {
	vmi.mu.Lock()
	defer vmi.mu.Unlock()

	cutoff := time.Now().Add(-vmi.config.WindowDuration * 2) // Keep 2x window for safety

	for key, timestamps := range vmi.errorRateTracking {
		filtered := make([]time.Time, 0)
		for _, ts := range timestamps {
			if ts.After(cutoff) {
				filtered = append(filtered, ts)
			}
		}

		if len(filtered) == 0 {
			delete(vmi.errorRateTracking, key)
		} else {
			vmi.errorRateTracking[key] = filtered
		}
	}
}

// Helper methods for extracting error information

func (vmi *ValidationMonitorIntegration) extractErrorDetails(err error) (code, severity string) {
	// Default values
	code = "UNKNOWN_ERROR"
	severity = "error"

	if err == nil {
		return
	}

	// Extract structured error information
	// This would be enhanced based on actual error types
	errMsg := err.Error()

	// Map common error patterns to codes and severities
	switch {
	case contains(errMsg, "FIELD_REQUIRED"):
		code = "FIELD_REQUIRED"
		severity = "error"
	case contains(errMsg, "CONSTRAINT_VIOLATION"):
		code = "CONSTRAINT_VIOLATION"
		severity = "error"
	case contains(errMsg, "BUSINESS_RULE_VIOLATION"):
		code = "BUSINESS_RULE_VIOLATION"
		severity = "warning"
	case contains(errMsg, "COMPLIANCE_VIOLATION"):
		code = "COMPLIANCE_VIOLATION"
		severity = "error"
	case contains(errMsg, "GDPR"):
		code = "GDPR_VIOLATION"
		severity = "critical"
	case contains(errMsg, "HIPAA"):
		code = "HIPAA_VIOLATION"
		severity = "critical"
	case contains(errMsg, "PCI"):
		code = "PCI_VIOLATION"
		severity = "critical"
	}

	return code, severity
}

func (vmi *ValidationMonitorIntegration) extractFieldFromError(err error) (string, bool) {
	// Extract field name from error message
	// This would be enhanced with structured error parsing
	if err == nil {
		return "", false
	}
	return "unknown_field", false
}

func (vmi *ValidationMonitorIntegration) extractRuleNameFromError(err error) (string, bool) {
	// Extract business rule name from error
	if err == nil {
		return "", false
	}
	return "unknown_rule", false
}

func (vmi *ValidationMonitorIntegration) extractComplianceInfo(err error) (framework, ruleID string) {
	// Extract compliance framework and rule ID
	if err == nil {
		return "unknown", "unknown"
	}

	errMsg := err.Error()
	switch {
	case contains(errMsg, "GDPR"):
		return "gdpr", "data_minimization"
	case contains(errMsg, "HIPAA"):
		return "hipaa", "phi_protection"
	case contains(errMsg, "PCI"):
		return "pci_dss", "cardholder_data"
	default:
		return "unknown", "unknown"
	}
}

func (vmi *ValidationMonitorIntegration) extractDataIntegrityInfo(err error) (errorType, field string) {
	// Extract data integrity error type and field
	if err == nil {
		return "unknown", "unknown"
	}

	errMsg := err.Error()
	switch {
	case contains(errMsg, "TIMESTAMP"):
		return "timestamp_integrity", "timestamp"
	case contains(errMsg, "ID_INTEGRITY"):
		return "id_integrity", "id"
	case contains(errMsg, "IP_INTEGRITY"):
		return "ip_integrity", "ip_address"
	case contains(errMsg, "JSON_INTEGRITY"):
		return "json_integrity", "payload"
	default:
		return "unknown", "unknown"
	}
}

func (vmi *ValidationMonitorIntegration) extractRuleFromError(err error) string {
	// Extract rule name from error
	if err == nil {
		return "unknown"
	}
	return "unknown_rule"
}

func (vmi *ValidationMonitorIntegration) isImmediateComplianceAlert(errorCode string) bool {
	immediateAlerts := []string{
		"GDPR_VIOLATION",
		"HIPAA_VIOLATION", 
		"PCI_VIOLATION",
	}

	for _, alert := range immediateAlerts {
		if errorCode == alert {
			return true
		}
	}
	return false
}

func (vmi *ValidationMonitorIntegration) shouldSample() bool {
	// Simple sampling implementation
	// Could be enhanced with more sophisticated sampling algorithms
	if !vmi.config.EnableSampling {
		return false
	}

	// Generate random number between 0 and 1
	// This is a simplified implementation
	return false // Placeholder - would implement proper random sampling
}

// contains is a simple string contains helper
func contains(s, substr string) bool {
	return len(s) >= len(substr) && (s == substr || 
		(len(s) > len(substr) && (s[:len(substr)] == substr || s[len(s)-len(substr):] == substr ||
		 (len(s) > 2*len(substr) && containsInMiddle(s, substr)))))
}

func containsInMiddle(s, substr string) bool {
	for i := 1; i <= len(s)-len(substr)-1; i++ {
		if s[i:i+len(substr)] == substr {
			return true
		}
	}
	return false
}

// Health check methods
func (vmi *ValidationMonitorIntegration) GetHealth() map[string]interface{} {
	vmi.mu.RLock()
	defer vmi.mu.RUnlock()

	return map[string]interface{}{
		"status":               "healthy",
		"buffered_alerts":      len(vmi.alertBuffer),
		"error_rate_windows":   len(vmi.errorRateTracking),
		"last_flush":          vmi.lastFlush.Format(time.RFC3339),
		"metrics_enabled":     vmi.config.MetricsEnabled,
		"sampling_enabled":    vmi.config.EnableSampling,
	}
}

// Shutdown gracefully shuts down the monitoring integration
func (vmi *ValidationMonitorIntegration) Shutdown(ctx context.Context) error {
	log.Println("Shutting down validation monitor integration")

	// Flush any remaining alerts
	vmi.flushAlerts()

	// Clear internal state
	vmi.mu.Lock()
	vmi.errorRateTracking = make(map[string][]time.Time)
	vmi.alertBuffer = vmi.alertBuffer[:0]
	vmi.mu.Unlock()

	log.Println("Validation monitor integration shutdown complete")
	return nil
}