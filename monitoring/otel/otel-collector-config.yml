# iSECTECH OpenTelemetry Collector Configuration
# Production-grade telemetry collection and processing

# ═══════════════════════════════════════════════════════════════════════════════
# RECEIVERS - Data collection endpoints
# ═══════════════════════════════════════════════════════════════════════════════

receivers:
  # OTLP receiver for traces, metrics, and logs
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
        max_recv_msg_size: 4194304
        max_concurrent_streams: 16
        keepalive:
          server_parameters:
            max_connection_idle: 11s
            max_connection_age: 12s
            max_connection_age_grace: 13s
            time: 30s
            timeout: 5s
      http:
        endpoint: 0.0.0.0:4318
        cors:
          allowed_origins:
            - http://localhost:3000
            - https://isectech.com
            - https://*.isectech.com

  # Jaeger receiver for legacy Jaeger clients
  jaeger:
    protocols:
      grpc:
        endpoint: 0.0.0.0:14250
      thrift_http:
        endpoint: 0.0.0.0:14268
      thrift_compact:
        endpoint: 0.0.0.0:6831
      thrift_binary:
        endpoint: 0.0.0.0:6832

  # Zipkin receiver for Zipkin-compatible traces
  zipkin:
    endpoint: 0.0.0.0:9411

  # Prometheus receiver for metrics scraping
  prometheus:
    config:
      global:
        scrape_interval: 15s
      scrape_configs:
        - job_name: 'otel-collector'
          static_configs:
            - targets: ['localhost:8888']
        - job_name: 'isectech-services'
          static_configs:
            - targets:
              - 'frontend-service:3000'
              - 'backend-service:8080'
              - 'ai-service:5000'

  # Host metrics for infrastructure monitoring
  hostmetrics:
    collection_interval: 30s
    scrapers:
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
      disk:
      filesystem:
        exclude_mount_points:
          mount_points: ["/dev/*", "/proc/*", "/sys/*", "/var/lib/docker/*"]
          match_type: regexp
      memory:
      network:
      load:
      processes:

  # Docker stats receiver
  docker_stats:
    endpoint: unix:///var/run/docker.sock
    timeout: 20s
    api_version: 1.40

# ═══════════════════════════════════════════════════════════════════════════════
# PROCESSORS - Data transformation and filtering
# ═══════════════════════════════════════════════════════════════════════════════

processors:
  # Batch processor for performance optimization
  batch:
    timeout: 1s
    send_batch_size: 1024
    send_batch_max_size: 2048

  # Memory limiter to prevent OOM
  memory_limiter:
    limit_mib: 512
    spike_limit_mib: 128
    check_interval: 5s

  # Resource processor to add/modify resource attributes
  resource:
    attributes:
      - key: service.namespace
        value: "isectech"
        action: upsert
      - key: deployment.environment
        value: "production"
        action: upsert
      - key: service.version
        from_attribute: "version"
        action: insert

  # Attributes processor for span modification
  attributes:
    actions:
      - key: environment
        value: production
        action: upsert
      - key: cluster
        value: isectech-k8s
        action: upsert
      - key: http.user_agent
        action: delete
      - key: user.email
        action: hash

  # Span processor for trace sampling and filtering
  span:
    name:
      to_attributes:
        rules:
          - ^\/api\/v[0-9]+\/(?P<endpoint>.*)$
          - ^(?P<method>GET|POST|PUT|DELETE|PATCH)\s+(?P<path>.*)$

  # Probabilistic sampler for high-volume environments
  probabilistic_sampler:
    sampling_percentage: 10

  # Tail sampling for intelligent sampling decisions
  tail_sampling:
    decision_wait: 10s
    num_traces: 50000
    expected_new_traces_per_sec: 10
    policies:
      - name: error_policy
        type: status_code
        status_code:
          status_codes: [ERROR]
      - name: slow_requests
        type: latency
        latency:
          threshold_ms: 5000
      - name: security_events
        type: string_attribute
        string_attribute:
          key: service.name
          values: ["security-service", "auth-service"]
      - name: sample_rate
        type: probabilistic
        probabilistic:
          sampling_percentage: 5

  # Filter processor to exclude unwanted spans
  filter:
    traces:
      span:
        - 'attributes["http.url"] != nil and IsMatch(attributes["http.url"], ".*health.*")'
        - 'name == "GET /metrics"'

  # Resource detection for cloud environments
  resourcedetection:
    detectors: [env, system, docker]
    timeout: 5s
    override: false

# ═══════════════════════════════════════════════════════════════════════════════
# EXPORTERS - Data output destinations
# ═══════════════════════════════════════════════════════════════════════════════

exporters:
  # Jaeger exporter for traces
  jaeger:
    endpoint: jaeger-collector:14250
    tls:
      insecure: true
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s

  # OTLP exporter for traces to Jaeger
  otlp/jaeger:
    endpoint: jaeger-collector:4317
    tls:
      insecure: true
    retry_on_failure:
      enabled: true

  # Prometheus exporter for metrics
  prometheus:
    endpoint: "0.0.0.0:8889"
    const_labels:
      environment: production
      cluster: isectech
    send_timestamps: true
    metric_expiration: 180m
    enable_open_metrics: true

  # Elasticsearch exporter for traces and logs
  elasticsearch:
    endpoints: ["http://elasticsearch:9200"]
    username: elastic
    password: isectech_elastic_2024
    index: "otel-traces-%{+yyyy.MM.dd}"
    pipeline: "otel-pipeline"
    timeout: 30s
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s

  # Loki exporter for logs
  loki:
    endpoint: "http://loki:3100/loki/api/v1/push"
    tenant_id: "isectech"
    labels:
      attributes:
        service.name: "service_name"
        service.namespace: "service_namespace"
      resource:
        container.name: "container_name"
        k8s.pod.name: "k8s_pod_name"

  # Logging exporter for debugging
  logging:
    loglevel: info
    sampling_initial: 5
    sampling_thereafter: 200

  # File exporter for backup/debugging
  file:
    path: /tmp/otel-traces.json
    rotation:
      max_megabytes: 100
      max_days: 3
      max_backups: 3

# ═══════════════════════════════════════════════════════════════════════════════
# EXTENSIONS - Additional functionality
# ═══════════════════════════════════════════════════════════════════════════════

extensions:
  # Health check extension
  health_check:
    endpoint: 0.0.0.0:13133
    path: /health

  # pprof extension for performance profiling
  pprof:
    endpoint: 0.0.0.0:1777

  # zpages extension for live debugging
  zpages:
    endpoint: 0.0.0.0:55679

  # Memory ballast for GC optimization
  memory_ballast:
    size_mib: 165

# ═══════════════════════════════════════════════════════════════════════════════
# SERVICE PIPELINES - Data flow configuration
# ═══════════════════════════════════════════════════════════════════════════════

service:
  extensions: [health_check, pprof, zpages, memory_ballast]
  
  pipelines:
    # Traces pipeline
    traces:
      receivers: [otlp, jaeger, zipkin]
      processors: [memory_limiter, resource, attributes, span, tail_sampling, batch]
      exporters: [jaeger, otlp/jaeger, elasticsearch, logging]

    # Metrics pipeline
    metrics:
      receivers: [otlp, prometheus, hostmetrics, docker_stats]
      processors: [memory_limiter, resource, batch]
      exporters: [prometheus, logging]

    # Logs pipeline
    logs:
      receivers: [otlp]
      processors: [memory_limiter, resource, attributes, batch]
      exporters: [loki, elasticsearch, logging]

  # Telemetry configuration
  telemetry:
    logs:
      level: "info"
    metrics:
      address: 0.0.0.0:8888
      level: detailed
    traces:
      processors: [batch]